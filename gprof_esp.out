Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ms/call  ms/call  name    
 89.56     90.04    90.04 108017432     0.00     0.00  ggml_vec_dot_q4_0_q8_0_esp_riscv
  6.20     96.27     6.23 11219832     0.00     0.00  ggml_vec_dot_q6_K_q8_K
  1.28     97.56     1.29  1401498     0.00     0.00  ggml_vec_dot_q4_1_q8_1
  0.69     98.25     0.69   274781     0.00     0.36  ggml_compute_forward_mul_mat
  0.63     98.88     0.63 13516431     0.00     0.00  ggml_vec_dot_f16
  0.26     99.14     0.26                             _init
  0.19     99.33     0.19     1061     0.18     0.18  void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long)
  0.15     99.48     0.15                             ggml_compute_forward
  0.10     99.58     0.10   102629     0.00     0.00  ggml_compute_forward_dup
  0.09     99.67     0.09    81218     0.00     0.00  ggml_compute_forward_rope_f32
  0.08     99.75     0.08    38450     0.00     0.00  quantize_row_q8_0
  0.07     99.82     0.07                             ggml_vec_mad_f32_unroll
  0.07     99.89     0.07   280147     0.00     0.00  std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&)
  0.06     99.95     0.06    36360     0.00     0.00  ggml_compute_forward_soft_max
  0.05    100.00     0.05   181214     0.00     0.00  ggml_vec_soft_max_f32
  0.04    100.04     0.04   125350     0.00     0.00  ggml_compute_forward_mul
  0.04    100.08     0.04    88828     0.00     0.00  ggml_compute_forward_rms_norm
  0.04    100.12     0.04      512     0.08     0.20  common_sampler_sample(common_sampler*, llama_context*, int, bool)
  0.04    100.16     0.04      512     0.08     0.11  void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>)
  0.04    100.20     0.04                             print_gemm_cfg
  0.03    100.23     0.03     1029     0.03     0.03  ggml_backend_sched_get_tensor_backend
  0.03    100.26     0.03      609     0.05     0.05  void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long)
  0.03    100.29     0.03                             ggml_vec_dot_q5_K_q8_K
  0.02    100.31     0.02   380136     0.00     0.00  ggml_fp32_to_fp16_row
  0.02    100.33     0.02   104421     0.00     0.00  void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>)
  0.02    100.35     0.02    40460     0.00     0.00  ggml_compute_forward_unary
  0.02    100.37     0.02      531     0.04     0.04  llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool)
  0.02    100.39     0.02      513     0.04     0.22  llama_decode_internal(llama_context&, llama_batch)
  0.01    100.40     0.01  9977911     0.00     0.00  ggml_blck_size
  0.01    100.41     0.01  8736023     0.00     0.00  ggml_type_size
  0.01    100.42     0.01  2354340     0.00     0.00  ggml_is_contiguous_0
  0.01    100.43     0.01   693095     0.00     0.00  ggml_nbytes
  0.01    100.44     0.01   128256     0.00     0.00  std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.01    100.45     0.01   108360     0.00     0.00  ggml_visit_parents
  0.01    100.46     0.01    80551     0.00     0.00  ggml_compute_forward_add
  0.01    100.47     0.01      517     0.02     0.02  llama_sampler_penalties_accept(llama_sampler*, int)
  0.01    100.48     0.01      513     0.02     0.02  llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&)
  0.01    100.49     0.01      513     0.02     0.04  ggml_gallocr_alloc_graph
  0.01    100.50     0.01      341     0.03     0.03  quantize_row_q8_K_ref
  0.01    100.51     0.01        6     1.67     1.67  unicode_len_utf8(char)
  0.01    100.52     0.01        1    10.00    95.00  llm_load_vocab(llama_model_loader&, llama_model&)
  0.01    100.53     0.01        1    10.00    10.68  llama_vocab::~llama_vocab()
  0.01    100.54     0.01                             ggml_backend_alloc_ctx_tensors
  0.00    100.54     0.00  3182328     0.00     0.00  unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&)
  0.00    100.54     0.00  3176310     0.00     0.00  ggml_row_size
  0.00    100.54     0.00  2412793     0.00     0.00  ggml_is_contiguous
  0.00    100.54     0.00  1756974     0.00     0.00  ggml_is_empty
  0.00    100.54     0.00  1654012     0.00     0.00  ggml_n_dims
  0.00    100.54     0.00   872707     0.00     0.00  unicode_cpt_to_utf8[abi:cxx11](unsigned int)
  0.00    100.54     0.00   871921     0.00     0.00  unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00   871921     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00   818795     0.00     0.00  gguf_get_n_kv
  0.00    100.54     0.00   817191     0.00     0.00  replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00   816820     0.00     0.00  gguf_get_arr_str
  0.00    100.54     0.00   599166     0.00     0.00  ggml_backend_buft_get_alloc_size
  0.00    100.54     0.00   570742     0.00     0.00  ggml_get_type_traits
  0.00    100.54     0.00   560310     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00    100.54     0.00   533399     0.00     0.00  ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*)
  0.00    100.54     0.00   533399     0.00     0.00  ggml_backend_buffer_get_base
  0.00    100.54     0.00   495424     0.00     0.00  llamafile_sgemm
  0.00    100.54     0.00   409746     0.00     0.00  unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00   408611     0.00     0.00  gguf_fread_str
  0.00    100.54     0.00   400857     0.00     0.00  ggml_nelements
  0.00    100.54     0.00   395044     0.00     0.00  ggml_cpu_has_f16c
  0.00    100.54     0.00   387162     0.00     0.00  bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*)
  0.00    100.54     0.00   372584     0.00     0.00  ggml_format_name
  0.00    100.54     0.00   370587     0.00     0.00  ggml_nrows
  0.00    100.54     0.00   345268     0.00     0.00  ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*)
  0.00    100.54     0.00   318551     0.00     0.00  ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*)
  0.00    100.54     0.00   318551     0.00     0.00  ggml_backend_dev_supports_op
  0.00    100.54     0.00   318372     0.00     0.00  ggml_backend_supports_op
  0.00    100.54     0.00   296028     0.00     0.00  ggml_are_same_shape
  0.00    100.54     0.00   270584     0.00     0.00  ggml_new_object
  0.00    100.54     0.00   267965     0.00     0.00  ggml_backend_buffer_init_tensor
  0.00    100.54     0.00   247815     0.00     0.00  ggml_can_repeat
  0.00    100.54     0.00   235296     0.00     0.00  std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&)
  0.00    100.54     0.00   218779     0.00     0.00  ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*)
  0.00    100.54     0.00   218779     0.00     0.00  ggml_backend_buft_is_host
  0.00    100.54     0.00   217753     0.00     0.00  ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*)
  0.00    100.54     0.00   217753     0.00     0.00  ggml_backend_dev_supports_buft
  0.00    100.54     0.00   217753     0.00     0.00  ggml_backend_supports_buft
  0.00    100.54     0.00   179252     0.00     0.00  ggml_new_tensor
  0.00    100.54     0.00   178739     0.00     0.00  ggml_backend_buffer_get_type
  0.00    100.54     0.00   178228     0.00     0.00  ggml_backend_buffer_get_size
  0.00    100.54     0.00   177709     0.00     0.00  ggml_backend_buffer_get_alloc_size
  0.00    100.54     0.00   177677     0.00     0.00  ggml_backend_tensor_alloc
  0.00    100.54     0.00   168713     0.00     0.00  ggml_is_numa
  0.00    100.54     0.00   130616     0.00     0.00  llama_token_get_attr_impl(llama_vocab const&, int)
  0.00    100.54     0.00   130616     0.00     0.00  llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool)
  0.00    100.54     0.00   130616     0.00     0.00  llama_token_to_piece
  0.00    100.54     0.00   128292     0.00     0.00  gguf_data_to_str(gguf_type, void const*, int)
  0.00    100.54     0.00   128256     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long)
  0.00    100.54     0.00    92060     0.00     0.00  ggml_dup_tensor
  0.00    100.54     0.00    90288     0.00     0.00  ggml_backend_view_init
  0.00    100.54     0.00    79884     0.00     0.00  ggml_rope_cache_init
  0.00    100.54     0.00    79347     0.00     0.00  ggml_rope_yarn_corr_dims
  0.00    100.54     0.00    74933     0.00     0.00  ggml_is_transposed
  0.00    100.54     0.00    74933     0.00     0.00  ggml_mul_mat
  0.00    100.54     0.00    58308     0.00     0.00  llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*)
  0.00    100.54     0.00    50052     0.00     0.00  ggml_build_forward_expand
  0.00    100.54     0.00    49125     0.00     0.00  ggml_get_unary_op
  0.00    100.54     0.00    41280     0.00     0.00  ggml_new_tensor_impl.constprop.0
  0.00    100.54     0.00    41280     0.00     0.00  ggml_view_tensor
  0.00    100.54     0.00    34050     0.00     0.00  ggml_element_size
  0.00    100.54     0.00    33024     0.00     0.00  ggml_new_tensor_impl.constprop.1
  0.00    100.54     0.00    32833     0.00     0.00  ggml_is_quantized
  0.00    100.54     0.00    25317     0.00     0.00  ggml_mul
  0.00    100.54     0.00    17028     0.00     0.00  ggml_rms_norm
  0.00    100.54     0.00    16544     0.00     0.00  ggml_is_vector
  0.00    100.54     0.00    16528     0.00     0.00  ggml_rope_ext
  0.00    100.54     0.00    16512     0.00     0.00  llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int)
  0.00    100.54     0.00    16512     0.00     0.00  ggml_add
  0.00    100.54     0.00    16512     0.00     0.00  ggml_cpy
  0.00    100.54     0.00    16512     0.00     0.00  ggml_permute
  0.00    100.54     0.00    16512     0.00     0.00  ggml_reshape_3d
  0.00    100.54     0.00    16512     0.00     0.00  ggml_view_3d
  0.00    100.54     0.00    16449     0.00     0.00  ggml_backend_get_device
  0.00    100.54     0.00    16448     0.00     0.00  ggml_backend_sched_set_tensor_backend
  0.00    100.54     0.00    10878     0.00     0.00  gguf_get_tensor_name
  0.00    100.54     0.00     9918     0.00     0.00  ggml_new_tensor_4d
  0.00    100.54     0.00     8256     0.00     0.00  llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int)
  0.00    100.54     0.00     8256     0.00     0.00  llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long)
  0.00    100.54     0.00     8256     0.00     0.00  ggml_cont_2d
  0.00    100.54     0.00     8256     0.00     0.00  ggml_cont_4d
  0.00    100.54     0.00     8256     0.00     0.00  ggml_is_contiguous_1
  0.00    100.54     0.00     8256     0.00     0.00  ggml_is_matrix
  0.00    100.54     0.00     8256     0.00     0.00  ggml_mul_mat_set_prec
  0.00    100.54     0.00     8256     0.00     0.00  ggml_new_tensor_impl.constprop.2
  0.00    100.54     0.00     8256     0.00     0.00  ggml_new_tensor_impl.constprop.3
  0.00    100.54     0.00     8256     0.00     0.00  ggml_silu
  0.00    100.54     0.00     8256     0.00     0.00  ggml_soft_max_ext
  0.00    100.54     0.00     8256     0.00     0.00  ggml_transpose
  0.00    100.54     0.00     8256     0.00     0.00  ggml_unary
  0.00    100.54     0.00     8256     0.00     0.00  ggml_view_1d
  0.00    100.54     0.00     8256     0.00     0.00  ggml_view_2d
  0.00    100.54     0.00     7090     0.00     0.00  ggml_compute_forward_get_rows
  0.00    100.54     0.00     6199     0.00     0.00  llama_sampler_accept
  0.00    100.54     0.00     6144     0.00     0.00  llama_sampler_apply
  0.00    100.54     0.00     4833     0.00     0.00  ggml_gallocr_allocate_node
  0.00    100.54     0.00     4422     0.00     0.00  ggml_set_name
  0.00    100.54     0.00     3091     0.00     0.00  ggml_time_us
  0.00    100.54     0.00     2246     0.00     0.00  ggml_critical_section_end
  0.00    100.54     0.00     2246     0.00     0.00  ggml_critical_section_start
  0.00    100.54     0.00     2064     0.00     0.00  ggml_set_input
  0.00    100.54     0.00     1731     0.00     0.00  ggml_free
  0.00    100.54     0.00     1730     0.00     0.00  ggml_init
  0.00    100.54     0.00     1629     0.00     0.00  ggml_new_tensor_1d
  0.00    100.54     0.00     1613     0.00     0.00  gguf_get_key
  0.00    100.54     0.00     1549     0.00     0.00  ggml_get_rows
  0.00    100.54     0.00     1541     0.00     0.00  ggml_backend_is_cpu
  0.00    100.54     0.00     1541     0.00     0.00  ggml_guid_matches
  0.00    100.54     0.00     1036     0.00     0.21  (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long)
  0.00    100.54     0.00     1036     0.00     0.00  ggml_hash_set_reset
  0.00    100.54     0.00     1036     0.00     0.00  ggml_hash_size
  0.00    100.54     0.00     1033     0.00     0.00  std::vector<int, std::allocator<int> >::_M_default_append(unsigned long)
  0.00    100.54     0.00     1030     0.00     0.00  ggml_backend_sched_reset
  0.00    100.54     0.00     1030     0.00     0.00  llama_get_model
  0.00    100.54     0.00     1026     0.00     0.00  llama_token_is_eog_impl(llama_vocab const&, int)
  0.00    100.54     0.00     1026     0.00     0.00  ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long)
  0.00    100.54     0.00     1026     0.00     0.00  ggml_backend_buffer_is_host
  0.00    100.54     0.00     1026     0.00     0.00  ggml_backend_tensor_set
  0.00    100.54     0.00     1026     0.00     0.00  ggml_graph_node
  0.00    100.54     0.00     1026     0.00     0.00  llama_token_is_eog
  0.00    100.54     0.00     1024     0.00     0.00  llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00     1024     0.00     0.00  llama_sampler_softmax_impl(llama_token_data_array*)
  0.00    100.54     0.00     1020     0.00     0.00  void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long)
  0.00    100.54     0.00     1012     0.00     0.00  (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long)
  0.00    100.54     0.00      962     0.00     0.00  common_log_add(common_log*, ggml_log_level, char const*, ...)
  0.00    100.54     0.00      962     0.00     0.00  common_log_main()
  0.00    100.54     0.00      953     0.00     0.00  void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long)
  0.00    100.54     0.00      799     0.00     0.00  ggml_get_next_tensor
  0.00    100.54     0.00      735     0.00     0.00  ggml_get_name
  0.00    100.54     0.00      733     0.00     0.00  void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&)
  0.00    100.54     0.00      705     0.00     0.00  ggml_aligned_free
  0.00    100.54     0.00      705     0.00     0.00  ggml_aligned_malloc
  0.00    100.54     0.00      693     0.00     0.00  ggml_graph_compute_with_ctx
  0.00    100.54     0.00      685     0.00     0.00  quantize_row_q8_1
  0.00    100.54     0.00      565     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00      549     0.00     0.00  ggml_new_tensor_2d
  0.00    100.54     0.00      534     0.00     0.00  llama_set_inputs(llama_context&, llama_ubatch const&)
  0.00    100.54     0.00      528     0.00     0.00  llama_format_tensor_shape(ggml_tensor const*)
  0.00    100.54     0.00      524     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&)
  0.00    100.54     0.00      522     0.00     0.00  format(char const*, ...)
  0.00    100.54     0.00      520     0.00     0.00  std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&)
  0.00    100.54     0.00      517     0.00     0.02  common_sampler_accept(common_sampler*, int, bool)
  0.00    100.54     0.00      517     0.00     0.00  common_token_to_piece[abi:cxx11](llama_context const*, int, bool)
  0.00    100.54     0.00      517     0.00     0.00  llama_sampler_dry_accept(llama_sampler*, int)
  0.00    100.54     0.00      517     0.00     0.02  llama_sampler_chain_accept(llama_sampler*, int)
  0.00    100.54     0.00      516     0.00     0.03  llama_build_graph(llama_context&, llama_ubatch const&, bool)
  0.00    100.54     0.00      516     0.00     0.00  ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char)
  0.00    100.54     0.00      516     0.00     0.03  llm_build_context::build_llama()
  0.00    100.54     0.00      516     0.00     0.00  std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00      516     0.00     0.00  std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run()
  0.00    100.54     0.00      516     0.00     0.00  ggml_backend_buffer_clear
  0.00    100.54     0.00      516     0.00     0.00  ggml_backend_sched_synchronize
  0.00    100.54     0.00      516     0.00     0.00  ggml_backend_synchronize
  0.00    100.54     0.00      516     0.00     0.00  ggml_graph_view
  0.00    100.54     0.00      516     0.00     0.00  ggml_new_graph_custom
  0.00    100.54     0.00      515     0.00     0.00  llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int)
  0.00    100.54     0.00      515     0.00     0.00  console::set_display(console::display_t)
  0.00    100.54     0.00      515     0.00     0.00  std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long)
  0.00    100.54     0.00      515     0.00     0.00  std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long)
  0.00    100.54     0.00      515     0.00     0.00  ggml_cpu_init
  0.00    100.54     0.00      514     0.00     0.00  llama_output_reserve(llama_context&, unsigned long)
  0.00    100.54     0.00      514     0.00     0.00  llama_n_vocab
  0.00    100.54     0.00      513     0.00     0.00  common_sampler_last(common_sampler const*)
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*)
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long)
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_buffer_reset
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_cpu_set_abort_callback
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_cpu_set_n_threads
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_cpu_set_threadpool
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_graph_compute_async
  0.00    100.54     0.00      513     0.00     0.07  ggml_backend_sched_alloc_graph
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_sched_graph_compute_async
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_sched_set_eval_callback
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_tensor_get
  0.00    100.54     0.00      513     0.00     0.00  ggml_backend_tensor_get_async
  0.00    100.54     0.00      513     0.00     0.00  ggml_graph_compute
  0.00    100.54     0.00      513     0.00     0.00  ggml_graph_plan
  0.00    100.54     0.00      513     0.00     0.00  llama_batch_get_one
  0.00    100.54     0.00      513     0.00     0.22  llama_decode
  0.00    100.54     0.00      513     0.00     0.00  llama_kv_cache_update
  0.00    100.54     0.00      513     0.00     0.00  llama_synchronize
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.12  llama_sampler_top_k_impl(llama_token_data_array*, int)
  0.00    100.54     0.00      512     0.00     0.12  llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*)
  0.00    100.54     0.00      512     0.00     0.00  llama_sampler_grammar_accept_impl(llama_sampler*, int)
  0.00    100.54     0.00      512     0.00     0.00  llama_get_logits_ith
  0.00    100.54     0.00      431     0.00     0.00  llama_log_internal(ggml_log_level, char const*, ...)
  0.00    100.54     0.00      431     0.00     0.00  llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*)
  0.00    100.54     0.00      431     0.00     0.00  common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*)
  0.00    100.54     0.00      409     0.00     0.00  void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long)
  0.00    100.54     0.00      385     0.00     0.00  common_arg::in_example(llama_example)
  0.00    100.54     0.00      376     0.00     0.00  common_arg::~common_arg()
  0.00    100.54     0.00      305     0.00     0.00  quantize_row_q8_K
  0.00    100.54     0.00      291     0.00     0.00  dequantize_row_q6_K
  0.00    100.54     0.00      276     0.00     0.00  llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const
  0.00    100.54     0.00      258     0.00     0.00  std::vector<char, std::allocator<char> >::_M_default_append(unsigned long)
  0.00    100.54     0.00      256     0.00     0.00  std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long)
  0.00    100.54     0.00      256     0.00     0.00  std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&)
  0.00    100.54     0.00      256     0.00     0.00  std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&)
  0.00    100.54     0.00      203     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const
  0.00    100.54     0.00      184     0.00     0.00  ggml_backend_buffer_free
  0.00    100.54     0.00      184     0.00     0.00  ggml_tensor_overhead
  0.00    100.54     0.00      183     0.00     0.00  ggml_backend_buffer_init
  0.00    100.54     0.00      182     0.00     0.00  ggml_backend_buft_alloc_buffer
  0.00    100.54     0.00      173     0.00     0.00  common_arg::common_arg(common_arg const&)
  0.00    100.54     0.00      172     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long)
  0.00    100.54     0.00      164     0.00     0.00  ggml_backend_buft_get_device
  0.00    100.54     0.00      164     0.00     0.00  ggml_backend_dev_host_buffer_type
  0.00    100.54     0.00      163     0.00     0.00  weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*)
  0.00    100.54     0.00      158     0.00     0.00  gguf_get_kv_type
  0.00    100.54     0.00      148     0.00     0.00  llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*)
  0.00    100.54     0.00      147     0.00     0.00  llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int)
  0.00    100.54     0.00      147     0.00     0.00  std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&)
  0.00    100.54     0.00      147     0.00     0.00  std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00      147     0.00     0.00  gguf_find_tensor
  0.00    100.54     0.00      147     0.00     0.00  gguf_get_data_offset
  0.00    100.54     0.00      147     0.00     0.00  gguf_get_n_tensors
  0.00    100.54     0.00      147     0.00     0.00  gguf_get_tensor_offset
  0.00    100.54     0.00      120     0.00     0.00  common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)
  0.00    100.54     0.00      120     0.00     0.00  void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&)
  0.00    100.54     0.00      119     0.00     0.00  std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00      107     0.00     0.00  common_arg::set_examples(std::initializer_list<llama_example>)
  0.00    100.54     0.00      107     0.00     0.00  void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*)
  0.00    100.54     0.00      105     0.00     0.00  string_format[abi:cxx11](char const*, ...)
  0.00    100.54     0.00       96     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&))
  0.00    100.54     0.00       71     0.00     0.00  gguf_kv_to_str(gguf_context const*, int)
  0.00    100.54     0.00       60     0.00     0.00  common_arg::set_env(char const*)
  0.00    100.54     0.00       58     0.00     0.00  gguf_find_key
  0.00    100.54     0.00       50     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&))
  0.00    100.54     0.00       50     0.00     0.00  std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&)
  0.00    100.54     0.00       50     0.00     0.00  std::__throw_regex_error(std::regex_constants::error_type, char const*)
  0.00    100.54     0.00       49     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00       45     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00       40     0.00     0.00  gguf_type_name
  0.00    100.54     0.00       36     0.00     0.00  gguf_get_val_data
  0.00    100.54     0.00       32     0.00     0.00  std::__detail::_Scanner<char>::_M_advance()
  0.00    100.54     0.00       32     0.00     0.00  ggml_tallocr_alloc
  0.00    100.54     0.00       30     0.00     0.00  common_arg::set_sparam()
  0.00    100.54     0.00       30     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long)
  0.00    100.54     0.00       30     0.00     0.00  gguf_get_val_str
  0.00    100.54     0.00       28     0.00     0.00  bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool)
  0.00    100.54     0.00       26     0.00     0.00  void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&)
  0.00    100.54     0.00       25     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char()
  0.00    100.54     0.00       22     0.00     0.00  std::__detail::_Scanner<char>::_M_scan_in_bracket()
  0.00    100.54     0.00       19     0.00     0.00  ggml_backend_dev_count
  0.00    100.54     0.00       18     0.00     0.00  std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&)
  0.00    100.54     0.00       18     0.00     0.00  std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::~vector()
  0.00    100.54     0.00       17     0.00     0.00  std::__cxx11::to_string(int)
  0.00    100.54     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00    100.54     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00    100.54     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00    100.54     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00    100.54     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00    100.54     0.00       16     0.00     0.00  ggml_get_tensor
  0.00    100.54     0.00       16     0.00     0.00  ggml_new_tensor_3d
  0.00    100.54     0.00       16     0.00     0.00  ggml_rope
  0.00    100.54     0.00       15     0.00     0.00  bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)
  0.00    100.54     0.00       13     0.00     0.00  unicode_cpt_flags(unsigned int)
  0.00    100.54     0.00       13     0.00     0.00  gguf_get_val_u32
  0.00    100.54     0.00       12     0.00     0.00  void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&)
  0.00    100.54     0.00       12     0.00     0.00  gguf_get_arr_n
  0.00    100.54     0.00       12     0.00     0.00  llama_sampler_free
  0.00    100.54     0.00       11     0.00     0.00  llama_sampler_chain_n
  0.00    100.54     0.00       10     0.00     0.00  unicode_byte_to_utf8[abi:cxx11](unsigned char)
  0.00    100.54     0.00       10     0.00     0.00  __static_initialization_and_destruction_0()
  0.00    100.54     0.00       10     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const
  0.00    100.54     0.00       10     0.00     0.00  gguf_get_arr_type
  0.00    100.54     0.00       10     0.00     0.00  llama_sampler_chain_add
  0.00    100.54     0.00       10     0.00     0.00  llama_sampler_chain_get
  0.00    100.54     0.00       10     0.00     0.00  llama_sampler_name
  0.00    100.54     0.00       10     0.00     0.00  llama_state_seq_get_size
  0.00    100.54     0.00        9     0.00     0.00  tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool)
  0.00    100.54     0.00        9     0.00     0.00  get_reg()
  0.00    100.54     0.00        9     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int))
  0.00    100.54     0.00        9     0.00     0.00  void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&)
  0.00    100.54     0.00        9     0.00     0.00  void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&)
  0.00    100.54     0.00        8     0.00     0.00  llm_tokenizer_bpe_session::add_new_bigram(int, int)
  0.00    100.54     0.00        8     0.00     0.00  void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&)
  0.00    100.54     0.00        8     0.00     0.00  void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&)
  0.00    100.54     0.00        7     0.00     0.00  string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)
  0.00    100.54     0.00        7     0.00     0.00  common_sampler_type_to_chr(common_sampler_type)
  0.00    100.54     0.00        7     0.00     0.00  common_sampler_type_to_str[abi:cxx11](common_sampler_type)
  0.00    100.54     0.00        7     0.00     0.00  ggml_backend_cpu_device_get_type(ggml_backend_device*)
  0.00    100.54     0.00        7     0.00     0.00  ggml_backend_dev_get
  0.00    100.54     0.00        7     0.00     0.00  ggml_backend_dev_type
  0.00    100.54     0.00        7     0.00     0.00  ggml_get_first_tensor
  0.00    100.54     0.00        6     0.00     0.00  llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const
  0.00    100.54     0.00        6     0.00     0.00  void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&)
  0.00    100.54     0.00        6     0.00     0.00  std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&)
  0.00    100.54     0.00        6     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion()
  0.00    100.54     0.00        6     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression()
  0.00    100.54     0.00        6     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom()
  0.00    100.54     0.00        6     0.00     0.00  ggml_backend_reg_count
  0.00    100.54     0.00        6     0.00     0.00  ggml_type_name
  0.00    100.54     0.00        6     0.00     0.00  gguf_get_arr_data
  0.00    100.54     0.00        5     0.00     0.00  bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool)
  0.00    100.54     0.00        5     0.00     0.00  bool llama_model_loader::get_key<float>(llm_kv, float&, bool)
  0.00    100.54     0.00        5     0.00     0.00  void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&)
  0.00    100.54     0.00        4     0.00     0.00  postprocess_cpu_params(cpu_params&, cpu_params const*)
  0.00    100.54     0.00        4     0.00     0.00  ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long)
  0.00    100.54     0.00        4     0.00     0.00  llama_data_write_file::write(void const*, unsigned long)
  0.00    100.54     0.00        4     0.00     0.00  std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...)
  0.00    100.54     0.00        4     0.00     0.00  void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)
  0.00    100.54     0.00        4     0.00     0.00  std::__detail::_Scanner<char>::_M_scan_normal()
  0.00    100.54     0.00        4     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier()
  0.00    100.54     0.00        4     0.00     0.00  ggml_backend_buft_name
  0.00    100.54     0.00        4     0.00     0.00  ggml_backend_cpu_buffer_type
  0.00    100.54     0.00        4     0.00     0.00  ggml_backend_cpu_reg
  0.00    100.54     0.00        4     0.00     0.00  ggml_backend_reg_dev_get
  0.00    100.54     0.00        4     0.00     0.00  llama_model_has_encoder
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*)
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*)
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*)
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long)
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*)
  0.00    100.54     0.00        3     0.00     0.00  common_arg::has_value_from_env()
  0.00    100.54     0.00        3     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&))
  0.00    100.54     0.00        3     0.00     0.00  std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00        3     0.00     0.00  std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_destroy()
  0.00    100.54     0.00        3     0.00     0.00  std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
  0.00    100.54     0.00        3     0.00     0.00  void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&)
  0.00    100.54     0.00        3     0.00     0.00  void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&)
  0.00    100.54     0.00        3     0.00     0.00  void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&)
  0.00    100.54     0.00        3     0.00     0.00  std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type)
  0.00    100.54     0.00        3     0.00     0.00  std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type)
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready()
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher()
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>)
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>)
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_Scanner<char>::_M_eat_escape_ecma()
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative()
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction()
  0.00    100.54     0.00        3     0.00     0.00  void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool)
  0.00    100.54     0.00        3     0.00     0.00  std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_buffer_name
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_buft_get_alignment
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_dev_buffer_type
  0.00    100.54     0.00        3     0.00     0.00  ggml_backend_dev_by_type
  0.00    100.54     0.00        3     0.00     0.05  ggml_backend_sched_reserve
  0.00    100.54     0.00        3     0.00     0.02  ggml_gallocr_reserve_n
  0.00    100.54     0.00        3     0.00     0.00  ggml_hash_set_free
  0.00    100.54     0.00        3     0.00     0.00  ggml_threadpool_free
  0.00    100.54     0.00        3     0.00     0.00  ggml_threadpool_params_init
  0.00    100.54     0.00        3     0.00     0.00  ggml_time_init
  0.00    100.54     0.00        3     0.00     0.00  iq2xs_free_impl
  0.00    100.54     0.00        2     0.00     0.00  unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&)
  0.00    100.54     0.00        2     0.00     0.00  llama_token_bos_impl(llama_vocab const&)
  0.00    100.54     0.00        2     0.00     0.00  llama_token_eos_impl(llama_vocab const&)
  0.00    100.54     0.00        2     0.00     5.00  llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool)
  0.00    100.54     0.00        2     0.00     0.00  ggml_threadpool_params_from_cpu_params(cpu_params const&)
  0.00    100.54     0.00        2     0.00     0.00  print_usage(int, char**)
  0.00    100.54     0.00        2     0.00     0.00  get_rng_seed(unsigned int)
  0.00    100.54     0.00        2     0.00     0.00  kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_cpu_reg_get_name(ggml_backend_reg*)
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*)
  0.00    100.54     0.00        2     0.00     0.00  unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&)
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*)
  0.00    100.54     0.00        2     0.00     0.00  llama_mmap::unmap_fragment(unsigned long, unsigned long)
  0.00    100.54     0.00        2     0.00     0.00  common_params::~common_params()
  0.00    100.54     0.00        2     0.00     5.00  llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&)
  0.00    100.54     0.00        2     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>)
  0.00    100.54     0.00        2     0.00     0.00  std::_Hashtable<char, char, std::allocator<char>, std::__detail::_Identity, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, true, true> >::_Hashtable<char const*>(char const*, char const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<char> const&, std::integral_constant<bool, true>)
  0.00    100.54     0.00        2     0.00     0.00  std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long)
  0.00    100.54     0.00        2     0.00     0.00  std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long)
  0.00    100.54     0.00        2     0.00     0.00  std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        2     0.00     0.00  std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long)
  0.00    100.54     0.00        2     0.00     0.00  void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>)
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_buffer_is_multi_buffer
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_buffer_set_usage
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_dev_backend_reg
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_free
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_reg_by_name
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_reg_dev_count
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_reg_get
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_reg_get_proc_address
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_reg_name
  0.00    100.54     0.00        2     0.00     0.00  ggml_backend_sched_get_n_splits
  0.00    100.54     0.00        2     0.00     0.00  ggml_fopen
  0.00    100.54     0.00        2     0.00     0.00  ggml_graph_n_nodes
  0.00    100.54     0.00        2     0.00     0.00  ggml_graph_overhead_custom
  0.00    100.54     0.00        2     0.00     0.00  ggml_hash_set_new
  0.00    100.54     0.00        2     0.00     0.00  ggml_set_no_alloc
  0.00    100.54     0.00        2     0.00     0.00  ggml_threadpool_new_impl
  0.00    100.54     0.00        2     0.00     0.00  gguf_get_val_f32
  0.00    100.54     0.00        2     0.00     0.00  llama_model_is_recurrent
  0.00    100.54     0.00        2     0.00     0.00  llama_n_ctx_train
  0.00    100.54     0.00        2     0.00     0.00  llama_supports_rpc
  0.00    100.54     0.00        2     0.00     0.00  llama_token_bos
  0.00    100.54     0.00        2     0.00     0.00  llama_token_eos
  0.00    100.54     0.00        1     0.00     0.00  common_init()
  0.00    100.54     0.00        1     0.00     5.00  common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool)
  0.00    100.54     0.00        1     0.00     5.00  common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool)
  0.00    100.54     0.00        1     0.00     0.00  cpu_get_num_math()
  0.00    100.54     0.00        1     0.00     0.00  common_perf_print(llama_context const*, common_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**))
  0.00    100.54     0.00        1     0.00     0.00  common_sampler_free(common_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  common_sampler_init(llama_model const*, common_sampler_params const&)
  0.00    100.54     0.00        1     0.00     0.00  llama_token_nl_impl(llama_vocab const&)
  0.00    100.54     0.00        1     0.00     5.00  llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool)
  0.00    100.54     0.00        1     0.00     0.00  common_sampler_print[abi:cxx11](common_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  set_process_priority(ggml_sched_priority)
  0.00    100.54     0.00        1     0.00    95.47  common_init_from_params(common_params&)
  0.00    100.54     0.00        1     0.00     0.00  common_sampler_get_seed(common_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_add_bos_token_impl(llama_vocab const&)
  0.00    100.54     0.00        1     0.00     0.00  llama_add_eos_token_impl(llama_vocab const&)
  0.00    100.54     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))
  0.00    100.54     0.00        1     0.00     0.00  common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  common_model_params_to_llama(common_params const&)
  0.00    100.54     0.00        1     0.00     0.00  common_params_get_system_info[abi:cxx11](common_params const&)
  0.00    100.54     0.00        1     0.00     0.00  common_context_params_to_llama(common_params const&)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*)
  0.00    100.54     0.00        1     0.00     0.00  llm_load_arch(llama_model_loader&, llama_model&)
  0.00    100.54     0.00        1     0.00     0.00  write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&)
  0.00    100.54     0.00        1     0.00     0.00  llm_load_hparams(llama_model_loader&, llama_model&)
  0.00    100.54     0.00        1     0.00     0.01  llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_cpu_free(ggml_backend*)
  0.00    100.54     0.00        1     0.00     0.00  llama_model_type_name(e_model)
  0.00    100.54     0.00        1     0.00     0.00  llama_model_ftype_name(llama_ftype)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_dry_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_dry_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_xtc_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_xtc_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_dist_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_dist_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_chain_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_min_p_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_min_p_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_top_k_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_top_k_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_top_p_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_top_p_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_grammar_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_typical_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_typical_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_temp_ext_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_temp_ext_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_penalties_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_penalties_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_logit_bias_free(llama_sampler*)
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_logit_bias_name(llama_sampler const*)
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*)
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*)
  0.00    100.54     0.00        1     0.00    10.68  llama_model::~llama_model()
  0.00    100.54     0.00        1     0.00     0.00  llama_vocab::init_tokenizer()
  0.00    100.54     0.00        1     0.00     0.00  common_params::common_params()
  0.00    100.54     0.00        1     0.00     0.00  llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&)
  0.00    100.54     0.00        1     0.00     0.00  llm_tokenizer_bpe::~llm_tokenizer_bpe()
  0.00    100.54     0.00        1     0.00     0.00  llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*)
  0.00    100.54     0.00        1     0.00     0.00  llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)
  0.00    100.54     0.00        1     0.00     0.01  llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*)
  0.00    100.54     0.00        1     0.00     0.00  common_sampler_params::common_sampler_params(common_sampler_params const&)
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_cpu_device_context::ggml_backend_cpu_device_context()
  0.00    100.54     0.00        1     0.00     0.00  console::init(bool, bool)
  0.00    100.54     0.00        1     0.00     0.00  common_sampler_params::print[abi:cxx11]() const
  0.00    100.54     0.00        1     0.00     0.00  LLM_KV::operator()[abi:cxx11](llm_kv) const
  0.00    100.54     0.00        1     0.00     0.00  std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>)
  0.00    100.54     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00    100.54     0.00        1     0.00     0.00  std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand()
  0.00    100.54     0.00        1     0.00     0.00  std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&)
  0.00    100.54     0.00        1     0.00     0.00  std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map()
  0.00    100.54     0.00        1     0.00     0.00  std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&)
  0.00    100.54     0.00        1     0.00     0.00  std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&)
  0.00    100.54     0.00        1     0.00     0.00  std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&)
  0.00    100.54     0.00        1     0.00     0.00  std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&)
  0.00    100.54     0.00        1     0.00     0.00  std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back()
  0.00    100.54     0.00        1     0.00     0.00  std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector()
  0.00    100.54     0.00        1     0.00     0.00  std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector()
  0.00    100.54     0.00        1     0.00     0.00  std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&)
  0.00    100.54     0.00        1     0.00     0.00  void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&)
  0.00    100.54     0.00        1     0.00     0.00  std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector()
  0.00    100.54     0.00        1     0.00     0.00  void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&)
  0.00    100.54     0.00        1     0.00     0.00  void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&)
  0.00    100.54     0.00        1     0.00     0.00  void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&)
  0.00    100.54     0.00        1     0.00     0.00  void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&)
  0.00    100.54     0.00        1     0.00     0.00  std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long)
  0.00    100.54     0.00        1     0.00     0.00  std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool)
  0.00    100.54     0.00        1     0.00     0.00  common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*)
  0.00    100.54     0.00        1     0.00     0.00  common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*)
  0.00    100.54     0.00        1     0.00     0.00  std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*)
  0.00    100.54     0.00        1     0.00     0.00  void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>)
  0.00    100.54     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00    100.54     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int)
  0.00    100.54     0.00        1     0.00     0.00  llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const
  0.00    100.54     0.00        1     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const
  0.00    100.54     0.00        1     0.00     0.00  alloc_tensor_range
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_alloc_ctx_tensors_from_buft
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_buffer_get_alignment
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_buft_get_max_size
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_cpu_buffer_from_ptr
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_cpu_init
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_dev_buffer_from_host_ptr
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_dev_get_props
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_event_free
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_get_default_buffer_type
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_sched_free
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_sched_get_buffer_size
  0.00    100.54     0.00        1     0.00     0.00  ggml_backend_sched_new
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_amx_int8
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_arm_fma
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_avx
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_avx2
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_avx512
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_avx512_bf16
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_avx512_vbmi
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_avx512_vnni
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_avx_vnni
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_blas
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_fma
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_fp16_va
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_llamafile
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_matmul_int8
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_neon
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_riscv_v
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_sse3
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_ssse3
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_sve
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_vsx
  0.00    100.54     0.00        1     0.00     0.00  ggml_cpu_has_wasm_simd
  0.00    100.54     0.00        1     0.00     0.00  ggml_gallocr_free
  0.00    100.54     0.00        1     0.00     0.00  ggml_gallocr_get_buffer_size
  0.00    100.54     0.00        1     0.00     0.00  ggml_gallocr_new_n
  0.00    100.54     0.00        1     0.00     0.00  ggml_get_max_tensor_size
  0.00    100.54     0.00        1     0.00     0.00  ggml_get_no_alloc
  0.00    100.54     0.00        1     0.00     0.00  ggml_log_set
  0.00    100.54     0.00        1     0.00     0.00  ggml_quantize_free
  0.00    100.54     0.00        1     0.00     0.00  ggml_tallocr_new
  0.00    100.54     0.00        1     0.00     0.00  ggml_threadpool_new
  0.00    100.54     0.00        1     0.00     0.00  ggml_threadpool_params_default
  0.00    100.54     0.00        1     0.00     0.00  ggml_threadpool_params_match
  0.00    100.54     0.00        1     0.00     0.00  gguf_free
  0.00    100.54     0.00        1     0.00     0.00  gguf_get_version
  0.00    100.54     0.00        1     0.00     0.00  gguf_init_from_file
  0.00    100.54     0.00        1     0.00     0.00  iq3xs_free_impl
  0.00    100.54     0.00        1     0.00     0.00  llama_add_bos_token
  0.00    100.54     0.00        1     0.00     0.00  llama_add_eos_token
  0.00    100.54     0.00        1     0.00     0.00  llama_attach_threadpool
  0.00    100.54     0.00        1     0.00     0.00  llama_backend_free
  0.00    100.54     0.00        1     0.00     0.00  llama_backend_init
  0.00    100.54     0.00        1     0.00     0.00  llama_context_default_params
  0.00    100.54     0.00        1     0.00     0.00  llama_free
  0.00    100.54     0.00        1     0.00    10.68  llama_free_model
  0.00    100.54     0.00        1     0.00     0.00  llama_kv_cache_clear
  0.00    100.54     0.00        1     0.00    95.02  llama_load_model_from_file
  0.00    100.54     0.00        1     0.00     0.00  llama_log_set
  0.00    100.54     0.00        1     0.00     0.00  llama_lora_adapter_clear
  0.00    100.54     0.00        1     0.00     0.00  llama_model_default_params
  0.00    100.54     0.00        1     0.00     0.00  llama_model_has_decoder
  0.00    100.54     0.00        1     0.00     0.00  llama_n_ctx
  0.00    100.54     0.00        1     0.00     0.23  llama_new_context_with_model
  0.00    100.54     0.00        1     0.00     0.00  llama_numa_init
  0.00    100.54     0.00        1     0.00     0.00  llama_perf_context
  0.00    100.54     0.00        1     0.00     0.00  llama_perf_context_print
  0.00    100.54     0.00        1     0.00     0.00  llama_perf_context_reset
  0.00    100.54     0.00        1     0.00     0.00  llama_perf_sampler
  0.00    100.54     0.00        1     0.00     0.00  llama_perf_sampler_print
  0.00    100.54     0.00        1     0.00     0.00  llama_print_system_info
  0.00    100.54     0.00        1     0.00     0.00  llama_rope_type
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_chain_default_params
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_chain_init
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_get_seed
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_dist
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_dry
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_grammar
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_logit_bias
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_min_p
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_penalties
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_temp_ext
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_top_k
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_top_p
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_typical
  0.00    100.54     0.00        1     0.00     0.00  llama_sampler_init_xtc
  0.00    100.54     0.00        1     0.00     0.00  llama_supports_gpu_offload
  0.00    100.54     0.00        1     0.00     0.00  llama_token_nl
  0.00    100.54     0.00        1     0.00     0.00  llama_tokenize

 %         the percentage of the total running time of the
time       program used by this function.

cumulative a running sum of the number of seconds accounted
 seconds   for by this function and those listed above it.

 self      the number of seconds accounted for by this
seconds    function alone.  This is the major sort for this
           listing.

calls      the number of times this function was invoked, if
           this function is profiled, else blank.

 self      the average number of milliseconds spent in this
ms/call    function per call, if this function is profiled,
	   else blank.

 total     the average number of milliseconds spent in this
ms/call    function and its descendents per call, if this
	   function is profiled, else blank.

name       the name of the function.  This is the minor sort
           for this listing. The index shows the location of
	   the function in the gprof listing. If the index is
	   in parenthesis it shows where it would appear in
	   the gprof listing if it were to be printed.

Copyright (C) 2012-2024 Free Software Foundation, Inc.

Copying and distribution of this file, with or without modification,
are permitted in any medium without royalty provided the copyright
notice and this notice are preserved.

		     Call graph (explanation follows)


granularity: each sample hit covers 2 byte(s) for 0.01% of 100.54 seconds

index % time    self  children    called     name
                             1231021             ggml_compute_forward [1]
[1]     99.3    0.15   99.65       0+1231021 ggml_compute_forward [1]
                0.69   98.54  274781/274781      ggml_compute_forward_mul_mat [2]
                0.06    0.05   36360/36360       ggml_compute_forward_soft_max [14]
                0.10    0.00  102629/102629      ggml_compute_forward_dup [15]
                0.09    0.00   81218/81218       ggml_compute_forward_rope_f32 [20]
                0.04    0.00  125350/125350      ggml_compute_forward_mul [28]
                0.04    0.00   88828/88828       ggml_compute_forward_rms_norm [29]
                0.02    0.00   40460/40460       ggml_compute_forward_unary [36]
                0.01    0.00   80551/80551       ggml_compute_forward_add [49]
                0.00    0.00 1248228/1756974     ggml_is_empty [130]
                0.00    0.00    7090/7090        ggml_compute_forward_get_rows [172]
                0.00    0.00    1802/168713      ggml_is_numa [154]
                             1231021             ggml_compute_forward [1]
-----------------------------------------------
                0.69   98.54  274781/274781      ggml_compute_forward [1]
[2]     98.7    0.69   98.54  274781         ggml_compute_forward_mul_mat [2]
               90.04    0.00 108017432/108017432     ggml_vec_dot_q4_0_q8_0_esp_riscv [3]
                6.23    0.00 11219832/11219832     ggml_vec_dot_q6_K_q8_K [4]
                1.29    0.00 1401498/1401498     ggml_vec_dot_q4_1_q8_1 [5]
                0.63    0.00 13516431/13516431     ggml_vec_dot_f16 [6]
                0.00    0.22  495424/495424      llamafile_sgemm [9]
                0.08    0.00   38450/38450       quantize_row_q8_0 [21]
                0.02    0.00  335700/380136      ggml_fp32_to_fp16_row [35]
                0.01    0.01 2157950/2354340     ggml_is_contiguous_0 [40]
                0.01    0.00     341/341         quantize_row_q8_K_ref [50]
                0.00    0.01 2806942/3176310     ggml_row_size [63]
                0.00    0.00 1969366/8736023     ggml_type_size [48]
                0.00    0.00  483774/9977911     ggml_blck_size [60]
                0.00    0.00 2216660/2412793     ggml_is_contiguous [129]
                0.00    0.00 1654012/1654012     ggml_n_dims [131]
                0.00    0.00  506847/570742      ggml_get_type_traits [135]
                0.00    0.00  166397/168713      ggml_is_numa [154]
                0.00    0.00     685/685         quantize_row_q8_1 [196]
                0.00    0.00     305/305         quantize_row_q8_K [215]
-----------------------------------------------
               90.04    0.00 108017432/108017432     ggml_compute_forward_mul_mat [2]
[3]     89.6   90.04    0.00 108017432         ggml_vec_dot_q4_0_q8_0_esp_riscv [3]
-----------------------------------------------
                6.23    0.00 11219832/11219832     ggml_compute_forward_mul_mat [2]
[4]      6.2    6.23    0.00 11219832         ggml_vec_dot_q6_K_q8_K [4]
-----------------------------------------------
                1.29    0.00 1401498/1401498     ggml_compute_forward_mul_mat [2]
[5]      1.3    1.29    0.00 1401498         ggml_vec_dot_q4_1_q8_1 [5]
-----------------------------------------------
                0.63    0.00 13516431/13516431     ggml_compute_forward_mul_mat [2]
[6]      0.6    0.63    0.00 13516431         ggml_vec_dot_f16 [6]
-----------------------------------------------
                                                 <spontaneous>
[7]      0.3    0.00    0.33                 main [7]
                0.00    0.11     512/513         llama_decode [12]
                0.04    0.06     512/512         common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
                0.00    0.10       1/1           common_init_from_params(common_params&) [17]
                0.00    0.01       1/1           llama_free_model [45]
                0.00    0.01     517/517         common_sampler_accept(common_sampler*, int, bool) [53]
                0.00    0.01       1/1           common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [65]
                0.00    0.00    1026/1026        llama_token_is_eog_impl(llama_vocab const&, int) [984]
                0.00    0.00    1026/1026        llama_token_is_eog [191]
                0.00    0.00     529/962         common_log_main() [991]
                0.00    0.00     529/962         common_log_add(common_log*, ggml_log_level, char const*, ...) [990]
                0.00    0.00     517/517         common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [999]
                0.00    0.00     514/515         console::set_display(console::display_t) [1004]
                0.00    0.00     513/513         common_sampler_last(common_sampler const*) [1008]
                0.00    0.00     512/513         llama_batch_get_one [211]
                0.00    0.00      18/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1055]
                0.00    0.00       2/2           ggml_threadpool_params_from_cpu_params(cpu_params const&) [1127]
                0.00    0.00       2/2           print_usage(int, char**) [1128]
                0.00    0.00       2/4           llama_model_has_encoder [253]
                0.00    0.00       2/3           ggml_threadpool_free [259]
                0.00    0.00       1/1           common_params::common_params() [1195]
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
                0.00    0.00       1/2           common_params::~common_params() [1136]
                0.00    0.00       1/1           common_init() [1144]
                0.00    0.00       1/1           console::init(bool, bool) [1200]
                0.00    0.00       1/1           llama_numa_init [343]
                0.00    0.00       1/1731        ggml_free [180]
                0.00    0.00       1/1           llama_backend_init [334]
                0.00    0.00       1/1           set_process_priority(ggml_sched_priority) [1152]
                0.00    0.00       1/1           ggml_threadpool_params_match [326]
                0.00    0.00       1/2           ggml_threadpool_new_impl [278]
                0.00    0.00       1/1           ggml_threadpool_new [324]
                0.00    0.00       1/1           llama_attach_threadpool [332]
                0.00    0.00       1/2           llama_n_ctx_train [281]
                0.00    0.00       1/1           llama_n_ctx [342]
                0.00    0.00       1/1           llama_add_bos_token_impl(llama_vocab const&) [1154]
                0.00    0.00       1/1           llama_add_bos_token [330]
                0.00    0.00       1/1           std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector() [1219]
                0.00    0.00       1/1           std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector() [1222]
                0.00    0.00       1/1           common_params_get_system_info[abi:cxx11](common_params const&) [1160]
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
                0.00    0.00       1/1           llama_add_eos_token_impl(llama_vocab const&) [1155]
                0.00    0.00       1/1           llama_add_eos_token [331]
                0.00    0.00       1/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00       1/1           llama_perf_context_print [345]
                0.00    0.00       1/1           common_perf_print(llama_context const*, common_sampler const*) [1146]
                0.00    0.00       1/1           write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&) [1164]
                0.00    0.00       1/1           llama_free [336]
                0.00    0.00       1/1           common_sampler_free(common_sampler*) [1148]
                0.00    0.00       1/2246        ggml_critical_section_end [177]
                0.00    0.00       1/1           ggml_quantize_free [322]
                0.00    0.00       1/1           llama_backend_free [333]
                0.00    0.00       1/705         ggml_aligned_free [194]
                0.00    0.00       1/1           std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector() [1227]
                0.00    0.00       1/1           llama_sampler_get_seed [353]
                0.00    0.00       1/1           common_sampler_get_seed(common_sampler const*) [1153]
                0.00    0.00       1/1           common_sampler_params::print[abi:cxx11]() const [1201]
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
-----------------------------------------------
                                                 <spontaneous>
[8]      0.3    0.26    0.00                 _init [8]
-----------------------------------------------
                0.00    0.22  495424/495424      ggml_compute_forward_mul_mat [2]
[9]      0.2    0.00    0.22  495424         llamafile_sgemm [9]
                0.00    0.22    1036/1036        (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [10]
                0.00    0.00    1012/1012        (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [989]
-----------------------------------------------
                0.00    0.22    1036/1036        llamafile_sgemm [9]
[10]     0.2    0.00    0.22    1036         (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [10]
                0.19    0.00    1061/1061        void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long) [11]
                0.03    0.00     609/609         void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long) [34]
-----------------------------------------------
                0.19    0.00    1061/1061        (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [10]
[11]     0.2    0.19    0.00    1061         void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long) [11]
-----------------------------------------------
                0.00    0.00       1/513         common_init_from_params(common_params&) [17]
                0.00    0.11     512/513         main [7]
[12]     0.1    0.00    0.11     513         llama_decode [12]
                0.02    0.09     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
-----------------------------------------------
                0.02    0.09     513/513         llama_decode [12]
[13]     0.1    0.02    0.09     513         llama_decode_internal(llama_context&, llama_batch) [13]
                0.00    0.03     513/513         ggml_backend_sched_alloc_graph [31]
                0.02    0.00     513/531         llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [38]
                0.01    0.00     513/1029        ggml_backend_sched_get_tensor_backend [32]
                0.00    0.01     513/516         llama_build_graph(llama_context&, llama_ubatch const&, bool) [41]
                0.01    0.00     513/513         llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) [56]
                0.00    0.00     513/513         ggml_backend_sched_graph_compute_async [81]
                0.00    0.00     513/534         llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00     513/513         ggml_backend_tensor_get [106]
                0.00    0.00     513/513         ggml_backend_tensor_get_async [107]
                0.00    0.00    1032/1033        std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [983]
                0.00    0.00    1026/1030        ggml_backend_sched_reset [187]
                0.00    0.00    1026/1026        ggml_graph_node [190]
                0.00    0.00     515/515         std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long) [1005]
                0.00    0.00     515/515         std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long) [1006]
                0.00    0.00     513/514         llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00     513/513         llama_kv_cache_update [212]
                0.00    0.00     513/513         ggml_backend_sched_set_eval_callback [209]
                0.00    0.00     513/513         ggml_backend_cpu_set_threadpool [207]
                0.00    0.00     513/513         ggml_backend_cpu_set_abort_callback [205]
                0.00    0.00     513/513         ggml_backend_cpu_set_n_threads [206]
                0.00    0.00     513/513         ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long) [1009]
                0.00    0.00     513/515         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [1003]
                0.00    0.00     513/3091        ggml_time_us [176]
-----------------------------------------------
                0.06    0.05   36360/36360       ggml_compute_forward [1]
[14]     0.1    0.06    0.05   36360         ggml_compute_forward_soft_max [14]
                0.05    0.00  181214/181214      ggml_vec_soft_max_f32 [27]
                0.00    0.00   35055/370587      ggml_nrows [141]
-----------------------------------------------
                0.10    0.00  102629/102629      ggml_compute_forward [1]
[15]     0.1    0.10    0.00  102629         ggml_compute_forward_dup [15]
                0.00    0.00   44436/380136      ggml_fp32_to_fp16_row [35]
                0.00    0.00  163366/2354340     ggml_is_contiguous_0 [40]
                0.00    0.00   31191/9977911     ggml_blck_size [60]
                0.00    0.00   26334/8736023     ggml_type_size [48]
                0.00    0.00  261323/400857      ggml_nelements [138]
                0.00    0.00  163109/2412793     ggml_is_contiguous [129]
                0.00    0.00   62111/570742      ggml_get_type_traits [135]
-----------------------------------------------
                0.04    0.06     512/512         main [7]
[16]     0.1    0.04    0.06     512         common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
                0.00    0.06     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.00    1024/6144        llama_sampler_apply [174]
                0.00    0.00     512/512         llama_get_logits_ith [214]
                0.00    0.00     512/1030        llama_get_model [188]
                0.00    0.00     512/514         llama_n_vocab [203]
                0.00    0.00     512/512         llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*) [1015]
                0.00    0.00       1/1           std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long) [1221]
-----------------------------------------------
                0.00    0.10       1/1           main [7]
[17]     0.1    0.00    0.10       1         common_init_from_params(common_params&) [17]
                0.00    0.10       1/1           llama_load_model_from_file [18]
                0.00    0.00       1/1           llama_new_context_with_model [80]
                0.00    0.00       1/513         llama_decode [12]
                0.00    0.00       2/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1055]
                0.00    0.00       1/1           common_model_params_to_llama(common_params const&) [1159]
                0.00    0.00       1/1           common_context_params_to_llama(common_params const&) [1161]
                0.00    0.00       1/962         common_log_main() [991]
                0.00    0.00       1/962         common_log_add(common_log*, ggml_log_level, char const*, ...) [990]
                0.00    0.00       1/2           llama_token_bos_impl(llama_vocab const&) [1125]
                0.00    0.00       1/2           llama_token_bos [283]
                0.00    0.00       1/2           llama_token_eos_impl(llama_vocab const&) [1126]
                0.00    0.00       1/2           llama_token_eos [284]
                0.00    0.00       1/4           llama_model_has_encoder [253]
                0.00    0.00       1/1           llama_model_has_decoder [341]
                0.00    0.00       1/513         llama_batch_get_one [211]
                0.00    0.00       1/1           llama_kv_cache_clear [337]
                0.00    0.00       1/1           llama_perf_context_reset [346]
                0.00    0.00       1/513         llama_synchronize [213]
                0.00    0.00       1/1           common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1157]
-----------------------------------------------
                0.00    0.10       1/1           common_init_from_params(common_params&) [17]
[18]     0.1    0.00    0.10       1         llama_load_model_from_file [18]
                0.01    0.09       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00      52/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00       7/528         llama_format_tensor_shape(ggml_tensor const*) [995]
                0.00    0.00       6/71          gguf_kv_to_str(gguf_context const*, int) [1044]
                0.00    0.00       2/19          ggml_backend_dev_count [232]
                0.00    0.00       2/3091        ggml_time_us [176]
                0.00    0.00       1/3           ggml_time_init [261]
                0.00    0.00       1/7           ggml_backend_dev_get [243]
                0.00    0.00       1/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1083]
                0.00    0.00       1/7           ggml_backend_dev_type [244]
                0.00    0.00       1/1           llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00       1/1           llm_load_arch(llama_model_loader&, llama_model&) [1163]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1209]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1204]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1205]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1206]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1207]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1208]
                0.00    0.00       1/1           llama_model_type_name(e_model) [1167]
                0.00    0.00       1/1           llama_model_ftype_name(llama_ftype) [1168]
                0.00    0.00       1/1731        ggml_free [180]
                0.00    0.00       1/1           gguf_free [327]
-----------------------------------------------
                0.01    0.09       1/1           llama_load_model_from_file [18]
[19]     0.1    0.01    0.09       1         llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.07    0.00  280147/280147      std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&) [23]
                0.01    0.00  128256/128256      std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [52]
                0.00    0.01       1/2           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [58]
                0.00    0.00       1/534         llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00  560294/560310      std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) [970]
                0.00    0.00  408403/816820      gguf_get_arr_str [133]
                0.00    0.00  387158/387162      bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [973]
                0.00    0.00  280147/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [972]
                0.00    0.00  130099/130616      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [980]
                0.00    0.00  130099/130616      llama_token_to_piece [155]
                0.00    0.00     256/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00      25/522         format(char const*, ...) [997]
                0.00    0.00      18/28          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
                0.00    0.00       4/10          llama_state_seq_get_size [242]
                0.00    0.00       4/5           bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1090]
                0.00    0.00       4/58          gguf_find_key [228]
                0.00    0.00       2/12          gguf_get_arr_n [235]
                0.00    0.00       2/520         std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [998]
                0.00    0.00       1/6           gguf_get_arr_data [248]
                0.00    0.00       1/1           llama_vocab::init_tokenizer() [1194]
                0.00    0.00       1/528         llama_format_tensor_shape(ggml_tensor const*) [995]
                0.00    0.00       1/1           void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1237]
                0.00    0.00       1/2           void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1143]
                0.00    0.00       1/1           std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long) [1224]
                0.00    0.00       1/1           LLM_KV::operator()[abi:cxx11](llm_kv) const [1202]
-----------------------------------------------
                0.09    0.00   81218/81218       ggml_compute_forward [1]
[20]     0.1    0.09    0.00   81218         ggml_compute_forward_rope_f32 [20]
                0.00    0.00   79884/79884       ggml_rope_cache_init [158]
                0.00    0.00   79873/370587      ggml_nrows [141]
                0.00    0.00   79347/79347       ggml_rope_yarn_corr_dims [159]
-----------------------------------------------
                0.08    0.00   38450/38450       ggml_compute_forward_mul_mat [2]
[21]     0.1    0.08    0.00   38450         quantize_row_q8_0 [21]
-----------------------------------------------
                                                 <spontaneous>
[22]     0.1    0.07    0.00                 ggml_vec_mad_f32_unroll [22]
-----------------------------------------------
                0.07    0.00  280147/280147      llm_load_vocab(llama_model_loader&, llama_model&) [19]
[23]     0.1    0.07    0.00  280147         std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&) [23]
-----------------------------------------------
                0.00    0.06     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[24]     0.1    0.00    0.06     512         llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
                0.04    0.02     512/512         void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) [26]
                0.00    0.00   19968/104421      void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) [37]
-----------------------------------------------
                0.00    0.06     512/512         common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
[25]     0.1    0.00    0.06     512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.06     512/512         llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
                0.00    0.00    5120/6144        llama_sampler_apply [174]
                0.00    0.00    1024/3091        ggml_time_us [176]
                0.00    0.00     512/512         llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1011]
                0.00    0.00     512/512         llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*) [1017]
                0.00    0.00     512/1024        llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [986]
                0.00    0.00     512/512         llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*) [1012]
                0.00    0.00     512/512         llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) [1014]
                0.00    0.00     512/512         llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*) [1016]
                0.00    0.00     512/512         llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*) [1013]
                0.00    0.00     512/512         llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*) [1010]
                0.00    0.00     512/512         llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*) [1018]
                0.00    0.00     512/512         llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*) [1019]
-----------------------------------------------
                0.04    0.02     512/512         llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
[26]     0.1    0.04    0.02     512         void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) [26]
                0.02    0.00   84453/104421      void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) [37]
-----------------------------------------------
                0.05    0.00  181214/181214      ggml_compute_forward_soft_max [14]
[27]     0.0    0.05    0.00  181214         ggml_vec_soft_max_f32 [27]
-----------------------------------------------
                0.04    0.00  125350/125350      ggml_compute_forward [1]
[28]     0.0    0.04    0.00  125350         ggml_compute_forward_mul [28]
                0.00    0.00  125817/370587      ggml_nrows [141]
                0.00    0.00  125593/296028      ggml_are_same_shape [144]
                0.00    0.00  125408/247815      ggml_can_repeat [147]
-----------------------------------------------
                0.04    0.00   88828/88828       ggml_compute_forward [1]
[29]     0.0    0.04    0.00   88828         ggml_compute_forward_rms_norm [29]
                0.00    0.00   89765/296028      ggml_are_same_shape [144]
-----------------------------------------------
                                                 <spontaneous>
[30]     0.0    0.04    0.00                 print_gemm_cfg [30]
-----------------------------------------------
                0.00    0.03     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[31]     0.0    0.00    0.03     513         ggml_backend_sched_alloc_graph [31]
                0.01    0.01     513/513         ggml_gallocr_alloc_graph [39]
                0.01    0.00     513/1029        ggml_backend_sched_get_tensor_backend [32]
                0.00    0.00     513/1731        ggml_free [180]
                0.00    0.00     513/1730        ggml_init [181]
-----------------------------------------------
                0.00    0.00       3/1029        ggml_backend_sched_reserve [90]
                0.01    0.00     513/1029        ggml_backend_sched_alloc_graph [31]
                0.01    0.00     513/1029        llama_decode_internal(llama_context&, llama_batch) [13]
[32]     0.0    0.03    0.00    1029         ggml_backend_sched_get_tensor_backend [32]
                0.00    0.00  345268/345268      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
                0.00    0.00   84172/318551      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [975]
                0.00    0.00   84172/318551      ggml_backend_dev_supports_op [142]
                0.00    0.00   84172/318372      ggml_backend_supports_op [143]
                0.00    0.00     516/516         ggml_graph_view [200]
-----------------------------------------------
                                                 <spontaneous>
[33]     0.0    0.03    0.00                 ggml_vec_dot_q5_K_q8_K [33]
-----------------------------------------------
                0.03    0.00     609/609         (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [10]
[34]     0.0    0.03    0.00     609         void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long) [34]
-----------------------------------------------
                0.00    0.00   44436/380136      ggml_compute_forward_dup [15]
                0.02    0.00  335700/380136      ggml_compute_forward_mul_mat [2]
[35]     0.0    0.02    0.00  380136         ggml_fp32_to_fp16_row [35]
                0.00    0.00  395043/395044      ggml_cpu_has_f16c [139]
-----------------------------------------------
                0.02    0.00   40460/40460       ggml_compute_forward [1]
[36]     0.0    0.02    0.00   40460         ggml_compute_forward_unary [36]
                0.00    0.00   40917/49125       ggml_get_unary_op [161]
                0.00    0.00   40756/370587      ggml_nrows [141]
-----------------------------------------------
                0.00    0.00   19968/104421      llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
                0.02    0.00   84453/104421      void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) [26]
[37]     0.0    0.02    0.00  104421         void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) [37]
-----------------------------------------------
                               46885             llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [38]
                0.00    0.00      18/531         llama_vocab::~llama_vocab() [47]
                0.02    0.00     513/531         llama_decode_internal(llama_context&, llama_batch) [13]
[38]     0.0    0.02    0.00     531+46885   llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [38]
                0.00    0.00       2/2           std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long) [1141]
                               46885             llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [38]
-----------------------------------------------
                0.01    0.01     513/513         ggml_backend_sched_alloc_graph [31]
[39]     0.0    0.01    0.01     513         ggml_gallocr_alloc_graph [39]
                0.01    0.00  417582/693095      ggml_nbytes [44]
                0.00    0.00  177498/177677      ggml_backend_tensor_alloc [67]
                0.00    0.00  417582/599166      ggml_backend_buft_get_alloc_size [134]
                0.00    0.00  267786/267965      ggml_backend_buffer_init_tensor [146]
                0.00    0.00  177498/533399      ggml_backend_buffer_get_base [136]
                0.00    0.00   90288/90288       ggml_backend_view_init [157]
                0.00    0.00     513/513         ggml_backend_buffer_reset [204]
-----------------------------------------------
                0.00    0.00   16512/2354340     ggml_reshape_3d [74]
                0.00    0.00   16512/2354340     ggml_soft_max_ext [89]
                0.00    0.00  163366/2354340     ggml_compute_forward_dup [15]
                0.01    0.01 2157950/2354340     ggml_compute_forward_mul_mat [2]
[40]     0.0    0.01    0.01 2354340         ggml_is_contiguous_0 [40]
                0.01    0.00 5277471/9977911     ggml_blck_size [60]
                0.00    0.00 2507689/8736023     ggml_type_size [48]
-----------------------------------------------
                0.00    0.00       3/516         llama_new_context_with_model [80]
                0.00    0.01     513/516         llama_decode_internal(llama_context&, llama_batch) [13]
[41]     0.0    0.00    0.01     516         llama_build_graph(llama_context&, llama_ubatch const&, bool) [41]
                0.00    0.01     516/516         llm_build_context::build_llama() [42]
                0.00    0.00     516/1730        ggml_init [181]
                0.00    0.00     516/1731        ggml_free [180]
                0.00    0.00     516/516         std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1002]
-----------------------------------------------
                0.00    0.01     516/516         llama_build_graph(llama_context&, llama_ubatch const&, bool) [41]
[42]     0.0    0.00    0.01     516         llm_build_context::build_llama() [42]
                0.00    0.01   16512/16512       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
                0.00    0.00   16512/16512       ggml_reshape_3d [74]
                0.00    0.00   25284/58308       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [79]
                0.00    0.00     516/50052       ggml_build_forward_expand [62]
                0.00    0.00   17028/17028       ggml_rms_norm [92]
                0.00    0.00   17028/25317       ggml_mul [91]
                0.00    0.00   16512/16512       ggml_add [94]
                0.00    0.00   16512/16528       ggml_rope_ext [93]
                0.00    0.00    1032/1629        ggml_new_tensor_1d [108]
                0.00    0.00     516/516         std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [111]
                0.00    0.00    1032/1549        ggml_get_rows [109]
                0.00    0.00     516/549         ggml_new_tensor_2d [114]
                0.00    0.00  110424/235296      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00    1548/2064        ggml_set_input [179]
                0.00    0.00     516/516         ggml_new_graph_custom [201]
-----------------------------------------------
                0.00    0.01   16512/16512       llm_build_context::build_llama() [42]
[43]     0.0    0.00    0.01   16512         llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
                0.00    0.01   33024/50052       ggml_build_forward_expand [62]
                0.00    0.00    8256/8256        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.00    8256/8256        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
                0.00    0.00   24768/58308       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [79]
                0.00    0.00    8256/8256        ggml_unary [96]
                0.00    0.00    8256/25317       ggml_mul [91]
                0.00    0.00   41280/235296      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00    8256/8256        ggml_silu [171]
-----------------------------------------------
                0.00    0.00      32/693095      ggml_tallocr_alloc [121]
                0.00    0.00      32/693095      ggml_backend_alloc_ctx_tensors_from_buft [116]
                0.00    0.00      32/693095      llama_new_context_with_model [80]
                0.00    0.00     147/693095      ggml_get_max_tensor_size [112]
                0.00    0.00     147/693095      llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00     147/693095      llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [113]
                0.00    0.00     147/693095      llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00     441/693095      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00     513/693095      ggml_backend_tensor_get [106]
                0.00    0.00     513/693095      ggml_backend_tensor_get_async [107]
                0.00    0.00     693/693095      ggml_graph_compute_with_ctx [104]
                0.00    0.00     696/693095      ggml_gallocr_allocate_node [103]
                0.00    0.00    1026/693095      ggml_backend_tensor_set [101]
                0.00    0.00    2454/693095      ggml_gallocr_reserve_n [95]
                0.00    0.00    8256/693095      ggml_new_tensor_impl.constprop.2 [84]
                0.00    0.00    8256/693095      ggml_new_tensor_impl.constprop.3 [85]
                0.00    0.00   33024/693095      ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   41280/693095      ggml_new_tensor_impl.constprop.0 [70]
                0.00    0.00  177677/693095      ggml_backend_tensor_alloc [67]
                0.01    0.00  417582/693095      ggml_gallocr_alloc_graph [39]
[44]     0.0    0.01    0.00  693095         ggml_nbytes [44]
                0.00    0.00  692191/8736023     ggml_type_size [48]
                0.00    0.00  693095/9977911     ggml_blck_size [60]
-----------------------------------------------
                0.00    0.01       1/1           main [7]
[45]     0.0    0.00    0.01       1         llama_free_model [45]
                0.00    0.01       1/1           llama_model::~llama_model() [46]
-----------------------------------------------
                0.00    0.01       1/1           llama_free_model [45]
[46]     0.0    0.00    0.01       1         llama_model::~llama_model() [46]
                0.01    0.00       1/1           llama_vocab::~llama_vocab() [47]
                0.00    0.00       1/184         ggml_backend_buffer_free [217]
                0.00    0.00       1/1731        ggml_free [180]
-----------------------------------------------
                0.01    0.00       1/1           llama_model::~llama_model() [46]
[47]     0.0    0.01    0.00       1         llama_vocab::~llama_vocab() [47]
                0.00    0.00      18/531         llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [38]
                0.00    0.00       1/1           llm_tokenizer_bpe::~llm_tokenizer_bpe() [1197]
-----------------------------------------------
                0.00    0.00    1026/8736023     llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00    8256/8736023     ggml_new_tensor_impl.constprop.2 [84]
                0.00    0.00    8256/8736023     ggml_new_tensor_impl.constprop.3 [85]
                0.00    0.00    8256/8736023     ggml_is_contiguous_1 [99]
                0.00    0.00   16512/8736023     llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
                0.00    0.00   16512/8736023     llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.00   24624/8736023     ggml_graph_plan [82]
                0.00    0.00   26334/8736023     ggml_compute_forward_dup [15]
                0.00    0.00   33024/8736023     ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   41280/8736023     ggml_new_tensor_impl.constprop.0 [70]
                0.00    0.00  179252/8736023     ggml_new_tensor [72]
                0.00    0.00  692191/8736023     ggml_nbytes [44]
                0.00    0.00 1969366/8736023     ggml_compute_forward_mul_mat [2]
                0.00    0.00 2507689/8736023     ggml_is_contiguous_0 [40]
                0.00    0.00 3203445/8736023     ggml_row_size [63]
[48]     0.0    0.01    0.00 8736023         ggml_type_size [48]
-----------------------------------------------
                0.01    0.00   80551/80551       ggml_compute_forward [1]
[49]     0.0    0.01    0.00   80551         ggml_compute_forward_add [49]
                0.00    0.00   80878/370587      ggml_nrows [141]
                0.00    0.00   80670/296028      ggml_are_same_shape [144]
                0.00    0.00   80578/247815      ggml_can_repeat [147]
-----------------------------------------------
                0.01    0.00     341/341         ggml_compute_forward_mul_mat [2]
[50]     0.0    0.01    0.00     341         quantize_row_q8_K_ref [50]
-----------------------------------------------
                                                 <spontaneous>
[51]     0.0    0.01    0.00                 ggml_backend_alloc_ctx_tensors [51]
-----------------------------------------------
                0.01    0.00  128256/128256      llm_load_vocab(llama_model_loader&, llama_model&) [19]
[52]     0.0    0.01    0.00  128256         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [52]
                0.00    0.00  128256/128256      std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long) [982]
-----------------------------------------------
                0.00    0.01     517/517         main [7]
[53]     0.0    0.00    0.01     517         common_sampler_accept(common_sampler*, int, bool) [53]
                0.00    0.01     517/517         llama_sampler_chain_accept(llama_sampler*, int) [54]
                0.00    0.00    1029/6199        llama_sampler_accept [173]
                0.00    0.00     512/512         llama_sampler_grammar_accept_impl(llama_sampler*, int) [1020]
-----------------------------------------------
                0.00    0.01     517/517         common_sampler_accept(common_sampler*, int, bool) [53]
[54]     0.0    0.00    0.01     517         llama_sampler_chain_accept(llama_sampler*, int) [54]
                0.01    0.00     517/517         llama_sampler_penalties_accept(llama_sampler*, int) [55]
                0.00    0.00    5170/6199        llama_sampler_accept [173]
                0.00    0.00    1034/3091        ggml_time_us [176]
                0.00    0.00     517/517         llama_sampler_dry_accept(llama_sampler*, int) [1000]
-----------------------------------------------
                0.01    0.00     517/517         llama_sampler_chain_accept(llama_sampler*, int) [54]
[55]     0.0    0.01    0.00     517         llama_sampler_penalties_accept(llama_sampler*, int) [55]
-----------------------------------------------
                0.01    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[56]     0.0    0.01    0.00     513         llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) [56]
                0.00    0.00     518/520         std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [998]
-----------------------------------------------
                0.01    0.00       6/6           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
[57]     0.0    0.01    0.00       6         unicode_len_utf8(char) [57]
-----------------------------------------------
                0.00    0.01       1/2           llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.01       1/2           llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [66]
[58]     0.0    0.00    0.01       2         llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [58]
                0.00    0.01       2/2           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
                0.00    0.00       2/9           tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1072]
                0.00    0.00       1/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1055]
-----------------------------------------------
                0.00    0.01       2/2           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [58]
[59]     0.0    0.00    0.01       2         llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
                0.01    0.00       6/6           unicode_len_utf8(char) [57]
                0.00    0.00      10/10          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1071]
                0.00    0.00       9/9           void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&) [1075]
                0.00    0.00       8/8           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1077]
                0.00    0.00       5/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1055]
                0.00    0.00       3/9           tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1072]
                0.00    0.00       2/2           unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
-----------------------------------------------
                0.00    0.00       2/9977911     llama_new_context_with_model [80]
                0.00    0.00     294/9977911     gguf_init_from_file [118]
                0.00    0.00    8256/9977911     ggml_new_tensor_impl.constprop.2 [84]
                0.00    0.00    8256/9977911     ggml_new_tensor_impl.constprop.3 [85]
                0.00    0.00   16512/9977911     ggml_is_contiguous_1 [99]
                0.00    0.00   31191/9977911     ggml_compute_forward_dup [15]
                0.00    0.00   33024/9977911     ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   41280/9977911     ggml_new_tensor_impl.constprop.0 [70]
                0.00    0.00  179252/9977911     ggml_new_tensor [72]
                0.00    0.00  483774/9977911     ggml_compute_forward_mul_mat [2]
                0.00    0.00  693095/9977911     ggml_nbytes [44]
                0.00    0.00 3205504/9977911     ggml_row_size [63]
                0.01    0.00 5277471/9977911     ggml_is_contiguous_0 [40]
[60]     0.0    0.01    0.00 9977911         ggml_blck_size [60]
-----------------------------------------------
                              334884             ggml_visit_parents [61]
                0.01    0.00  108360/108360      ggml_build_forward_expand [62]
[61]     0.0    0.01    0.00  108360+334884  ggml_visit_parents [61]
                0.00    0.00    1032/372584      ggml_format_name [140]
                              334884             ggml_visit_parents [61]
-----------------------------------------------
                0.00    0.00     516/50052       llm_build_context::build_llama() [42]
                0.00    0.00    8256/50052       llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
                0.00    0.00    8256/50052       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.01   33024/50052       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
[62]     0.0    0.00    0.01   50052         ggml_build_forward_expand [62]
                0.01    0.00  108360/108360      ggml_visit_parents [61]
-----------------------------------------------
                0.00    0.00     147/3176310     gguf_init_from_file [118]
                0.00    0.00    8256/3176310     ggml_new_tensor_impl.constprop.2 [84]
                0.00    0.00    8256/3176310     ggml_new_tensor_impl.constprop.3 [85]
                0.00    0.00    8256/3176310     llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
                0.00    0.00   16512/3176310     llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.00   33024/3176310     ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   41280/3176310     ggml_new_tensor_impl.constprop.0 [70]
                0.00    0.00   74385/3176310     ggml_graph_plan [82]
                0.00    0.00  179252/3176310     ggml_new_tensor [72]
                0.00    0.01 2806942/3176310     ggml_compute_forward_mul_mat [2]
[63]     0.0    0.00    0.01 3176310         ggml_row_size [63]
                0.00    0.00 3203445/8736023     ggml_type_size [48]
                0.00    0.00 3205504/9977911     ggml_blck_size [60]
-----------------------------------------------
                0.00    0.01       1/1           common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [65]
[64]     0.0    0.00    0.01       1         common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [64]
                0.00    0.01       1/1           llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [66]
                0.00    0.00       1/1           llama_tokenize [367]
-----------------------------------------------
                0.00    0.01       1/1           main [7]
[65]     0.0    0.00    0.01       1         common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [65]
                0.00    0.01       1/1           common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [64]
                0.00    0.00       1/1030        llama_get_model [188]
-----------------------------------------------
                0.00    0.01       1/1           common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [64]
[66]     0.0    0.00    0.01       1         llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [66]
                0.00    0.01       1/2           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [58]
-----------------------------------------------
                0.00    0.00      32/177677      alloc_tensor_range [119]
                0.00    0.00     147/177677      llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00  177498/177677      ggml_gallocr_alloc_graph [39]
[67]     0.0    0.00    0.00  177677         ggml_backend_tensor_alloc [67]
                0.00    0.00  177677/693095      ggml_nbytes [44]
                0.00    0.00  355354/533399      ggml_backend_buffer_get_base [136]
                0.00    0.00  177677/599166      ggml_backend_buft_get_alloc_size [134]
                0.00    0.00  177677/177709      ggml_backend_buffer_get_alloc_size [153]
                0.00    0.00  177677/178228      ggml_backend_buffer_get_size [152]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
[68]     0.0    0.00    0.00    8256         llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.00    8256/50052       ggml_build_forward_expand [62]
                0.00    0.00   16512/16512       ggml_permute [76]
                0.00    0.00   16512/16512       ggml_view_3d [77]
                0.00    0.00    8256/8256        ggml_soft_max_ext [89]
                0.00    0.00   16512/74933       ggml_mul_mat [78]
                0.00    0.00   16512/3176310     ggml_row_size [63]
                0.00    0.00    8256/8256        ggml_cont_4d [98]
                0.00    0.00    8256/58308       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [79]
                0.00    0.00   16512/8736023     ggml_type_size [48]
                0.00    0.00   66048/235296      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00   16512/34050       ggml_element_size [162]
                0.00    0.00    8256/8256        ggml_mul_mat_set_prec [170]
                0.00    0.00    8256/8256        ggml_cont_2d [168]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
[69]     0.0    0.00    0.00    8256         llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
                0.00    0.00    8256/50052       ggml_build_forward_expand [62]
                0.00    0.00   16512/16512       ggml_cpy [75]
                0.00    0.00    8256/8256        ggml_view_1d [87]
                0.00    0.00    8256/8256        ggml_view_2d [88]
                0.00    0.00    8256/8256        ggml_transpose [86]
                0.00    0.00   16512/8736023     ggml_type_size [48]
                0.00    0.00    8256/3176310     ggml_row_size [63]
                0.00    0.00   16512/235296      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00   16512/34050       ggml_element_size [162]
-----------------------------------------------
                0.00    0.00   41280/41280       ggml_view_tensor [71]
[70]     0.0    0.00    0.00   41280         ggml_new_tensor_impl.constprop.0 [70]
                0.00    0.00   41280/693095      ggml_nbytes [44]
                0.00    0.00   41280/3176310     ggml_row_size [63]
                0.00    0.00   41280/8736023     ggml_type_size [48]
                0.00    0.00   41280/9977911     ggml_blck_size [60]
                0.00    0.00   41280/270584      ggml_new_object [145]
-----------------------------------------------
                0.00    0.00    8256/41280       ggml_transpose [86]
                0.00    0.00   16512/41280       ggml_cpy [75]
                0.00    0.00   16512/41280       ggml_permute [76]
[71]     0.0    0.00    0.00   41280         ggml_view_tensor [71]
                0.00    0.00   41280/41280       ggml_new_tensor_impl.constprop.0 [70]
                0.00    0.00   41280/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00      16/179252      ggml_new_tensor_3d [125]
                0.00    0.00      16/179252      ggml_rope [126]
                0.00    0.00     147/179252      gguf_init_from_file [118]
                0.00    0.00     147/179252      llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [120]
                0.00    0.00     549/179252      ggml_new_tensor_2d [114]
                0.00    0.00    1629/179252      ggml_new_tensor_1d [108]
                0.00    0.00    8256/179252      ggml_soft_max_ext [89]
                0.00    0.00    8256/179252      ggml_unary [96]
                0.00    0.00    9918/179252      ggml_new_tensor_4d [97]
                0.00    0.00   16512/179252      ggml_add [94]
                0.00    0.00   16528/179252      ggml_rope_ext [93]
                0.00    0.00   17028/179252      ggml_rms_norm [92]
                0.00    0.00   25317/179252      ggml_mul [91]
                0.00    0.00   74933/179252      ggml_mul_mat [78]
[72]     0.0    0.00    0.00  179252         ggml_new_tensor [72]
                0.00    0.00  179252/3176310     ggml_row_size [63]
                0.00    0.00  179252/8736023     ggml_type_size [48]
                0.00    0.00  179252/9977911     ggml_blck_size [60]
                0.00    0.00  179252/270584      ggml_new_object [145]
-----------------------------------------------
                0.00    0.00   16512/33024       ggml_reshape_3d [74]
                0.00    0.00   16512/33024       ggml_view_3d [77]
[73]     0.0    0.00    0.00   33024         ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   33024/693095      ggml_nbytes [44]
                0.00    0.00   33024/3176310     ggml_row_size [63]
                0.00    0.00   33024/8736023     ggml_type_size [48]
                0.00    0.00   33024/9977911     ggml_blck_size [60]
                0.00    0.00   33024/270584      ggml_new_object [145]
-----------------------------------------------
                0.00    0.00   16512/16512       llm_build_context::build_llama() [42]
[74]     0.0    0.00    0.00   16512         ggml_reshape_3d [74]
                0.00    0.00   16512/33024       ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   16512/2354340     ggml_is_contiguous_0 [40]
                0.00    0.00   16512/2412793     ggml_is_contiguous [129]
                0.00    0.00   16512/400857      ggml_nelements [138]
                0.00    0.00   16512/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00   16512/16512       llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
[75]     0.0    0.00    0.00   16512         ggml_cpy [75]
                0.00    0.00   16512/41280       ggml_view_tensor [71]
                0.00    0.00   33024/400857      ggml_nelements [138]
                0.00    0.00   16512/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00   16512/16512       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
[76]     0.0    0.00    0.00   16512         ggml_permute [76]
                0.00    0.00   16512/41280       ggml_view_tensor [71]
                0.00    0.00   16512/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00   16512/16512       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
[77]     0.0    0.00    0.00   16512         ggml_view_3d [77]
                0.00    0.00   16512/33024       ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   16512/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00     113/74933       weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00   16512/74933       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.00   58308/74933       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [79]
[78]     0.0    0.00    0.00   74933         ggml_mul_mat [78]
                0.00    0.00   74933/179252      ggml_new_tensor [72]
                0.00    0.00   74933/74933       ggml_is_transposed [160]
-----------------------------------------------
                0.00    0.00    8256/58308       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.00   24768/58308       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
                0.00    0.00   25284/58308       llm_build_context::build_llama() [42]
[79]     0.0    0.00    0.00   58308         llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [79]
                0.00    0.00   58308/74933       ggml_mul_mat [78]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [17]
[80]     0.0    0.00    0.00       1         llama_new_context_with_model [80]
                0.00    0.00       3/3           ggml_backend_sched_reserve [90]
                0.00    0.00       3/516         llama_build_graph(llama_context&, llama_ubatch const&, bool) [41]
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [116]
                0.00    0.00      32/693095      ggml_nbytes [44]
                0.00    0.00      64/1629        ggml_new_tensor_1d [108]
                0.00    0.00      16/16          ggml_rope [126]
                0.00    0.00       2/9977911     ggml_blck_size [60]
                0.00    0.00      32/372584      ggml_format_name [140]
                0.00    0.00      18/184         ggml_tensor_overhead [218]
                0.00    0.00      17/1730        ggml_init [181]
                0.00    0.00      16/182         ggml_backend_buft_alloc_buffer [220]
                0.00    0.00      16/318551      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [975]
                0.00    0.00      16/318551      ggml_backend_dev_supports_op [142]
                0.00    0.00      16/1731        ggml_free [180]
                0.00    0.00      16/184         ggml_backend_buffer_free [217]
                0.00    0.00      15/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00       3/3           ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*) [1101]
                0.00    0.00       3/4           ggml_backend_buft_name [249]
                0.00    0.00       3/178228      ggml_backend_buffer_get_size [152]
                0.00    0.00       2/2           llama_model_is_recurrent [280]
                0.00    0.00       2/19          ggml_backend_dev_count [232]
                0.00    0.00       2/2           std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long) [1139]
                0.00    0.00       2/3           ggml_backend_buffer_name [254]
                0.00    0.00       2/6           ggml_type_name [247]
                0.00    0.00       2/2           ggml_backend_sched_get_n_splits [272]
                0.00    0.00       2/2           ggml_graph_n_nodes [274]
                0.00    0.00       1/32833       ggml_is_quantized [163]
                0.00    0.00       1/4           llama_model_has_encoder [253]
                0.00    0.00       1/7           ggml_backend_dev_get [243]
                0.00    0.00       1/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1083]
                0.00    0.00       1/7           ggml_backend_dev_type [244]
                0.00    0.00       1/1           ggml_backend_cpu_init [288]
                0.00    0.00       1/16449       ggml_backend_get_device [165]
                0.00    0.00       1/2           ggml_backend_dev_backend_reg [265]
                0.00    0.00       1/2           ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) [1132]
                0.00    0.00       1/2           ggml_backend_reg_get_proc_address [270]
                0.00    0.00       1/516         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [1001]
                0.00    0.00       1/516         ggml_backend_buffer_clear [197]
                0.00    0.00       1/528         llama_format_tensor_shape(ggml_tensor const*) [995]
                0.00    0.00       1/515         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [1003]
                0.00    0.00       1/514         llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00       1/1541        ggml_guid_matches [184]
                0.00    0.00       1/1541        ggml_backend_is_cpu [183]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [250]
                0.00    0.00       1/3           ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) [1102]
                0.00    0.00       1/3           ggml_backend_dev_buffer_type [256]
                0.00    0.00       1/1           ggml_backend_get_default_buffer_type [292]
                0.00    0.00       1/2           ggml_graph_overhead_custom [275]
                0.00    0.00       1/1           ggml_backend_sched_new [295]
                0.00    0.00       1/2           llama_token_bos_impl(llama_vocab const&) [1125]
                0.00    0.00       1/2           llama_token_bos [283]
                0.00    0.00       1/1           ggml_gallocr_get_buffer_size [318]
                0.00    0.00       1/1           ggml_backend_sched_get_buffer_size [294]
                0.00    0.00       1/1           void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&) [1230]
                0.00    0.00       1/1           std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long) [1218]
                0.00    0.00       1/3           void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1111]
                0.00    0.00       1/1           std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long) [1232]
                0.00    0.00       1/1           void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&) [1229]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[81]     0.0    0.00    0.00     513         ggml_backend_sched_graph_compute_async [81]
                0.00    0.00     513/513         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [83]
                0.00    0.00     513/513         ggml_backend_graph_compute_async [208]
-----------------------------------------------
                0.00    0.00     513/513         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [83]
[82]     0.0    0.00    0.00     513         ggml_graph_plan [82]
                0.00    0.00   74385/3176310     ggml_row_size [63]
                0.00    0.00   24624/8736023     ggml_type_size [48]
                0.00    0.00  265734/1756974     ggml_is_empty [130]
                0.00    0.00   74385/400857      ggml_nelements [138]
                0.00    0.00   32832/32833       ggml_is_quantized [163]
                0.00    0.00    8208/370587      ggml_nrows [141]
                0.00    0.00    8208/49125       ggml_get_unary_op [161]
-----------------------------------------------
                0.00    0.00     513/513         ggml_backend_sched_graph_compute_async [81]
[83]     0.0    0.00    0.00     513         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [83]
                0.00    0.00     513/513         ggml_graph_plan [82]
                0.00    0.00     513/513         ggml_graph_compute [210]
-----------------------------------------------
                0.00    0.00    8256/8256        ggml_view_2d [88]
[84]     0.0    0.00    0.00    8256         ggml_new_tensor_impl.constprop.2 [84]
                0.00    0.00    8256/693095      ggml_nbytes [44]
                0.00    0.00    8256/3176310     ggml_row_size [63]
                0.00    0.00    8256/8736023     ggml_type_size [48]
                0.00    0.00    8256/9977911     ggml_blck_size [60]
                0.00    0.00    8256/270584      ggml_new_object [145]
-----------------------------------------------
                0.00    0.00    8256/8256        ggml_view_1d [87]
[85]     0.0    0.00    0.00    8256         ggml_new_tensor_impl.constprop.3 [85]
                0.00    0.00    8256/693095      ggml_nbytes [44]
                0.00    0.00    8256/3176310     ggml_row_size [63]
                0.00    0.00    8256/8736023     ggml_type_size [48]
                0.00    0.00    8256/9977911     ggml_blck_size [60]
                0.00    0.00    8256/270584      ggml_new_object [145]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
[86]     0.0    0.00    0.00    8256         ggml_transpose [86]
                0.00    0.00    8256/41280       ggml_view_tensor [71]
                0.00    0.00    8256/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
[87]     0.0    0.00    0.00    8256         ggml_view_1d [87]
                0.00    0.00    8256/8256        ggml_new_tensor_impl.constprop.3 [85]
                0.00    0.00    8256/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
[88]     0.0    0.00    0.00    8256         ggml_view_2d [88]
                0.00    0.00    8256/8256        ggml_new_tensor_impl.constprop.2 [84]
                0.00    0.00    8256/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
[89]     0.0    0.00    0.00    8256         ggml_soft_max_ext [89]
                0.00    0.00   16512/2354340     ggml_is_contiguous_0 [40]
                0.00    0.00    8256/179252      ggml_new_tensor [72]
                0.00    0.00   16512/2412793     ggml_is_contiguous [129]
                0.00    0.00    8256/8256        ggml_is_matrix [169]
                0.00    0.00    8256/92060       ggml_dup_tensor [156]
-----------------------------------------------
                0.00    0.00       3/3           llama_new_context_with_model [80]
[90]     0.0    0.00    0.00       3         ggml_backend_sched_reserve [90]
                0.00    0.00       3/1029        ggml_backend_sched_get_tensor_backend [32]
                0.00    0.00       3/3           ggml_gallocr_reserve_n [95]
                0.00    0.00       3/1731        ggml_free [180]
                0.00    0.00       3/1730        ggml_init [181]
                0.00    0.00       3/516         ggml_backend_sched_synchronize [198]
                0.00    0.00       3/1030        ggml_backend_sched_reset [187]
-----------------------------------------------
                0.00    0.00      33/25317       weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00    8256/25317       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
                0.00    0.00   17028/25317       llm_build_context::build_llama() [42]
[91]     0.0    0.00    0.00   25317         ggml_mul [91]
                0.00    0.00   25317/179252      ggml_new_tensor [72]
                0.00    0.00   25317/247815      ggml_can_repeat [147]
                0.00    0.00   25317/92060       ggml_dup_tensor [156]
-----------------------------------------------
                0.00    0.00   17028/17028       llm_build_context::build_llama() [42]
[92]     0.0    0.00    0.00   17028         ggml_rms_norm [92]
                0.00    0.00   17028/179252      ggml_new_tensor [72]
                0.00    0.00   17028/92060       ggml_dup_tensor [156]
-----------------------------------------------
                0.00    0.00      16/16528       weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00   16512/16528       llm_build_context::build_llama() [42]
[93]     0.0    0.00    0.00   16528         ggml_rope_ext [93]
                0.00    0.00   16528/179252      ggml_new_tensor [72]
                0.00    0.00   16528/16544       ggml_is_vector [164]
                0.00    0.00   16528/92060       ggml_dup_tensor [156]
-----------------------------------------------
                0.00    0.00   16512/16512       llm_build_context::build_llama() [42]
[94]     0.0    0.00    0.00   16512         ggml_add [94]
                0.00    0.00   16512/179252      ggml_new_tensor [72]
                0.00    0.00   16512/247815      ggml_can_repeat [147]
                0.00    0.00   16512/92060       ggml_dup_tensor [156]
-----------------------------------------------
                0.00    0.00       3/3           ggml_backend_sched_reserve [90]
[95]     0.0    0.00    0.00       3         ggml_gallocr_reserve_n [95]
                0.00    0.00    2454/693095      ggml_nbytes [44]
                0.00    0.00    4833/4833        ggml_gallocr_allocate_node [103]
                0.00    0.00     693/693         ggml_graph_compute_with_ctx [104]
                0.00    0.00    2454/599166      ggml_backend_buft_get_alloc_size [134]
                0.00    0.00       3/1036        ggml_hash_set_reset [185]
                0.00    0.00       2/178228      ggml_backend_buffer_get_size [152]
                0.00    0.00       1/184         ggml_backend_buffer_free [217]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1103]
                0.00    0.00       1/182         ggml_backend_buft_alloc_buffer [220]
                0.00    0.00       1/2           ggml_backend_buffer_set_usage [264]
                0.00    0.00       1/3           ggml_hash_set_free [258]
                0.00    0.00       1/2           ggml_hash_set_new [276]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
[96]     0.0    0.00    0.00    8256         ggml_unary [96]
                0.00    0.00    8256/179252      ggml_new_tensor [72]
                0.00    0.00    8256/8256        ggml_is_contiguous_1 [99]
                0.00    0.00    8256/92060       ggml_dup_tensor [156]
-----------------------------------------------
                0.00    0.00     113/9918        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00    1549/9918        ggml_get_rows [109]
                0.00    0.00    8256/9918        ggml_cont_4d [98]
[97]     0.0    0.00    0.00    9918         ggml_new_tensor_4d [97]
                0.00    0.00    9918/179252      ggml_new_tensor [72]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
[98]     0.0    0.00    0.00    8256         ggml_cont_4d [98]
                0.00    0.00    8256/9918        ggml_new_tensor_4d [97]
                0.00    0.00    8256/400857      ggml_nelements [138]
                0.00    0.00    8256/372584      ggml_format_name [140]
-----------------------------------------------
                0.00    0.00    8256/8256        ggml_unary [96]
[99]     0.0    0.00    0.00    8256         ggml_is_contiguous_1 [99]
                0.00    0.00   16512/9977911     ggml_blck_size [60]
                0.00    0.00    8256/8736023     ggml_type_size [48]
-----------------------------------------------
                                   2             llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00       1/534         llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00       2/534         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       2/534         std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::~map() [127]
                0.00    0.00       5/534         std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [123]
                0.00    0.00       5/534         std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::~map() [124]
                0.00    0.00       6/534         std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::~map() [122]
                0.00    0.00     513/534         llama_decode_internal(llama_context&, llama_batch) [13]
[100]    0.0    0.00    0.00     534+2       llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00    1026/1026        ggml_backend_tensor_set [101]
                0.00    0.00    1026/8736023     ggml_type_size [48]
                0.00    0.00    1026/34050       ggml_element_size [162]
                0.00    0.00    1026/1026        ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long) [985]
                0.00    0.00    1026/218779      ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [977]
                0.00    0.00    1026/218779      ggml_backend_buft_is_host [148]
                0.00    0.00    1026/1026        ggml_backend_buffer_is_host [189]
                                   2             llama_set_inputs(llama_context&, llama_ubatch const&) [100]
-----------------------------------------------
                0.00    0.00    1026/1026        llama_set_inputs(llama_context&, llama_ubatch const&) [100]
[101]    0.0    0.00    0.00    1026         ggml_backend_tensor_set [101]
                0.00    0.00    1026/693095      ggml_nbytes [44]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[102]    0.0    0.00    0.00       1         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/1           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00     147/693095      ggml_nbytes [44]
                0.00    0.00       1/1           llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [113]
                0.00    0.00       1/1           ggml_get_max_tensor_size [112]
                0.00    0.00     276/276         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
                0.00    0.00       2/534         llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00     294/799         ggml_get_next_tensor [192]
                0.00    0.00     294/735         ggml_get_name [193]
                0.00    0.00       9/9           void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&) [1076]
                0.00    0.00       4/19          ggml_backend_dev_count [232]
                0.00    0.00       3/7           ggml_get_first_tensor [245]
                0.00    0.00       2/7           ggml_backend_dev_get [243]
                0.00    0.00       2/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1083]
                0.00    0.00       2/7           ggml_backend_dev_type [244]
                0.00    0.00       2/3           ggml_backend_dev_by_type [257]
                0.00    0.00       2/4           ggml_backend_cpu_buffer_type [250]
                0.00    0.00       2/3           ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) [1102]
                0.00    0.00       2/3           ggml_backend_dev_buffer_type [256]
                0.00    0.00       1/2           ggml_backend_dev_backend_reg [265]
                0.00    0.00       1/2           ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) [1132]
                0.00    0.00       1/2           ggml_backend_reg_get_proc_address [270]
                0.00    0.00       1/184         ggml_tensor_overhead [218]
                0.00    0.00       1/1           void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&) [1231]
                0.00    0.00       1/1           std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long) [1217]
                0.00    0.00       1/1           std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long) [1223]
                0.00    0.00       1/2           std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [1140]
                0.00    0.00       1/164         ggml_backend_buft_get_device [221]
                0.00    0.00       1/1           ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*) [1191]
                0.00    0.00       1/1           ggml_backend_dev_get_props [290]
                0.00    0.00       1/2           ggml_backend_buffer_set_usage [264]
                0.00    0.00       1/2           void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1143]
                0.00    0.00       1/2           llama_supports_rpc [282]
                0.00    0.00       1/1           llama_supports_gpu_offload [365]
                0.00    0.00       1/1           ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*) [1193]
                0.00    0.00       1/4           ggml_backend_buft_name [249]
                0.00    0.00       1/3           ggml_backend_buffer_name [254]
                0.00    0.00       1/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00       1/178228      ggml_backend_buffer_get_size [152]
                0.00    0.00       1/515         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [1003]
                0.00    0.00       1/1           ggml_backend_cpu_buffer_from_ptr [287]
                0.00    0.00       1/1           ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long) [1192]
                0.00    0.00       1/1           ggml_backend_dev_buffer_from_host_ptr [289]
-----------------------------------------------
                0.00    0.00    4833/4833        ggml_gallocr_reserve_n [95]
[103]    0.0    0.00    0.00    4833         ggml_gallocr_allocate_node [103]
                0.00    0.00     696/693095      ggml_nbytes [44]
                0.00    0.00     696/599166      ggml_backend_buft_get_alloc_size [134]
-----------------------------------------------
                0.00    0.00     693/693         ggml_gallocr_reserve_n [95]
[104]    0.0    0.00    0.00     693         ggml_graph_compute_with_ctx [104]
                0.00    0.00     693/693095      ggml_nbytes [44]
                0.00    0.00     693/599166      ggml_backend_buft_get_alloc_size [134]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[105]    0.0    0.00    0.00       1         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00     441/693095      ggml_nbytes [44]
                0.00    0.00       1/1           gguf_init_from_file [118]
                0.00    0.00       1/1           std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [123]
                0.00    0.00     147/147         std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1036]
                0.00    0.00     147/400857      ggml_nelements [138]
                0.00    0.00     147/735         ggml_get_name [193]
                0.00    0.00     147/147         gguf_find_tensor [224]
                0.00    0.00     147/147         gguf_get_data_offset [225]
                0.00    0.00     147/147         gguf_get_tensor_offset [227]
                0.00    0.00     147/147         std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&) [1035]
                0.00    0.00     147/799         ggml_get_next_tensor [192]
                0.00    0.00      41/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00      40/40          gguf_type_name [229]
                0.00    0.00      35/71          gguf_kv_to_str(gguf_context const*, int) [1044]
                0.00    0.00      35/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
                0.00    0.00      35/1613        gguf_get_key [182]
                0.00    0.00      35/158         gguf_get_kv_type [223]
                0.00    0.00      14/522         format(char const*, ...) [997]
                0.00    0.00       5/12          gguf_get_arr_n [235]
                0.00    0.00       5/10          gguf_get_arr_type [238]
                0.00    0.00       4/4           llama_data_write_file::write(void const*, unsigned long) [1095]
                0.00    0.00       4/6           ggml_type_name [247]
                0.00    0.00       2/58          gguf_find_key [228]
                0.00    0.00       1/10          llama_state_seq_get_size [242]
                0.00    0.00       1/2           ggml_fopen [273]
                0.00    0.00       1/7           ggml_get_first_tensor [245]
                0.00    0.00       1/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1049]
                0.00    0.00       1/818795      gguf_get_n_kv [132]
                0.00    0.00       1/1           gguf_get_version [328]
                0.00    0.00       1/1           void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&) [1228]
                0.00    0.00       1/3           void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1111]
                0.00    0.00       1/13          gguf_get_val_u32 [234]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[106]    0.0    0.00    0.00     513         ggml_backend_tensor_get [106]
                0.00    0.00     513/693095      ggml_nbytes [44]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[107]    0.0    0.00    0.00     513         ggml_backend_tensor_get_async [107]
                0.00    0.00     513/693095      ggml_nbytes [44]
-----------------------------------------------
                0.00    0.00      17/1629        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00      64/1629        llama_new_context_with_model [80]
                0.00    0.00     516/1629        std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [111]
                0.00    0.00    1032/1629        llm_build_context::build_llama() [42]
[108]    0.0    0.00    0.00    1629         ggml_new_tensor_1d [108]
                0.00    0.00    1629/179252      ggml_new_tensor [72]
-----------------------------------------------
                0.00    0.00       1/1549        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00     516/1549        std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [111]
                0.00    0.00    1032/1549        llm_build_context::build_llama() [42]
[109]    0.0    0.00    0.00    1549         ggml_get_rows [109]
                0.00    0.00    1549/9918        ggml_new_tensor_4d [97]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[110]    0.0    0.00    0.00       1         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00     147/693095      ggml_nbytes [44]
                0.00    0.00     147/177677      ggml_backend_tensor_alloc [67]
                0.00    0.00     148/148         llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) [1034]
                0.00    0.00     147/735         ggml_get_name [193]
                0.00    0.00     147/799         ggml_get_next_tensor [192]
                0.00    0.00     147/267965      ggml_backend_buffer_init_tensor [146]
                0.00    0.00       2/2           llama_mmap::unmap_fragment(unsigned long, unsigned long) [1135]
                0.00    0.00       1/1           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const [1241]
                0.00    0.00       1/7           ggml_get_first_tensor [245]
                0.00    0.00       1/2           ggml_backend_free [266]
-----------------------------------------------
                0.00    0.00     516/516         llm_build_context::build_llama() [42]
[111]    0.0    0.00    0.00     516         std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [111]
                0.00    0.00     516/1629        ggml_new_tensor_1d [108]
                0.00    0.00     516/1549        ggml_get_rows [109]
                0.00    0.00    1032/235296      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00     516/2064        ggml_set_input [179]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[112]    0.0    0.00    0.00       1         ggml_get_max_tensor_size [112]
                0.00    0.00     147/693095      ggml_nbytes [44]
                0.00    0.00     147/799         ggml_get_next_tensor [192]
                0.00    0.00       1/7           ggml_get_first_tensor [245]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[113]    0.0    0.00    0.00       1         llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [113]
                0.00    0.00     147/693095      ggml_nbytes [44]
                0.00    0.00       1/2           std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [1140]
                0.00    0.00       1/168713      ggml_is_numa [154]
-----------------------------------------------
                0.00    0.00      33/549         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00     516/549         llm_build_context::build_llama() [42]
[114]    0.0    0.00    0.00     549         ggml_new_tensor_2d [114]
                0.00    0.00     549/179252      ggml_new_tensor [72]
-----------------------------------------------
                0.00    0.00     276/276         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[115]    0.0    0.00    0.00     276         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
                0.00    0.00     163/163         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00     147/147         llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [120]
                0.00    0.00     439/522         format(char const*, ...) [997]
                0.00    0.00     163/164         ggml_backend_buft_get_device [221]
                0.00    0.00     163/164         ggml_backend_dev_host_buffer_type [222]
                0.00    0.00      16/16          ggml_get_tensor [233]
                0.00    0.00       1/1730        ggml_init [181]
                0.00    0.00       1/528         llama_format_tensor_shape(ggml_tensor const*) [995]
                0.00    0.00       1/3           void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1111]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[116]    0.0    0.00    0.00       1         ggml_backend_alloc_ctx_tensors_from_buft [116]
                0.00    0.00       1/1           alloc_tensor_range [119]
                0.00    0.00      32/693095      ggml_nbytes [44]
                0.00    0.00      32/799         ggml_get_next_tensor [192]
                0.00    0.00      32/599166      ggml_backend_buft_get_alloc_size [134]
                0.00    0.00       1/1           ggml_get_no_alloc [320]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1104]
                0.00    0.00       1/3           ggml_backend_buft_get_alignment [255]
                0.00    0.00       1/1           ggml_backend_buft_get_max_size [286]
                0.00    0.00       1/7           ggml_get_first_tensor [245]
-----------------------------------------------
                0.00    0.00     163/163         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
[117]    0.0    0.00    0.00     163         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00     113/9918        ggml_new_tensor_4d [97]
                0.00    0.00     113/74933       ggml_mul_mat [78]
                0.00    0.00      33/549         ggml_new_tensor_2d [114]
                0.00    0.00      33/25317       ggml_mul [91]
                0.00    0.00      17/1629        ggml_new_tensor_1d [108]
                0.00    0.00      16/16          ggml_new_tensor_3d [125]
                0.00    0.00      16/16528       ggml_rope_ext [93]
                0.00    0.00       1/1549        ggml_get_rows [109]
                0.00    0.00     163/184         ggml_tensor_overhead [218]
                0.00    0.00     163/1730        ggml_init [181]
                0.00    0.00     163/318551      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [975]
                0.00    0.00     163/318551      ggml_backend_dev_supports_op [142]
                0.00    0.00     163/182         ggml_backend_buft_alloc_buffer [220]
                0.00    0.00     163/184         ggml_backend_buffer_free [217]
                0.00    0.00     163/1731        ggml_free [180]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[118]    0.0    0.00    0.00       1         gguf_init_from_file [118]
                0.00    0.00     147/179252      ggml_new_tensor [72]
                0.00    0.00     147/3176310     ggml_row_size [63]
                0.00    0.00     294/9977911     ggml_blck_size [60]
                0.00    0.00  408611/408611      gguf_fread_str [137]
                0.00    0.00     147/4422        ggml_set_name [175]
                0.00    0.00       2/184         ggml_tensor_overhead [218]
                0.00    0.00       2/2           ggml_set_no_alloc [277]
                0.00    0.00       1/2           ggml_fopen [273]
                0.00    0.00       1/58          gguf_find_key [228]
                0.00    0.00       1/1730        ggml_init [181]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [116]
[119]    0.0    0.00    0.00       1         alloc_tensor_range [119]
                0.00    0.00      32/32          ggml_tallocr_alloc [121]
                0.00    0.00      32/177677      ggml_backend_tensor_alloc [67]
                0.00    0.00      32/799         ggml_get_next_tensor [192]
                0.00    0.00      32/267965      ggml_backend_buffer_init_tensor [146]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1103]
                0.00    0.00       1/182         ggml_backend_buft_alloc_buffer [220]
                0.00    0.00       1/1           ggml_tallocr_new [323]
-----------------------------------------------
                0.00    0.00     147/147         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
[120]    0.0    0.00    0.00     147         llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [120]
                0.00    0.00     147/179252      ggml_new_tensor [72]
                0.00    0.00     147/92060       ggml_dup_tensor [156]
                0.00    0.00     147/735         ggml_get_name [193]
                0.00    0.00     147/4422        ggml_set_name [175]
-----------------------------------------------
                0.00    0.00      32/32          alloc_tensor_range [119]
[121]    0.0    0.00    0.00      32         ggml_tallocr_alloc [121]
                0.00    0.00      32/693095      ggml_nbytes [44]
                0.00    0.00      32/599166      ggml_backend_buft_get_alloc_size [134]
                0.00    0.00      32/177709      ggml_backend_buffer_get_alloc_size [153]
                0.00    0.00      32/178228      ggml_backend_buffer_get_size [152]
                0.00    0.00      32/533399      ggml_backend_buffer_get_base [136]
-----------------------------------------------
                                                 <spontaneous>
[122]    0.0    0.00    0.00                 std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::~map() [122]
                0.00    0.00       6/534         llama_set_inputs(llama_context&, llama_ubatch const&) [100]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[123]    0.0    0.00    0.00       1         std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [123]
                0.00    0.00       5/534         llama_set_inputs(llama_context&, llama_ubatch const&) [100]
-----------------------------------------------
                                                 <spontaneous>
[124]    0.0    0.00    0.00                 std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::~map() [124]
                0.00    0.00       5/534         llama_set_inputs(llama_context&, llama_ubatch const&) [100]
-----------------------------------------------
                0.00    0.00      16/16          weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
[125]    0.0    0.00    0.00      16         ggml_new_tensor_3d [125]
                0.00    0.00      16/179252      ggml_new_tensor [72]
-----------------------------------------------
                0.00    0.00      16/16          llama_new_context_with_model [80]
[126]    0.0    0.00    0.00      16         ggml_rope [126]
                0.00    0.00      16/179252      ggml_new_tensor [72]
                0.00    0.00      16/16544       ggml_is_vector [164]
                0.00    0.00      16/92060       ggml_dup_tensor [156]
-----------------------------------------------
                                                 <spontaneous>
[127]    0.0    0.00    0.00                 std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::~map() [127]
                0.00    0.00       2/534         llama_set_inputs(llama_context&, llama_ubatch const&) [100]
-----------------------------------------------
[128]    0.0    0.00    0.00       2+11      <cycle 1 as a whole> [128]
                0.00    0.00      12             llama_sampler_free <cycle 1> [236]
                0.00    0.00       1             llama_sampler_chain_free(llama_sampler*) <cycle 1> [1175]
-----------------------------------------------
                0.00    0.00   16512/2412793     ggml_reshape_3d [74]
                0.00    0.00   16512/2412793     ggml_soft_max_ext [89]
                0.00    0.00  163109/2412793     ggml_compute_forward_dup [15]
                0.00    0.00 2216660/2412793     ggml_compute_forward_mul_mat [2]
[129]    0.0    0.00    0.00 2412793         ggml_is_contiguous [129]
-----------------------------------------------
                0.00    0.00  243012/1756974     ggml_can_repeat [147]
                0.00    0.00  265734/1756974     ggml_graph_plan [82]
                0.00    0.00 1248228/1756974     ggml_compute_forward [1]
[130]    0.0    0.00    0.00 1756974         ggml_is_empty [130]
-----------------------------------------------
                0.00    0.00 1654012/1654012     ggml_compute_forward_mul_mat [2]
[131]    0.0    0.00    0.00 1654012         ggml_n_dims [131]
-----------------------------------------------
                0.00    0.00       1/818795      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00       2/818795      gguf_get_val_f32 [279]
                0.00    0.00       6/818795      gguf_get_arr_data [248]
                0.00    0.00      10/818795      gguf_get_arr_type [238]
                0.00    0.00      12/818795      gguf_get_arr_n [235]
                0.00    0.00      13/818795      gguf_get_val_u32 [234]
                0.00    0.00      30/818795      gguf_get_val_str [231]
                0.00    0.00      36/818795      gguf_get_val_data [230]
                0.00    0.00      36/818795      llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00      58/818795      gguf_find_key [228]
                0.00    0.00     158/818795      gguf_get_kv_type [223]
                0.00    0.00    1613/818795      gguf_get_key [182]
                0.00    0.00  816820/818795      gguf_get_arr_str [133]
[132]    0.0    0.00    0.00  818795         gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00  408403/816820      llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00  408417/816820      gguf_kv_to_str(gguf_context const*, int) [1044]
[133]    0.0    0.00    0.00  816820         gguf_get_arr_str [133]
                0.00    0.00  816820/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00      32/599166      ggml_tallocr_alloc [121]
                0.00    0.00      32/599166      ggml_backend_alloc_ctx_tensors_from_buft [116]
                0.00    0.00     693/599166      ggml_graph_compute_with_ctx [104]
                0.00    0.00     696/599166      ggml_gallocr_allocate_node [103]
                0.00    0.00    2454/599166      ggml_gallocr_reserve_n [95]
                0.00    0.00  177677/599166      ggml_backend_tensor_alloc [67]
                0.00    0.00  417582/599166      ggml_gallocr_alloc_graph [39]
[134]    0.0    0.00    0.00  599166         ggml_backend_buft_get_alloc_size [134]
-----------------------------------------------
                0.00    0.00    1784/570742      ggml_compute_forward_get_rows [172]
                0.00    0.00   62111/570742      ggml_compute_forward_dup [15]
                0.00    0.00  506847/570742      ggml_compute_forward_mul_mat [2]
[135]    0.0    0.00    0.00  570742         ggml_get_type_traits [135]
-----------------------------------------------
                0.00    0.00       1/533399      ggml_tallocr_new [323]
                0.00    0.00      32/533399      ggml_tallocr_alloc [121]
                0.00    0.00     514/533399      llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00  177498/533399      ggml_gallocr_alloc_graph [39]
                0.00    0.00  355354/533399      ggml_backend_tensor_alloc [67]
[136]    0.0    0.00    0.00  533399         ggml_backend_buffer_get_base [136]
                0.00    0.00  533399/533399      ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*) [971]
-----------------------------------------------
                0.00    0.00  408611/408611      gguf_init_from_file [118]
[137]    0.0    0.00    0.00  408611         gguf_fread_str [137]
-----------------------------------------------
                0.00    0.00     147/400857      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00    7210/400857      ggml_compute_forward_get_rows [172]
                0.00    0.00    8256/400857      ggml_cont_4d [98]
                0.00    0.00   16512/400857      ggml_reshape_3d [74]
                0.00    0.00   33024/400857      ggml_cpy [75]
                0.00    0.00   74385/400857      ggml_graph_plan [82]
                0.00    0.00  261323/400857      ggml_compute_forward_dup [15]
[138]    0.0    0.00    0.00  400857         ggml_nelements [138]
-----------------------------------------------
                0.00    0.00       1/395044      llama_print_system_info [349]
                0.00    0.00  395043/395044      ggml_fp32_to_fp16_row [35]
[139]    0.0    0.00    0.00  395044         ggml_cpu_has_f16c [139]
-----------------------------------------------
                0.00    0.00      32/372584      llama_new_context_with_model [80]
                0.00    0.00    1032/372584      ggml_visit_parents [61]
                0.00    0.00    8256/372584      ggml_cont_4d [98]
                0.00    0.00    8256/372584      ggml_view_1d [87]
                0.00    0.00    8256/372584      ggml_view_2d [88]
                0.00    0.00    8256/372584      ggml_transpose [86]
                0.00    0.00   16512/372584      ggml_cpy [75]
                0.00    0.00   16512/372584      ggml_reshape_3d [74]
                0.00    0.00   16512/372584      ggml_view_3d [77]
                0.00    0.00   16512/372584      ggml_permute [76]
                0.00    0.00   41280/372584      ggml_view_tensor [71]
                0.00    0.00  231168/372584      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
[140]    0.0    0.00    0.00  372584         ggml_format_name [140]
-----------------------------------------------
                0.00    0.00    8208/370587      ggml_graph_plan [82]
                0.00    0.00   35055/370587      ggml_compute_forward_soft_max [14]
                0.00    0.00   40756/370587      ggml_compute_forward_unary [36]
                0.00    0.00   79873/370587      ggml_compute_forward_rope_f32 [20]
                0.00    0.00   80878/370587      ggml_compute_forward_add [49]
                0.00    0.00  125817/370587      ggml_compute_forward_mul [28]
[141]    0.0    0.00    0.00  370587         ggml_nrows [141]
-----------------------------------------------
                0.00    0.00      16/318551      llama_new_context_with_model [80]
                0.00    0.00     163/318551      weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00   16448/318551      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00   84172/318551      ggml_backend_sched_get_tensor_backend [32]
                0.00    0.00  217752/318551      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[142]    0.0    0.00    0.00  318551         ggml_backend_dev_supports_op [142]
-----------------------------------------------
                0.00    0.00   16448/318372      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00   84172/318372      ggml_backend_sched_get_tensor_backend [32]
                0.00    0.00  217752/318372      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[143]    0.0    0.00    0.00  318372         ggml_backend_supports_op [143]
-----------------------------------------------
                0.00    0.00   80670/296028      ggml_compute_forward_add [49]
                0.00    0.00   89765/296028      ggml_compute_forward_rms_norm [29]
                0.00    0.00  125593/296028      ggml_compute_forward_mul [28]
[144]    0.0    0.00    0.00  296028         ggml_are_same_shape [144]
-----------------------------------------------
                0.00    0.00     516/270584      ggml_new_graph_custom [201]
                0.00    0.00    8256/270584      ggml_new_tensor_impl.constprop.2 [84]
                0.00    0.00    8256/270584      ggml_new_tensor_impl.constprop.3 [85]
                0.00    0.00   33024/270584      ggml_new_tensor_impl.constprop.1 [73]
                0.00    0.00   41280/270584      ggml_new_tensor_impl.constprop.0 [70]
                0.00    0.00  179252/270584      ggml_new_tensor [72]
[145]    0.0    0.00    0.00  270584         ggml_new_object [145]
-----------------------------------------------
                0.00    0.00      32/267965      alloc_tensor_range [119]
                0.00    0.00     147/267965      llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00  267786/267965      ggml_gallocr_alloc_graph [39]
[146]    0.0    0.00    0.00  267965         ggml_backend_buffer_init_tensor [146]
-----------------------------------------------
                0.00    0.00   16512/247815      ggml_add [94]
                0.00    0.00   25317/247815      ggml_mul [91]
                0.00    0.00   80578/247815      ggml_compute_forward_add [49]
                0.00    0.00  125408/247815      ggml_compute_forward_mul [28]
[147]    0.0    0.00    0.00  247815         ggml_can_repeat [147]
                0.00    0.00  243012/1756974     ggml_is_empty [130]
-----------------------------------------------
                0.00    0.00       1/218779      ggml_backend_sched_new [295]
                0.00    0.00    1026/218779      llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00  217752/218779      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[148]    0.0    0.00    0.00  218779         ggml_backend_buft_is_host [148]
-----------------------------------------------
                0.00    0.00       1/217753      ggml_backend_sched_new [295]
                0.00    0.00  217752/217753      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[149]    0.0    0.00    0.00  217753         ggml_backend_dev_supports_buft [149]
-----------------------------------------------
                0.00    0.00       1/217753      ggml_backend_sched_new [295]
                0.00    0.00  217752/217753      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[150]    0.0    0.00    0.00  217753         ggml_backend_supports_buft [150]
-----------------------------------------------
                0.00    0.00       1/178739      ggml_backend_buffer_get_alignment [285]
                0.00    0.00       3/178739      ggml_backend_buffer_name [254]
                0.00    0.00    1026/178739      ggml_backend_buffer_is_host [189]
                0.00    0.00  177709/178739      ggml_backend_buffer_get_alloc_size [153]
[151]    0.0    0.00    0.00  178739         ggml_backend_buffer_get_type [151]
-----------------------------------------------
                0.00    0.00       1/178228      llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       2/178228      ggml_gallocr_reserve_n [95]
                0.00    0.00       3/178228      llama_new_context_with_model [80]
                0.00    0.00      32/178228      ggml_tallocr_alloc [121]
                0.00    0.00     513/178228      llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00  177677/178228      ggml_backend_tensor_alloc [67]
[152]    0.0    0.00    0.00  178228         ggml_backend_buffer_get_size [152]
-----------------------------------------------
                0.00    0.00      32/177709      ggml_tallocr_alloc [121]
                0.00    0.00  177677/177709      ggml_backend_tensor_alloc [67]
[153]    0.0    0.00    0.00  177709         ggml_backend_buffer_get_alloc_size [153]
                0.00    0.00  177709/178739      ggml_backend_buffer_get_type [151]
-----------------------------------------------
                0.00    0.00       1/168713      llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [113]
                0.00    0.00     513/168713      ggml_graph_compute [210]
                0.00    0.00    1802/168713      ggml_compute_forward [1]
                0.00    0.00  166397/168713      ggml_compute_forward_mul_mat [2]
[154]    0.0    0.00    0.00  168713         ggml_is_numa [154]
-----------------------------------------------
                0.00    0.00     517/130616      common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [999]
                0.00    0.00  130099/130616      llm_load_vocab(llama_model_loader&, llama_model&) [19]
[155]    0.0    0.00    0.00  130616         llama_token_to_piece [155]
-----------------------------------------------
                0.00    0.00      16/92060       ggml_rope [126]
                0.00    0.00     147/92060       llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [120]
                0.00    0.00    8256/92060       ggml_soft_max_ext [89]
                0.00    0.00    8256/92060       ggml_unary [96]
                0.00    0.00   16512/92060       ggml_add [94]
                0.00    0.00   16528/92060       ggml_rope_ext [93]
                0.00    0.00   17028/92060       ggml_rms_norm [92]
                0.00    0.00   25317/92060       ggml_mul [91]
[156]    0.0    0.00    0.00   92060         ggml_dup_tensor [156]
-----------------------------------------------
                0.00    0.00   90288/90288       ggml_gallocr_alloc_graph [39]
[157]    0.0    0.00    0.00   90288         ggml_backend_view_init [157]
-----------------------------------------------
                0.00    0.00   79884/79884       ggml_compute_forward_rope_f32 [20]
[158]    0.0    0.00    0.00   79884         ggml_rope_cache_init [158]
-----------------------------------------------
                0.00    0.00   79347/79347       ggml_compute_forward_rope_f32 [20]
[159]    0.0    0.00    0.00   79347         ggml_rope_yarn_corr_dims [159]
-----------------------------------------------
                0.00    0.00   74933/74933       ggml_mul_mat [78]
[160]    0.0    0.00    0.00   74933         ggml_is_transposed [160]
-----------------------------------------------
                0.00    0.00    8208/49125       ggml_graph_plan [82]
                0.00    0.00   40917/49125       ggml_compute_forward_unary [36]
[161]    0.0    0.00    0.00   49125         ggml_get_unary_op [161]
-----------------------------------------------
                0.00    0.00    1026/34050       llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00   16512/34050       llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
                0.00    0.00   16512/34050       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
[162]    0.0    0.00    0.00   34050         ggml_element_size [162]
-----------------------------------------------
                0.00    0.00       1/32833       llama_new_context_with_model [80]
                0.00    0.00   32832/32833       ggml_graph_plan [82]
[163]    0.0    0.00    0.00   32833         ggml_is_quantized [163]
-----------------------------------------------
                0.00    0.00      16/16544       ggml_rope [126]
                0.00    0.00   16528/16544       ggml_rope_ext [93]
[164]    0.0    0.00    0.00   16544         ggml_is_vector [164]
-----------------------------------------------
                0.00    0.00       1/16449       llama_new_context_with_model [80]
                0.00    0.00   16448/16449       std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
[165]    0.0    0.00    0.00   16449         ggml_backend_get_device [165]
-----------------------------------------------
                0.00    0.00   16448/16448       std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
[166]    0.0    0.00    0.00   16448         ggml_backend_sched_set_tensor_backend [166]
-----------------------------------------------
                0.00    0.00   10878/10878       gguf_find_tensor [224]
[167]    0.0    0.00    0.00   10878         gguf_get_tensor_name [167]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
[168]    0.0    0.00    0.00    8256         ggml_cont_2d [168]
-----------------------------------------------
                0.00    0.00    8256/8256        ggml_soft_max_ext [89]
[169]    0.0    0.00    0.00    8256         ggml_is_matrix [169]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
[170]    0.0    0.00    0.00    8256         ggml_mul_mat_set_prec [170]
-----------------------------------------------
                0.00    0.00    8256/8256        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
[171]    0.0    0.00    0.00    8256         ggml_silu [171]
-----------------------------------------------
                0.00    0.00    7090/7090        ggml_compute_forward [1]
[172]    0.0    0.00    0.00    7090         ggml_compute_forward_get_rows [172]
                0.00    0.00    7210/400857      ggml_nelements [138]
                0.00    0.00    1784/570742      ggml_get_type_traits [135]
                0.00    0.00     291/291         dequantize_row_q6_K [216]
-----------------------------------------------
                0.00    0.00    1029/6199        common_sampler_accept(common_sampler*, int, bool) [53]
                0.00    0.00    5170/6199        llama_sampler_chain_accept(llama_sampler*, int) [54]
[173]    0.0    0.00    0.00    6199         llama_sampler_accept [173]
-----------------------------------------------
                0.00    0.00    1024/6144        common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
                0.00    0.00    5120/6144        llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[174]    0.0    0.00    0.00    6144         llama_sampler_apply [174]
-----------------------------------------------
                0.00    0.00     147/4422        gguf_init_from_file [118]
                0.00    0.00     147/4422        llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [120]
                0.00    0.00    4128/4422        std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
[175]    0.0    0.00    0.00    4422         ggml_set_name [175]
-----------------------------------------------
                0.00    0.00       1/3091        llama_perf_context_reset [346]
                0.00    0.00       1/3091        llama_perf_context_print [345]
                0.00    0.00       2/3091        ggml_cpu_init [202]
                0.00    0.00       2/3091        llama_load_model_from_file [18]
                0.00    0.00     513/3091        llama_decode_internal(llama_context&, llama_batch) [13]
                0.00    0.00     514/3091        llama_synchronize [213]
                0.00    0.00    1024/3091        llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.00    1034/3091        llama_sampler_chain_accept(llama_sampler*, int) [54]
[176]    0.0    0.00    0.00    3091         ggml_time_us [176]
-----------------------------------------------
                0.00    0.00       1/2246        main [7]
                0.00    0.00       1/2246        ggml_backend_cpu_init [288]
                0.00    0.00       1/2246        llama_print_system_info [349]
                0.00    0.00     513/2246        ggml_graph_compute [210]
                0.00    0.00    1730/2246        ggml_init [181]
[177]    0.0    0.00    0.00    2246         ggml_critical_section_end [177]
-----------------------------------------------
                0.00    0.00       1/2246        ggml_quantize_free [322]
                0.00    0.00     515/2246        ggml_cpu_init [202]
                0.00    0.00    1730/2246        ggml_init [181]
[178]    0.0    0.00    0.00    2246         ggml_critical_section_start [178]
-----------------------------------------------
                0.00    0.00     516/2064        std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [111]
                0.00    0.00    1548/2064        llm_build_context::build_llama() [42]
[179]    0.0    0.00    0.00    2064         ggml_set_input [179]
-----------------------------------------------
                0.00    0.00       1/1731        main [7]
                0.00    0.00       1/1731        ggml_backend_sched_free [293]
                0.00    0.00       1/1731        llama_free [336]
                0.00    0.00       1/1731        llama_load_model_from_file [18]
                0.00    0.00       1/1731        llama_model::~llama_model() [46]
                0.00    0.00       3/1731        ggml_backend_sched_reserve [90]
                0.00    0.00      16/1731        llama_new_context_with_model [80]
                0.00    0.00     163/1731        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00     513/1731        ggml_backend_sched_alloc_graph [31]
                0.00    0.00     515/1731        ggml_cpu_init [202]
                0.00    0.00     516/1731        llama_build_graph(llama_context&, llama_ubatch const&, bool) [41]
[180]    0.0    0.00    0.00    1731         ggml_free [180]
                0.00    0.00     698/705         ggml_aligned_free [194]
-----------------------------------------------
                0.00    0.00       1/1730        gguf_init_from_file [118]
                0.00    0.00       1/1730        llama_backend_init [334]
                0.00    0.00       1/1730        llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
                0.00    0.00       3/1730        ggml_backend_sched_reserve [90]
                0.00    0.00      17/1730        llama_new_context_with_model [80]
                0.00    0.00     163/1730        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00     513/1730        ggml_backend_sched_alloc_graph [31]
                0.00    0.00     515/1730        ggml_cpu_init [202]
                0.00    0.00     516/1730        llama_build_graph(llama_context&, llama_ubatch const&, bool) [41]
[181]    0.0    0.00    0.00    1730         ggml_init [181]
                0.00    0.00    1730/2246        ggml_critical_section_start [178]
                0.00    0.00    1730/2246        ggml_critical_section_end [177]
                0.00    0.00     698/705         ggml_aligned_malloc [195]
                0.00    0.00       1/3           ggml_time_init [261]
-----------------------------------------------
                0.00    0.00      30/1613        llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00      35/1613        llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00    1548/1613        gguf_find_key [228]
[182]    0.0    0.00    0.00    1613         gguf_get_key [182]
                0.00    0.00    1613/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00       1/1541        ggml_backend_sched_new [295]
                0.00    0.00       1/1541        llama_new_context_with_model [80]
                0.00    0.00     513/1541        ggml_backend_cpu_set_n_threads [206]
                0.00    0.00     513/1541        ggml_backend_cpu_set_threadpool [207]
                0.00    0.00     513/1541        ggml_backend_cpu_set_abort_callback [205]
[183]    0.0    0.00    0.00    1541         ggml_backend_is_cpu [183]
-----------------------------------------------
                0.00    0.00       1/1541        ggml_backend_sched_new [295]
                0.00    0.00       1/1541        llama_new_context_with_model [80]
                0.00    0.00     513/1541        ggml_backend_cpu_set_n_threads [206]
                0.00    0.00     513/1541        ggml_backend_cpu_set_threadpool [207]
                0.00    0.00     513/1541        ggml_backend_cpu_set_abort_callback [205]
[184]    0.0    0.00    0.00    1541         ggml_guid_matches [184]
-----------------------------------------------
                0.00    0.00       3/1036        ggml_gallocr_reserve_n [95]
                0.00    0.00     516/1036        ggml_new_graph_custom [201]
                0.00    0.00     517/1036        ggml_backend_sched_reset [187]
[185]    0.0    0.00    0.00    1036         ggml_hash_set_reset [185]
-----------------------------------------------
                0.00    0.00       2/1036        ggml_hash_set_new [276]
                0.00    0.00       2/1036        ggml_graph_overhead_custom [275]
                0.00    0.00    1032/1036        ggml_new_graph_custom [201]
[186]    0.0    0.00    0.00    1036         ggml_hash_size [186]
-----------------------------------------------
                0.00    0.00       1/1030        ggml_backend_sched_new [295]
                0.00    0.00       3/1030        ggml_backend_sched_reserve [90]
                0.00    0.00    1026/1030        llama_decode_internal(llama_context&, llama_batch) [13]
[187]    0.0    0.00    0.00    1030         ggml_backend_sched_reset [187]
                0.00    0.00     517/1036        ggml_hash_set_reset [185]
-----------------------------------------------
                0.00    0.00       1/1030        common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [65]
                0.00    0.00     512/1030        common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
                0.00    0.00     517/1030        common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [999]
[188]    0.0    0.00    0.00    1030         llama_get_model [188]
-----------------------------------------------
                0.00    0.00    1026/1026        llama_set_inputs(llama_context&, llama_ubatch const&) [100]
[189]    0.0    0.00    0.00    1026         ggml_backend_buffer_is_host [189]
                0.00    0.00    1026/178739      ggml_backend_buffer_get_type [151]
-----------------------------------------------
                0.00    0.00    1026/1026        llama_decode_internal(llama_context&, llama_batch) [13]
[190]    0.0    0.00    0.00    1026         ggml_graph_node [190]
-----------------------------------------------
                0.00    0.00    1026/1026        main [7]
[191]    0.0    0.00    0.00    1026         llama_token_is_eog [191]
-----------------------------------------------
                0.00    0.00      32/799         alloc_tensor_range [119]
                0.00    0.00      32/799         ggml_backend_alloc_ctx_tensors_from_buft [116]
                0.00    0.00     147/799         ggml_get_max_tensor_size [112]
                0.00    0.00     147/799         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00     147/799         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00     294/799         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[192]    0.0    0.00    0.00     799         ggml_get_next_tensor [192]
-----------------------------------------------
                0.00    0.00     147/735         llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [120]
                0.00    0.00     147/735         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00     147/735         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00     294/735         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[193]    0.0    0.00    0.00     735         ggml_get_name [193]
-----------------------------------------------
                0.00    0.00       1/705         main [7]
                0.00    0.00       1/705         ggml_graph_compute [210]
                0.00    0.00       2/705         ggml_threadpool_free [259]
                0.00    0.00       3/705         ggml_backend_buffer_free [217]
                0.00    0.00     698/705         ggml_free [180]
[194]    0.0    0.00    0.00     705         ggml_aligned_free [194]
-----------------------------------------------
                0.00    0.00       3/705         ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1103]
                0.00    0.00       4/705         ggml_threadpool_new_impl [278]
                0.00    0.00     698/705         ggml_init [181]
[195]    0.0    0.00    0.00     705         ggml_aligned_malloc [195]
-----------------------------------------------
                0.00    0.00     685/685         ggml_compute_forward_mul_mat [2]
[196]    0.0    0.00    0.00     685         quantize_row_q8_1 [196]
-----------------------------------------------
                0.00    0.00       1/516         llama_kv_cache_clear [337]
                0.00    0.00       1/516         llama_new_context_with_model [80]
                0.00    0.00     514/516         llama_output_reserve(llama_context&, unsigned long) [1007]
[197]    0.0    0.00    0.00     516         ggml_backend_buffer_clear [197]
-----------------------------------------------
                0.00    0.00       3/516         ggml_backend_sched_reserve [90]
                0.00    0.00     513/516         llama_synchronize [213]
[198]    0.0    0.00    0.00     516         ggml_backend_sched_synchronize [198]
                0.00    0.00     516/516         ggml_backend_synchronize [199]
-----------------------------------------------
                0.00    0.00     516/516         ggml_backend_sched_synchronize [198]
[199]    0.0    0.00    0.00     516         ggml_backend_synchronize [199]
-----------------------------------------------
                0.00    0.00     516/516         ggml_backend_sched_get_tensor_backend [32]
[200]    0.0    0.00    0.00     516         ggml_graph_view [200]
-----------------------------------------------
                0.00    0.00     516/516         llm_build_context::build_llama() [42]
[201]    0.0    0.00    0.00     516         ggml_new_graph_custom [201]
                0.00    0.00    1032/1036        ggml_hash_size [186]
                0.00    0.00     516/270584      ggml_new_object [145]
                0.00    0.00     516/1036        ggml_hash_set_reset [185]
-----------------------------------------------
                0.00    0.00       1/515         ggml_backend_cpu_init [288]
                0.00    0.00       1/515         llama_print_system_info [349]
                0.00    0.00     513/515         ggml_graph_compute [210]
[202]    0.0    0.00    0.00     515         ggml_cpu_init [202]
                0.00    0.00     515/1731        ggml_free [180]
                0.00    0.00     515/1730        ggml_init [181]
                0.00    0.00     515/2246        ggml_critical_section_start [178]
                0.00    0.00       2/3091        ggml_time_us [176]
-----------------------------------------------
                0.00    0.00       2/514         common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
                0.00    0.00     512/514         common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
[203]    0.0    0.00    0.00     514         llama_n_vocab [203]
-----------------------------------------------
                0.00    0.00     513/513         ggml_gallocr_alloc_graph [39]
[204]    0.0    0.00    0.00     513         ggml_backend_buffer_reset [204]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[205]    0.0    0.00    0.00     513         ggml_backend_cpu_set_abort_callback [205]
                0.00    0.00     513/1541        ggml_guid_matches [184]
                0.00    0.00     513/1541        ggml_backend_is_cpu [183]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[206]    0.0    0.00    0.00     513         ggml_backend_cpu_set_n_threads [206]
                0.00    0.00     513/1541        ggml_guid_matches [184]
                0.00    0.00     513/1541        ggml_backend_is_cpu [183]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[207]    0.0    0.00    0.00     513         ggml_backend_cpu_set_threadpool [207]
                0.00    0.00     513/1541        ggml_guid_matches [184]
                0.00    0.00     513/1541        ggml_backend_is_cpu [183]
-----------------------------------------------
                0.00    0.00     513/513         ggml_backend_sched_graph_compute_async [81]
[208]    0.0    0.00    0.00     513         ggml_backend_graph_compute_async [208]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[209]    0.0    0.00    0.00     513         ggml_backend_sched_set_eval_callback [209]
-----------------------------------------------
                0.00    0.00     513/513         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [83]
[210]    0.0    0.00    0.00     513         ggml_graph_compute [210]
                0.00    0.00     513/2246        ggml_critical_section_end [177]
                0.00    0.00     513/515         ggml_cpu_init [202]
                0.00    0.00     513/168713      ggml_is_numa [154]
                0.00    0.00       1/705         ggml_aligned_free [194]
                0.00    0.00       1/3           ggml_threadpool_free [259]
                0.00    0.00       1/1           ggml_threadpool_params_default [325]
                0.00    0.00       1/2           ggml_threadpool_new_impl [278]
-----------------------------------------------
                0.00    0.00       1/513         common_init_from_params(common_params&) [17]
                0.00    0.00     512/513         main [7]
[211]    0.0    0.00    0.00     513         llama_batch_get_one [211]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[212]    0.0    0.00    0.00     513         llama_kv_cache_update [212]
-----------------------------------------------
                0.00    0.00       1/513         common_init_from_params(common_params&) [17]
                0.00    0.00     512/513         llama_get_logits_ith [214]
[213]    0.0    0.00    0.00     513         llama_synchronize [213]
                0.00    0.00     514/3091        ggml_time_us [176]
                0.00    0.00     513/516         ggml_backend_sched_synchronize [198]
-----------------------------------------------
                0.00    0.00     512/512         common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
[214]    0.0    0.00    0.00     512         llama_get_logits_ith [214]
                0.00    0.00     512/513         llama_synchronize [213]
-----------------------------------------------
                0.00    0.00     305/305         ggml_compute_forward_mul_mat [2]
[215]    0.0    0.00    0.00     305         quantize_row_q8_K [215]
-----------------------------------------------
                0.00    0.00     291/291         ggml_compute_forward_get_rows [172]
[216]    0.0    0.00    0.00     291         dequantize_row_q6_K [216]
-----------------------------------------------
                0.00    0.00       1/184         ggml_gallocr_free [317]
                0.00    0.00       1/184         ggml_gallocr_reserve_n [95]
                0.00    0.00       1/184         llama_model::~llama_model() [46]
                0.00    0.00       2/184         llama_free [336]
                0.00    0.00      16/184         llama_new_context_with_model [80]
                0.00    0.00     163/184         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
[217]    0.0    0.00    0.00     184         ggml_backend_buffer_free [217]
                0.00    0.00       3/705         ggml_aligned_free [194]
                0.00    0.00       3/3           ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*) [1100]
-----------------------------------------------
                0.00    0.00       1/184         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       2/184         gguf_init_from_file [118]
                0.00    0.00      18/184         llama_new_context_with_model [80]
                0.00    0.00     163/184         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
[218]    0.0    0.00    0.00     184         ggml_tensor_overhead [218]
-----------------------------------------------
                0.00    0.00       1/183         ggml_backend_cpu_buffer_from_ptr [287]
                0.00    0.00       3/183         ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1103]
                0.00    0.00     179/183         ggml_backend_buft_alloc_buffer [220]
[219]    0.0    0.00    0.00     183         ggml_backend_buffer_init [219]
-----------------------------------------------
                0.00    0.00       1/182         alloc_tensor_range [119]
                0.00    0.00       1/182         ggml_gallocr_reserve_n [95]
                0.00    0.00       1/182         llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00      16/182         llama_new_context_with_model [80]
                0.00    0.00     163/182         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
[220]    0.0    0.00    0.00     182         ggml_backend_buft_alloc_buffer [220]
                0.00    0.00     179/183         ggml_backend_buffer_init [219]
-----------------------------------------------
                0.00    0.00       1/164         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00     163/164         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
[221]    0.0    0.00    0.00     164         ggml_backend_buft_get_device [221]
-----------------------------------------------
                0.00    0.00       1/164         llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00     163/164         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
[222]    0.0    0.00    0.00     164         ggml_backend_dev_host_buffer_type [222]
-----------------------------------------------
                0.00    0.00       2/158         bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1091]
                0.00    0.00       9/158         bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
                0.00    0.00      12/158         llama_state_seq_get_size [242]
                0.00    0.00      35/158         llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00      35/158         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00      65/158         gguf_kv_to_str(gguf_context const*, int) [1044]
[223]    0.0    0.00    0.00     158         gguf_get_kv_type [223]
                0.00    0.00     158/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[224]    0.0    0.00    0.00     147         gguf_find_tensor [224]
                0.00    0.00   10878/10878       gguf_get_tensor_name [167]
                0.00    0.00     147/147         gguf_get_n_tensors [226]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[225]    0.0    0.00    0.00     147         gguf_get_data_offset [225]
-----------------------------------------------
                0.00    0.00     147/147         gguf_find_tensor [224]
[226]    0.0    0.00    0.00     147         gguf_get_n_tensors [226]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[227]    0.0    0.00    0.00     147         gguf_get_tensor_offset [227]
-----------------------------------------------
                0.00    0.00       1/58          gguf_init_from_file [118]
                0.00    0.00       2/58          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00       4/58          llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00       5/58          bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1091]
                0.00    0.00       5/58          bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1090]
                0.00    0.00      13/58          llama_state_seq_get_size [242]
                0.00    0.00      28/58          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
[228]    0.0    0.00    0.00      58         gguf_find_key [228]
                0.00    0.00    1548/1613        gguf_get_key [182]
                0.00    0.00      58/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00      40/40          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[229]    0.0    0.00    0.00      40         gguf_type_name [229]
-----------------------------------------------
                0.00    0.00      36/36          gguf_kv_to_str(gguf_context const*, int) [1044]
[230]    0.0    0.00    0.00      36         gguf_get_val_data [230]
                0.00    0.00      36/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00       6/30          llama_state_seq_get_size [242]
                0.00    0.00      24/30          gguf_kv_to_str(gguf_context const*, int) [1044]
[231]    0.0    0.00    0.00      30         gguf_get_val_str [231]
                0.00    0.00      30/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00       2/19          llama_new_context_with_model [80]
                0.00    0.00       2/19          llama_load_model_from_file [18]
                0.00    0.00       4/19          ggml_backend_dev_by_type [257]
                0.00    0.00       4/19          llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       7/19          ggml_backend_dev_get [243]
[232]    0.0    0.00    0.00      19         ggml_backend_dev_count [232]
-----------------------------------------------
                0.00    0.00      16/16          llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
[233]    0.0    0.00    0.00      16         ggml_get_tensor [233]
-----------------------------------------------
                0.00    0.00       1/13          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00       3/13          llama_state_seq_get_size [242]
                0.00    0.00       9/13          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
[234]    0.0    0.00    0.00      13         gguf_get_val_u32 [234]
                0.00    0.00      13/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00       2/12          llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00       5/12          gguf_kv_to_str(gguf_context const*, int) [1044]
                0.00    0.00       5/12          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[235]    0.0    0.00    0.00      12         gguf_get_arr_n [235]
                0.00    0.00      12/818795      gguf_get_n_kv [132]
-----------------------------------------------
                                  10             llama_sampler_chain_free(llama_sampler*) <cycle 1> [1175]
                0.00    0.00       2/2           common_sampler_free(common_sampler*) [1148]
[236]    0.0    0.00    0.00      12         llama_sampler_free <cycle 1> [236]
                0.00    0.00       1/1           llama_sampler_dist_free(llama_sampler*) [1173]
                0.00    0.00       1/1           llama_sampler_temp_ext_free(llama_sampler*) [1185]
                0.00    0.00       1/1           llama_sampler_xtc_free(llama_sampler*) [1171]
                0.00    0.00       1/1           llama_sampler_min_p_free(llama_sampler*) [1176]
                0.00    0.00       1/1           llama_sampler_top_p_free(llama_sampler*) [1180]
                0.00    0.00       1/1           llama_sampler_typical_free(llama_sampler*) [1183]
                0.00    0.00       1/1           llama_sampler_top_k_free(llama_sampler*) [1178]
                0.00    0.00       1/1           llama_sampler_dry_free(llama_sampler*) [1169]
                0.00    0.00       1/1           llama_sampler_penalties_free(llama_sampler*) [1187]
                0.00    0.00       1/1           llama_sampler_logit_bias_free(llama_sampler*) [1189]
                0.00    0.00       1/1           llama_sampler_grammar_free(llama_sampler*) [1182]
                                   1             llama_sampler_chain_free(llama_sampler*) <cycle 1> [1175]
-----------------------------------------------
                0.00    0.00      11/11          common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[237]    0.0    0.00    0.00      11         llama_sampler_chain_n [237]
-----------------------------------------------
                0.00    0.00       5/10          gguf_kv_to_str(gguf_context const*, int) [1044]
                0.00    0.00       5/10          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[238]    0.0    0.00    0.00      10         gguf_get_arr_type [238]
                0.00    0.00      10/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00      10/10          common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[239]    0.0    0.00    0.00      10         llama_sampler_chain_add [239]
-----------------------------------------------
                0.00    0.00      10/10          common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[240]    0.0    0.00    0.00      10         llama_sampler_chain_get [240]
-----------------------------------------------
                0.00    0.00      10/10          common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[241]    0.0    0.00    0.00      10         llama_sampler_name [241]
-----------------------------------------------
                0.00    0.00       1/10          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00       4/10          llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00       5/10          llm_load_hparams(llama_model_loader&, llama_model&) [1165]
[242]    0.0    0.00    0.00      10         llama_state_seq_get_size [242]
                0.00    0.00      13/58          gguf_find_key [228]
                0.00    0.00      12/158         gguf_get_kv_type [223]
                0.00    0.00      10/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1049]
                0.00    0.00       6/30          gguf_get_val_str [231]
                0.00    0.00       3/522         format(char const*, ...) [997]
                0.00    0.00       3/13          gguf_get_val_u32 [234]
-----------------------------------------------
                0.00    0.00       1/7           llama_new_context_with_model [80]
                0.00    0.00       1/7           llama_load_model_from_file [18]
                0.00    0.00       2/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       3/7           ggml_backend_dev_by_type [257]
[243]    0.0    0.00    0.00       7         ggml_backend_dev_get [243]
                0.00    0.00       7/19          ggml_backend_dev_count [232]
                0.00    0.00       7/9           get_reg() [1073]
-----------------------------------------------
                0.00    0.00       1/7           llama_new_context_with_model [80]
                0.00    0.00       1/7           llama_load_model_from_file [18]
                0.00    0.00       2/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       3/7           ggml_backend_dev_by_type [257]
[244]    0.0    0.00    0.00       7         ggml_backend_dev_type [244]
-----------------------------------------------
                0.00    0.00       1/7           ggml_get_max_tensor_size [112]
                0.00    0.00       1/7           ggml_backend_alloc_ctx_tensors_from_buft [116]
                0.00    0.00       1/7           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
                0.00    0.00       1/7           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00       3/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[245]    0.0    0.00    0.00       7         ggml_get_first_tensor [245]
-----------------------------------------------
                0.00    0.00       2/6           ggml_backend_reg_get [269]
                0.00    0.00       4/6           ggml_backend_reg_by_name [267]
[246]    0.0    0.00    0.00       6         ggml_backend_reg_count [246]
                0.00    0.00       2/2           ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*) [1134]
                0.00    0.00       2/2           ggml_backend_reg_dev_count [268]
                0.00    0.00       1/4           ggml_backend_cpu_reg [251]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1094]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [252]
                0.00    0.00       1/1           void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&) [1226]
                0.00    0.00       1/1           void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&) [1225]
-----------------------------------------------
                0.00    0.00       2/6           llama_new_context_with_model [80]
                0.00    0.00       4/6           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[247]    0.0    0.00    0.00       6         ggml_type_name [247]
-----------------------------------------------
                0.00    0.00       1/6           llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00       5/6           gguf_kv_to_str(gguf_context const*, int) [1044]
[248]    0.0    0.00    0.00       6         gguf_get_arr_data [248]
                0.00    0.00       6/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00       1/4           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       3/4           llama_new_context_with_model [80]
[249]    0.0    0.00    0.00       4         ggml_backend_buft_name [249]
-----------------------------------------------
                0.00    0.00       1/4           llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00       1/4           llama_new_context_with_model [80]
                0.00    0.00       2/4           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[250]    0.0    0.00    0.00       4         ggml_backend_cpu_buffer_type [250]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1094]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [252]
                0.00    0.00       1/4           ggml_backend_cpu_reg [251]
-----------------------------------------------
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [250]
                0.00    0.00       1/4           ggml_backend_cpu_init [288]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_from_ptr [287]
                0.00    0.00       1/4           ggml_backend_reg_count [246]
[251]    0.0    0.00    0.00       4         ggml_backend_cpu_reg [251]
-----------------------------------------------
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [250]
                0.00    0.00       1/4           ggml_backend_cpu_init [288]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_from_ptr [287]
                0.00    0.00       1/4           ggml_backend_reg_count [246]
[252]    0.0    0.00    0.00       4         ggml_backend_reg_dev_get [252]
-----------------------------------------------
                0.00    0.00       1/4           llama_new_context_with_model [80]
                0.00    0.00       1/4           common_init_from_params(common_params&) [17]
                0.00    0.00       2/4           main [7]
[253]    0.0    0.00    0.00       4         llama_model_has_encoder [253]
-----------------------------------------------
                0.00    0.00       1/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       2/3           llama_new_context_with_model [80]
[254]    0.0    0.00    0.00       3         ggml_backend_buffer_name [254]
                0.00    0.00       3/178739      ggml_backend_buffer_get_type [151]
-----------------------------------------------
                0.00    0.00       1/3           ggml_tallocr_new [323]
                0.00    0.00       1/3           ggml_gallocr_new_n [319]
                0.00    0.00       1/3           ggml_backend_alloc_ctx_tensors_from_buft [116]
[255]    0.0    0.00    0.00       3         ggml_backend_buft_get_alignment [255]
-----------------------------------------------
                0.00    0.00       1/3           llama_new_context_with_model [80]
                0.00    0.00       2/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[256]    0.0    0.00    0.00       3         ggml_backend_dev_buffer_type [256]
-----------------------------------------------
                0.00    0.00       1/3           llama_supports_gpu_offload [365]
                0.00    0.00       2/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[257]    0.0    0.00    0.00       3         ggml_backend_dev_by_type [257]
                0.00    0.00       4/19          ggml_backend_dev_count [232]
                0.00    0.00       3/7           ggml_backend_dev_get [243]
                0.00    0.00       3/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1083]
                0.00    0.00       3/7           ggml_backend_dev_type [244]
-----------------------------------------------
                0.00    0.00       1/3           ggml_gallocr_free [317]
                0.00    0.00       1/3           ggml_gallocr_reserve_n [95]
                0.00    0.00       1/3           ggml_backend_sched_free [293]
[258]    0.0    0.00    0.00       3         ggml_hash_set_free [258]
-----------------------------------------------
                0.00    0.00       1/3           ggml_graph_compute [210]
                0.00    0.00       2/3           main [7]
[259]    0.0    0.00    0.00       3         ggml_threadpool_free [259]
                0.00    0.00       2/705         ggml_aligned_free [194]
-----------------------------------------------
                0.00    0.00       1/3           ggml_threadpool_params_default [325]
                0.00    0.00       2/3           ggml_threadpool_params_from_cpu_params(cpu_params const&) [1127]
[260]    0.0    0.00    0.00       3         ggml_threadpool_params_init [260]
-----------------------------------------------
                0.00    0.00       1/3           ggml_init [181]
                0.00    0.00       1/3           llama_backend_init [334]
                0.00    0.00       1/3           llama_load_model_from_file [18]
[261]    0.0    0.00    0.00       3         ggml_time_init [261]
-----------------------------------------------
                0.00    0.00       3/3           ggml_quantize_free [322]
[262]    0.0    0.00    0.00       3         iq2xs_free_impl [262]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_buffer_set_usage [264]
[263]    0.0    0.00    0.00       2         ggml_backend_buffer_is_multi_buffer [263]
-----------------------------------------------
                0.00    0.00       1/2           ggml_gallocr_reserve_n [95]
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[264]    0.0    0.00    0.00       2         ggml_backend_buffer_set_usage [264]
                0.00    0.00       2/2           ggml_backend_buffer_is_multi_buffer [263]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[265]    0.0    0.00    0.00       2         ggml_backend_dev_backend_reg [265]
-----------------------------------------------
                0.00    0.00       1/2           llama_free [336]
                0.00    0.00       1/2           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
[266]    0.0    0.00    0.00       2         ggml_backend_free [266]
-----------------------------------------------
                0.00    0.00       2/2           llama_supports_rpc [282]
[267]    0.0    0.00    0.00       2         ggml_backend_reg_by_name [267]
                0.00    0.00       4/6           ggml_backend_reg_count [246]
                0.00    0.00       2/2           ggml_backend_reg_get [269]
                0.00    0.00       2/2           ggml_backend_cpu_reg_get_name(ggml_backend_reg*) [1131]
                0.00    0.00       2/2           ggml_backend_reg_name [271]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_count [246]
[268]    0.0    0.00    0.00       2         ggml_backend_reg_dev_count [268]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_by_name [267]
[269]    0.0    0.00    0.00       2         ggml_backend_reg_get [269]
                0.00    0.00       2/6           ggml_backend_reg_count [246]
                0.00    0.00       2/9           get_reg() [1073]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[270]    0.0    0.00    0.00       2         ggml_backend_reg_get_proc_address [270]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_by_name [267]
[271]    0.0    0.00    0.00       2         ggml_backend_reg_name [271]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[272]    0.0    0.00    0.00       2         ggml_backend_sched_get_n_splits [272]
-----------------------------------------------
                0.00    0.00       1/2           gguf_init_from_file [118]
                0.00    0.00       1/2           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[273]    0.0    0.00    0.00       2         ggml_fopen [273]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[274]    0.0    0.00    0.00       2         ggml_graph_n_nodes [274]
-----------------------------------------------
                0.00    0.00       1/2           ggml_backend_sched_new [295]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[275]    0.0    0.00    0.00       2         ggml_graph_overhead_custom [275]
                0.00    0.00       2/1036        ggml_hash_size [186]
-----------------------------------------------
                0.00    0.00       1/2           ggml_gallocr_reserve_n [95]
                0.00    0.00       1/2           ggml_backend_sched_new [295]
[276]    0.0    0.00    0.00       2         ggml_hash_set_new [276]
                0.00    0.00       2/1036        ggml_hash_size [186]
-----------------------------------------------
                0.00    0.00       2/2           gguf_init_from_file [118]
[277]    0.0    0.00    0.00       2         ggml_set_no_alloc [277]
-----------------------------------------------
                0.00    0.00       1/2           main [7]
                0.00    0.00       1/2           ggml_graph_compute [210]
[278]    0.0    0.00    0.00       2         ggml_threadpool_new_impl [278]
                0.00    0.00       4/705         ggml_aligned_malloc [195]
-----------------------------------------------
                0.00    0.00       2/2           bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1091]
[279]    0.0    0.00    0.00       2         gguf_get_val_f32 [279]
                0.00    0.00       2/818795      gguf_get_n_kv [132]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[280]    0.0    0.00    0.00       2         llama_model_is_recurrent [280]
-----------------------------------------------
                0.00    0.00       1/2           main [7]
                0.00    0.00       1/2           llama_sampler_init_dry [355]
[281]    0.0    0.00    0.00       2         llama_n_ctx_train [281]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/2           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[282]    0.0    0.00    0.00       2         llama_supports_rpc [282]
                0.00    0.00       2/2           ggml_backend_reg_by_name [267]
-----------------------------------------------
                0.00    0.00       1/2           llama_new_context_with_model [80]
                0.00    0.00       1/2           common_init_from_params(common_params&) [17]
[283]    0.0    0.00    0.00       2         llama_token_bos [283]
-----------------------------------------------
                0.00    0.00       1/2           common_init_from_params(common_params&) [17]
                0.00    0.00       1/2           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[284]    0.0    0.00    0.00       2         llama_token_eos [284]
-----------------------------------------------
                0.00    0.00       1/1           ggml_tallocr_new [323]
[285]    0.0    0.00    0.00       1         ggml_backend_buffer_get_alignment [285]
                0.00    0.00       1/178739      ggml_backend_buffer_get_type [151]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [116]
[286]    0.0    0.00    0.00       1         ggml_backend_buft_get_max_size [286]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[287]    0.0    0.00    0.00       1         ggml_backend_cpu_buffer_from_ptr [287]
                0.00    0.00       1/183         ggml_backend_buffer_init [219]
                0.00    0.00       1/4           ggml_backend_cpu_reg [251]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1094]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [252]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[288]    0.0    0.00    0.00       1         ggml_backend_cpu_init [288]
                0.00    0.00       1/2246        ggml_critical_section_end [177]
                0.00    0.00       1/515         ggml_cpu_init [202]
                0.00    0.00       1/4           ggml_backend_cpu_reg [251]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1094]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [252]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[289]    0.0    0.00    0.00       1         ggml_backend_dev_buffer_from_host_ptr [289]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[290]    0.0    0.00    0.00       1         ggml_backend_dev_get_props [290]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_sched_free [293]
[291]    0.0    0.00    0.00       1         ggml_backend_event_free [291]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[292]    0.0    0.00    0.00       1         ggml_backend_get_default_buffer_type [292]
-----------------------------------------------
                0.00    0.00       1/1           llama_free [336]
[293]    0.0    0.00    0.00       1         ggml_backend_sched_free [293]
                0.00    0.00       1/1           ggml_backend_event_free [291]
                0.00    0.00       1/1           ggml_gallocr_free [317]
                0.00    0.00       1/1731        ggml_free [180]
                0.00    0.00       1/3           ggml_hash_set_free [258]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[294]    0.0    0.00    0.00       1         ggml_backend_sched_get_buffer_size [294]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[295]    0.0    0.00    0.00       1         ggml_backend_sched_new [295]
                0.00    0.00       1/1541        ggml_guid_matches [184]
                0.00    0.00       1/1541        ggml_backend_is_cpu [183]
                0.00    0.00       1/2           ggml_hash_set_new [276]
                0.00    0.00       1/2           ggml_graph_overhead_custom [275]
                0.00    0.00       1/218779      ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [977]
                0.00    0.00       1/218779      ggml_backend_buft_is_host [148]
                0.00    0.00       1/217753      ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) [978]
                0.00    0.00       1/217753      ggml_backend_dev_supports_buft [149]
                0.00    0.00       1/217753      ggml_backend_supports_buft [150]
                0.00    0.00       1/1030        ggml_backend_sched_reset [187]
                0.00    0.00       1/1           ggml_gallocr_new_n [319]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[296]    0.0    0.00    0.00       1         ggml_cpu_has_amx_int8 [296]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[297]    0.0    0.00    0.00       1         ggml_cpu_has_arm_fma [297]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[298]    0.0    0.00    0.00       1         ggml_cpu_has_avx [298]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[299]    0.0    0.00    0.00       1         ggml_cpu_has_avx2 [299]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[300]    0.0    0.00    0.00       1         ggml_cpu_has_avx512 [300]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[301]    0.0    0.00    0.00       1         ggml_cpu_has_avx512_bf16 [301]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[302]    0.0    0.00    0.00       1         ggml_cpu_has_avx512_vbmi [302]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[303]    0.0    0.00    0.00       1         ggml_cpu_has_avx512_vnni [303]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[304]    0.0    0.00    0.00       1         ggml_cpu_has_avx_vnni [304]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[305]    0.0    0.00    0.00       1         ggml_cpu_has_blas [305]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[306]    0.0    0.00    0.00       1         ggml_cpu_has_fma [306]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[307]    0.0    0.00    0.00       1         ggml_cpu_has_fp16_va [307]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[308]    0.0    0.00    0.00       1         ggml_cpu_has_llamafile [308]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[309]    0.0    0.00    0.00       1         ggml_cpu_has_matmul_int8 [309]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[310]    0.0    0.00    0.00       1         ggml_cpu_has_neon [310]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[311]    0.0    0.00    0.00       1         ggml_cpu_has_riscv_v [311]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[312]    0.0    0.00    0.00       1         ggml_cpu_has_sse3 [312]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[313]    0.0    0.00    0.00       1         ggml_cpu_has_ssse3 [313]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[314]    0.0    0.00    0.00       1         ggml_cpu_has_sve [314]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[315]    0.0    0.00    0.00       1         ggml_cpu_has_vsx [315]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [349]
[316]    0.0    0.00    0.00       1         ggml_cpu_has_wasm_simd [316]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_sched_free [293]
[317]    0.0    0.00    0.00       1         ggml_gallocr_free [317]
                0.00    0.00       1/3           ggml_hash_set_free [258]
                0.00    0.00       1/184         ggml_backend_buffer_free [217]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[318]    0.0    0.00    0.00       1         ggml_gallocr_get_buffer_size [318]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_sched_new [295]
[319]    0.0    0.00    0.00       1         ggml_gallocr_new_n [319]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1104]
                0.00    0.00       1/3           ggml_backend_buft_get_alignment [255]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [116]
[320]    0.0    0.00    0.00       1         ggml_get_no_alloc [320]
-----------------------------------------------
                0.00    0.00       1/1           llama_log_set [338]
[321]    0.0    0.00    0.00       1         ggml_log_set [321]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[322]    0.0    0.00    0.00       1         ggml_quantize_free [322]
                0.00    0.00       3/3           iq2xs_free_impl [262]
                0.00    0.00       1/2246        ggml_critical_section_start [178]
                0.00    0.00       1/1           iq3xs_free_impl [329]
-----------------------------------------------
                0.00    0.00       1/1           alloc_tensor_range [119]
[323]    0.0    0.00    0.00       1         ggml_tallocr_new [323]
                0.00    0.00       1/533399      ggml_backend_buffer_get_base [136]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1104]
                0.00    0.00       1/3           ggml_backend_buft_get_alignment [255]
                0.00    0.00       1/1           ggml_backend_buffer_get_alignment [285]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[324]    0.0    0.00    0.00       1         ggml_threadpool_new [324]
-----------------------------------------------
                0.00    0.00       1/1           ggml_graph_compute [210]
[325]    0.0    0.00    0.00       1         ggml_threadpool_params_default [325]
                0.00    0.00       1/3           ggml_threadpool_params_init [260]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[326]    0.0    0.00    0.00       1         ggml_threadpool_params_match [326]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[327]    0.0    0.00    0.00       1         gguf_free [327]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[328]    0.0    0.00    0.00       1         gguf_get_version [328]
-----------------------------------------------
                0.00    0.00       1/1           ggml_quantize_free [322]
[329]    0.0    0.00    0.00       1         iq3xs_free_impl [329]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[330]    0.0    0.00    0.00       1         llama_add_bos_token [330]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[331]    0.0    0.00    0.00       1         llama_add_eos_token [331]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[332]    0.0    0.00    0.00       1         llama_attach_threadpool [332]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[333]    0.0    0.00    0.00       1         llama_backend_free [333]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[334]    0.0    0.00    0.00       1         llama_backend_init [334]
                0.00    0.00       1/3           ggml_time_init [261]
                0.00    0.00       1/1730        ggml_init [181]
-----------------------------------------------
                0.00    0.00       1/1           common_context_params_to_llama(common_params const&) [1161]
[335]    0.0    0.00    0.00       1         llama_context_default_params [335]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[336]    0.0    0.00    0.00       1         llama_free [336]
                0.00    0.00     516/528         llama_format_tensor_shape(ggml_tensor const*) [995]
                0.00    0.00       2/184         ggml_backend_buffer_free [217]
                0.00    0.00       1/1           ggml_backend_sched_free [293]
                0.00    0.00       1/1           ggml_backend_cpu_free(ggml_backend*) [1166]
                0.00    0.00       1/2           ggml_backend_free [266]
                0.00    0.00       1/1731        ggml_free [180]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [17]
[337]    0.0    0.00    0.00       1         llama_kv_cache_clear [337]
                0.00    0.00       2/528         llama_format_tensor_shape(ggml_tensor const*) [995]
                0.00    0.00       1/516         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [1001]
                0.00    0.00       1/516         ggml_backend_buffer_clear [197]
-----------------------------------------------
                0.00    0.00       1/1           common_init() [1144]
[338]    0.0    0.00    0.00       1         llama_log_set [338]
                0.00    0.00       1/1           ggml_log_set [321]
-----------------------------------------------
                0.00    0.00       1/1           common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1157]
[339]    0.0    0.00    0.00       1         llama_lora_adapter_clear [339]
-----------------------------------------------
                0.00    0.00       1/1           common_model_params_to_llama(common_params const&) [1159]
[340]    0.0    0.00    0.00       1         llama_model_default_params [340]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [17]
[341]    0.0    0.00    0.00       1         llama_model_has_decoder [341]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[342]    0.0    0.00    0.00       1         llama_n_ctx [342]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[343]    0.0    0.00    0.00       1         llama_numa_init [343]
-----------------------------------------------
                0.00    0.00       1/1           llama_perf_context_print [345]
[344]    0.0    0.00    0.00       1         llama_perf_context [344]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[345]    0.0    0.00    0.00       1         llama_perf_context_print [345]
                0.00    0.00       3/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00       1/3091        ggml_time_us [176]
                0.00    0.00       1/1           llama_perf_context [344]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [17]
[346]    0.0    0.00    0.00       1         llama_perf_context_reset [346]
                0.00    0.00       1/3091        ggml_time_us [176]
-----------------------------------------------
                0.00    0.00       1/1           llama_perf_sampler_print [348]
[347]    0.0    0.00    0.00       1         llama_perf_sampler [347]
-----------------------------------------------
                0.00    0.00       1/1           common_perf_print(llama_context const*, common_sampler const*) [1146]
[348]    0.0    0.00    0.00       1         llama_perf_sampler_print [348]
                0.00    0.00       1/1           llama_perf_sampler [347]
-----------------------------------------------
                0.00    0.00       1/1           common_params_get_system_info[abi:cxx11](common_params const&) [1160]
[349]    0.0    0.00    0.00       1         llama_print_system_info [349]
                0.00    0.00      17/17          std::__cxx11::to_string(int) [1060]
                0.00    0.00       1/2246        ggml_critical_section_end [177]
                0.00    0.00       1/515         ggml_cpu_init [202]
                0.00    0.00       1/1           ggml_cpu_has_avx [298]
                0.00    0.00       1/1           ggml_cpu_has_avx_vnni [304]
                0.00    0.00       1/1           ggml_cpu_has_avx2 [299]
                0.00    0.00       1/1           ggml_cpu_has_avx512 [300]
                0.00    0.00       1/1           ggml_cpu_has_avx512_vbmi [302]
                0.00    0.00       1/1           ggml_cpu_has_avx512_vnni [303]
                0.00    0.00       1/1           ggml_cpu_has_avx512_bf16 [301]
                0.00    0.00       1/1           ggml_cpu_has_amx_int8 [296]
                0.00    0.00       1/1           ggml_cpu_has_fma [306]
                0.00    0.00       1/1           ggml_cpu_has_neon [310]
                0.00    0.00       1/1           ggml_cpu_has_sve [314]
                0.00    0.00       1/1           ggml_cpu_has_arm_fma [297]
                0.00    0.00       1/395044      ggml_cpu_has_f16c [139]
                0.00    0.00       1/1           ggml_cpu_has_fp16_va [307]
                0.00    0.00       1/1           ggml_cpu_has_riscv_v [311]
                0.00    0.00       1/1           ggml_cpu_has_wasm_simd [316]
                0.00    0.00       1/1           ggml_cpu_has_blas [305]
                0.00    0.00       1/1           ggml_cpu_has_sse3 [312]
                0.00    0.00       1/1           ggml_cpu_has_ssse3 [313]
                0.00    0.00       1/1           ggml_cpu_has_vsx [315]
                0.00    0.00       1/1           ggml_cpu_has_matmul_int8 [309]
                0.00    0.00       1/1           ggml_cpu_has_llamafile [308]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_hparams(llama_model_loader&, llama_model&) [1165]
[350]    0.0    0.00    0.00       1         llama_rope_type [350]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[351]    0.0    0.00    0.00       1         llama_sampler_chain_default_params [351]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[352]    0.0    0.00    0.00       1         llama_sampler_chain_init [352]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[353]    0.0    0.00    0.00       1         llama_sampler_get_seed [353]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[354]    0.0    0.00    0.00       1         llama_sampler_init_dist [354]
                0.00    0.00       1/2           get_rng_seed(unsigned int) [1129]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[355]    0.0    0.00    0.00       1         llama_sampler_init_dry [355]
                0.00    0.00       1/2           llama_n_ctx_train [281]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[356]    0.0    0.00    0.00       1         llama_sampler_init_grammar [356]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[357]    0.0    0.00    0.00       1         llama_sampler_init_logit_bias [357]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[358]    0.0    0.00    0.00       1         llama_sampler_init_min_p [358]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[359]    0.0    0.00    0.00       1         llama_sampler_init_penalties [359]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[360]    0.0    0.00    0.00       1         llama_sampler_init_temp_ext [360]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[361]    0.0    0.00    0.00       1         llama_sampler_init_top_k [361]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[362]    0.0    0.00    0.00       1         llama_sampler_init_top_p [362]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[363]    0.0    0.00    0.00       1         llama_sampler_init_typical [363]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[364]    0.0    0.00    0.00       1         llama_sampler_init_xtc [364]
                0.00    0.00       1/2           get_rng_seed(unsigned int) [1129]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[365]    0.0    0.00    0.00       1         llama_supports_gpu_offload [365]
                0.00    0.00       1/3           ggml_backend_dev_by_type [257]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[366]    0.0    0.00    0.00       1         llama_token_nl [366]
-----------------------------------------------
                0.00    0.00       1/1           common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [64]
[367]    0.0    0.00    0.00       1         llama_tokenize [367]
-----------------------------------------------
                0.00    0.00 3182328/3182328     unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [972]
[965]    0.0    0.00    0.00 3182328         unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&) [965]
-----------------------------------------------
                0.00    0.00      18/872707      unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
                0.00    0.00     256/872707      unicode_byte_to_utf8[abi:cxx11](unsigned char) [1069]
                0.00    0.00     512/872707      unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [967]
                0.00    0.00  871921/872707      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [980]
[966]    0.0    0.00    0.00  872707         unicode_cpt_to_utf8[abi:cxx11](unsigned int) [966]
-----------------------------------------------
                0.00    0.00  871921/871921      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [980]
[967]    0.0    0.00    0.00  871921         unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [967]
                0.00    0.00  871921/871921      std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [968]
                0.00    0.00     512/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [966]
                0.00    0.00     256/256         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&) [1029]
-----------------------------------------------
                0.00    0.00  871921/871921      unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [967]
[968]    0.0    0.00    0.00  871921         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [968]
-----------------------------------------------
                                 781             replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
                0.00    0.00      21/817191      std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::~map() [1921]
                0.00    0.00      35/817191      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00      50/817191      std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [1215]
                0.00    0.00      50/817191      std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [1047]
                0.00    0.00     201/817191      __static_initialization_and_destruction_0() [1070]
                0.00    0.00  816834/817191      gguf_kv_to_str(gguf_context const*, int) [1044]
[969]    0.0    0.00    0.00  817191+781     replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
                                 781             replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
-----------------------------------------------
                0.00    0.00      16/560310      gguf_kv_to_str(gguf_context const*, int) [1044]
                0.00    0.00  560294/560310      llm_load_vocab(llama_model_loader&, llama_model&) [19]
[970]    0.0    0.00    0.00  560310         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) [970]
-----------------------------------------------
                0.00    0.00  533399/533399      ggml_backend_buffer_get_base [136]
[971]    0.0    0.00    0.00  533399         ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*) [971]
-----------------------------------------------
                0.00    0.00       2/409746      unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1133]
                0.00    0.00       6/409746      unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
                0.00    0.00  129591/409746      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [980]
                0.00    0.00  280147/409746      llm_load_vocab(llama_model_loader&, llama_model&) [19]
[972]    0.0    0.00    0.00  409746         unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [972]
                0.00    0.00 3182328/3182328     unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&) [965]
-----------------------------------------------
                0.00    0.00       4/387162      common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
                0.00    0.00  387158/387162      llm_load_vocab(llama_model_loader&, llama_model&) [19]
[973]    0.0    0.00    0.00  387162         bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [973]
-----------------------------------------------
                0.00    0.00  345268/345268      ggml_backend_sched_get_tensor_backend [32]
[974]    0.0    0.00    0.00  345268         ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
                0.00    0.00  217752/218779      ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [977]
                0.00    0.00  217752/218779      ggml_backend_buft_is_host [148]
                0.00    0.00  217752/217753      ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) [978]
                0.00    0.00  217752/217753      ggml_backend_dev_supports_buft [149]
                0.00    0.00  217752/217753      ggml_backend_supports_buft [150]
                0.00    0.00  217752/318551      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [975]
                0.00    0.00  217752/318551      ggml_backend_dev_supports_op [142]
                0.00    0.00  217752/318372      ggml_backend_supports_op [143]
-----------------------------------------------
                0.00    0.00      16/318551      llama_new_context_with_model [80]
                0.00    0.00     163/318551      weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [117]
                0.00    0.00   16448/318551      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00   84172/318551      ggml_backend_sched_get_tensor_backend [32]
                0.00    0.00  217752/318551      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[975]    0.0    0.00    0.00  318551         ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [975]
-----------------------------------------------
                0.00    0.00    1032/235296      std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [111]
                0.00    0.00   16512/235296      llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [69]
                0.00    0.00   41280/235296      llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [43]
                0.00    0.00   66048/235296      llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [68]
                0.00    0.00  110424/235296      llm_build_context::build_llama() [42]
[976]    0.0    0.00    0.00  235296         std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [976]
                0.00    0.00  231168/372584      ggml_format_name [140]
                0.00    0.00   16448/16449       ggml_backend_get_device [165]
                0.00    0.00   16448/318551      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [975]
                0.00    0.00   16448/318551      ggml_backend_dev_supports_op [142]
                0.00    0.00   16448/318372      ggml_backend_supports_op [143]
                0.00    0.00   16448/16448       ggml_backend_sched_set_tensor_backend [166]
                0.00    0.00    4128/4422        ggml_set_name [175]
-----------------------------------------------
                0.00    0.00       1/218779      ggml_backend_sched_new [295]
                0.00    0.00    1026/218779      llama_set_inputs(llama_context&, llama_ubatch const&) [100]
                0.00    0.00  217752/218779      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[977]    0.0    0.00    0.00  218779         ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [977]
-----------------------------------------------
                0.00    0.00       1/217753      ggml_backend_sched_new [295]
                0.00    0.00  217752/217753      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [974]
[978]    0.0    0.00    0.00  217753         ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) [978]
-----------------------------------------------
                0.00    0.00  130616/130616      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [980]
[979]    0.0    0.00    0.00  130616         llama_token_get_attr_impl(llama_vocab const&, int) [979]
-----------------------------------------------
                0.00    0.00     517/130616      common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [999]
                0.00    0.00  130099/130616      llm_load_vocab(llama_model_loader&, llama_model&) [19]
[980]    0.0    0.00    0.00  130616         llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [980]
                0.00    0.00  871921/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [966]
                0.00    0.00  871921/871921      unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [967]
                0.00    0.00  130616/130616      llama_token_get_attr_impl(llama_vocab const&, int) [979]
                0.00    0.00  129591/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [972]
-----------------------------------------------
                0.00    0.00  128292/128292      gguf_kv_to_str(gguf_context const*, int) [1044]
[981]    0.0    0.00    0.00  128292         gguf_data_to_str(gguf_type, void const*, int) [981]
                0.00    0.00       4/4           std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...) [1096]
-----------------------------------------------
                0.00    0.00  128256/128256      std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [52]
[982]    0.0    0.00    0.00  128256         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long) [982]
-----------------------------------------------
                0.00    0.00       1/1033        llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00    1032/1033        llama_decode_internal(llama_context&, llama_batch) [13]
[983]    0.0    0.00    0.00    1033         std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [983]
-----------------------------------------------
                0.00    0.00    1026/1026        main [7]
[984]    0.0    0.00    0.00    1026         llama_token_is_eog_impl(llama_vocab const&, int) [984]
-----------------------------------------------
                0.00    0.00    1026/1026        llama_set_inputs(llama_context&, llama_ubatch const&) [100]
[985]    0.0    0.00    0.00    1026         ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long) [985]
-----------------------------------------------
                0.00    0.00     512/1024        llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.00     512/1024        llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1011]
[986]    0.0    0.00    0.00    1024         llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [986]
                0.00    0.00       1/1           std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand() [1210]
-----------------------------------------------
                0.00    0.00     512/1024        llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) [1014]
                0.00    0.00     512/1024        llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1011]
[987]    0.0    0.00    0.00    1024         llama_sampler_softmax_impl(llama_token_data_array*) [987]
-----------------------------------------------
                0.00    0.00    1020/1020        (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [989]
[988]    0.0    0.00    0.00    1020         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long) [988]
-----------------------------------------------
                                2918             (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [989]
                0.00    0.00    1012/1012        llamafile_sgemm [9]
[989]    0.0    0.00    0.00    1012+2918    (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [989]
                0.00    0.00    1020/1020        void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long) [988]
                0.00    0.00     953/953         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long) [992]
                0.00    0.00     409/409         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long) [1024]
                                2918             (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [989]
-----------------------------------------------
                0.00    0.00       1/962         common_init() [1144]
                0.00    0.00       1/962         common_init_from_params(common_params&) [17]
                0.00    0.00     431/962         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [1022]
                0.00    0.00     529/962         main [7]
[990]    0.0    0.00    0.00     962         common_log_add(common_log*, ggml_log_level, char const*, ...) [990]
                0.00    0.00       2/258         std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [1027]
-----------------------------------------------
                0.00    0.00       1/962         common_init() [1144]
                0.00    0.00       1/962         common_init_from_params(common_params&) [17]
                0.00    0.00     431/962         common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) [1023]
                0.00    0.00     529/962         main [7]
[991]    0.0    0.00    0.00     962         common_log_main() [991]
                0.00    0.00     256/258         std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [1027]
                0.00    0.00       1/1           std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long) [1220]
-----------------------------------------------
                0.00    0.00     953/953         (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [989]
[992]    0.0    0.00    0.00     953         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long) [992]
-----------------------------------------------
                0.00    0.00       2/733         std::map<int, int, std::less<int>, std::allocator<std::pair<int const, int> > >::~map() [1924]
                0.00    0.00       2/733         std::map<int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<int>, std::allocator<std::pair<int const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::~map() [1923]
                0.00    0.00       2/733         std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> > >::~map() [1922]
                0.00    0.00       4/733         void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1097]
                0.00    0.00      10/733         unicode_byte_to_utf8[abi:cxx11](unsigned char) [1069]
                0.00    0.00      14/733         unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
                0.00    0.00     699/733         std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [1115]
[993]    0.0    0.00    0.00     733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [993]
-----------------------------------------------
                                  17             common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [994]
                0.00    0.00     127/565         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
                0.00    0.00     173/565         common_arg::common_arg(common_arg const&) [1032]
                0.00    0.00     265/565         common_arg::~common_arg() [1026]
[994]    0.0    0.00    0.00     565+17      common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [994]
                                  17             common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [994]
-----------------------------------------------
                0.00    0.00       1/528         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
                0.00    0.00       1/528         llama_new_context_with_model [80]
                0.00    0.00       1/528         llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00       2/528         llama_kv_cache_clear [337]
                0.00    0.00       7/528         llama_load_model_from_file [18]
                0.00    0.00     516/528         llama_free [336]
[995]    0.0    0.00    0.00     528         llama_format_tensor_shape(ggml_tensor const*) [995]
-----------------------------------------------
                0.00    0.00       3/524         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1106]
                0.00    0.00       9/524         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [1074]
                0.00    0.00      42/524         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
                0.00    0.00      45/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1050]
                0.00    0.00      50/524         common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [1046]
                0.00    0.00      96/524         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1043]
                0.00    0.00     106/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
                0.00    0.00     173/524         common_arg::common_arg(common_arg const&) [1032]
[996]    0.0    0.00    0.00     524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
-----------------------------------------------
                0.00    0.00       1/522         LLM_KV::operator()[abi:cxx11](llm_kv) const [1202]
                0.00    0.00       2/522         llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00       3/522         llama_state_seq_get_size [242]
                0.00    0.00       5/522         bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1091]
                0.00    0.00       5/522         bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1090]
                0.00    0.00      14/522         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00      25/522         llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00      28/522         bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
                0.00    0.00     439/522         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
[997]    0.0    0.00    0.00     522         format(char const*, ...) [997]
-----------------------------------------------
                0.00    0.00       2/520         llm_load_vocab(llama_model_loader&, llama_model&) [19]
                0.00    0.00     518/520         llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) [56]
[998]    0.0    0.00    0.00     520         std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [998]
-----------------------------------------------
                0.00    0.00     517/517         main [7]
[999]    0.0    0.00    0.00     517         common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [999]
                0.00    0.00     517/1030        llama_get_model [188]
                0.00    0.00     517/130616      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [980]
                0.00    0.00     517/130616      llama_token_to_piece [155]
-----------------------------------------------
                0.00    0.00     517/517         llama_sampler_chain_accept(llama_sampler*, int) [54]
[1000]   0.0    0.00    0.00     517         llama_sampler_dry_accept(llama_sampler*, int) [1000]
-----------------------------------------------
                0.00    0.00       1/516         llama_kv_cache_clear [337]
                0.00    0.00       1/516         llama_new_context_with_model [80]
                0.00    0.00     514/516         llama_output_reserve(llama_context&, unsigned long) [1007]
[1001]   0.0    0.00    0.00     516         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [1001]
-----------------------------------------------
                0.00    0.00     516/516         llama_build_graph(llama_context&, llama_ubatch const&, bool) [41]
[1002]   0.0    0.00    0.00     516         std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1002]
-----------------------------------------------
                0.00    0.00       1/515         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/515         llama_new_context_with_model [80]
                0.00    0.00     513/515         llama_decode_internal(llama_context&, llama_batch) [13]
[1003]   0.0    0.00    0.00     515         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [1003]
-----------------------------------------------
                0.00    0.00       1/515         console::cleanup() [1620]
                0.00    0.00     514/515         main [7]
[1004]   0.0    0.00    0.00     515         console::set_display(console::display_t) [1004]
-----------------------------------------------
                0.00    0.00     515/515         llama_decode_internal(llama_context&, llama_batch) [13]
[1005]   0.0    0.00    0.00     515         std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long) [1005]
-----------------------------------------------
                0.00    0.00     515/515         llama_decode_internal(llama_context&, llama_batch) [13]
[1006]   0.0    0.00    0.00     515         std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long) [1006]
-----------------------------------------------
                0.00    0.00       1/514         llama_new_context_with_model [80]
                0.00    0.00     513/514         llama_decode_internal(llama_context&, llama_batch) [13]
[1007]   0.0    0.00    0.00     514         llama_output_reserve(llama_context&, unsigned long) [1007]
                0.00    0.00     514/533399      ggml_backend_buffer_get_base [136]
                0.00    0.00     514/516         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [1001]
                0.00    0.00     514/516         ggml_backend_buffer_clear [197]
                0.00    0.00     513/178228      ggml_backend_buffer_get_size [152]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [250]
                0.00    0.00       1/164         ggml_backend_dev_host_buffer_type [222]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1103]
                0.00    0.00       1/182         ggml_backend_buft_alloc_buffer [220]
                0.00    0.00       1/1033        std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [983]
-----------------------------------------------
                0.00    0.00     513/513         main [7]
[1008]   0.0    0.00    0.00     513         common_sampler_last(common_sampler const*) [1008]
-----------------------------------------------
                0.00    0.00     513/513         llama_decode_internal(llama_context&, llama_batch) [13]
[1009]   0.0    0.00    0.00     513         ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long) [1009]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1010]   0.0    0.00    0.00     512         llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*) [1010]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1011]   0.0    0.00    0.00     512         llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1011]
                0.00    0.00     512/1024        llama_sampler_softmax_impl(llama_token_data_array*) [987]
                0.00    0.00     512/1024        llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [986]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1012]   0.0    0.00    0.00     512         llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*) [1012]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1013]   0.0    0.00    0.00     512         llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*) [1013]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1014]   0.0    0.00    0.00     512         llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) [1014]
                0.00    0.00     512/1024        llama_sampler_softmax_impl(llama_token_data_array*) [987]
-----------------------------------------------
                0.00    0.00     512/512         common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
[1015]   0.0    0.00    0.00     512         llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*) [1015]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1016]   0.0    0.00    0.00     512         llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*) [1016]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1017]   0.0    0.00    0.00     512         llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*) [1017]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1018]   0.0    0.00    0.00     512         llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*) [1018]
-----------------------------------------------
                0.00    0.00     512/512         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1019]   0.0    0.00    0.00     512         llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*) [1019]
-----------------------------------------------
                0.00    0.00     512/512         common_sampler_accept(common_sampler*, int, bool) [53]
[1020]   0.0    0.00    0.00     512         llama_sampler_grammar_accept_impl(llama_sampler*, int) [1020]
-----------------------------------------------
                0.00    0.00       1/431         main [7]
                0.00    0.00       1/431         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/431         common_perf_print(llama_context const*, common_sampler const*) [1146]
                0.00    0.00       3/431         llama_perf_context_print [345]
                0.00    0.00      15/431         llama_new_context_with_model [80]
                0.00    0.00      41/431         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00      52/431         llama_load_model_from_file [18]
                0.00    0.00      61/431         llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) [1034]
                0.00    0.00     256/431         llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1021]   0.0    0.00    0.00     431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00     431/431         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [1022]
-----------------------------------------------
                0.00    0.00     431/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
[1022]   0.0    0.00    0.00     431         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [1022]
                0.00    0.00     431/962         common_log_add(common_log*, ggml_log_level, char const*, ...) [990]
                0.00    0.00     431/431         common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) [1023]
-----------------------------------------------
                0.00    0.00     431/431         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [1022]
[1023]   0.0    0.00    0.00     431         common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) [1023]
                0.00    0.00     431/962         common_log_main() [991]
-----------------------------------------------
                0.00    0.00     409/409         (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [989]
[1024]   0.0    0.00    0.00     409         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long) [1024]
-----------------------------------------------
                0.00    0.00     385/385         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const [1031]
[1025]   0.0    0.00    0.00     385         common_arg::in_example(llama_example) [1025]
-----------------------------------------------
                0.00    0.00     376/376         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1026]   0.0    0.00    0.00     376         common_arg::~common_arg() [1026]
                0.00    0.00     265/565         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [994]
-----------------------------------------------
                0.00    0.00       2/258         common_log_add(common_log*, ggml_log_level, char const*, ...) [990]
                0.00    0.00     256/258         common_log_main() [991]
[1027]   0.0    0.00    0.00     258         std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [1027]
-----------------------------------------------
                0.00    0.00     256/256         std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [1030]
[1028]   0.0    0.00    0.00     256         std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long) [1028]
-----------------------------------------------
                0.00    0.00     256/256         unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [967]
[1029]   0.0    0.00    0.00     256         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&) [1029]
-----------------------------------------------
                0.00    0.00     256/256         unicode_byte_to_utf8[abi:cxx11](unsigned char) [1069]
[1030]   0.0    0.00    0.00     256         std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [1030]
                0.00    0.00     256/256         std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long) [1028]
-----------------------------------------------
                0.00    0.00     203/203         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1031]   0.0    0.00    0.00     203         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const [1031]
                0.00    0.00     385/385         common_arg::in_example(llama_example) [1025]
-----------------------------------------------
                0.00    0.00     173/173         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1032]   0.0    0.00    0.00     173         common_arg::common_arg(common_arg const&) [1032]
                0.00    0.00     173/565         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [994]
                0.00    0.00     173/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
-----------------------------------------------
                0.00    0.00     172/172         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1033]   0.0    0.00    0.00     172         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long) [1033]
-----------------------------------------------
                0.00    0.00     148/148         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
[1034]   0.0    0.00    0.00     148         llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) [1034]
                0.00    0.00      61/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[1035]   0.0    0.00    0.00     147         std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&) [1035]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[1036]   0.0    0.00    0.00     147         std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1036]
-----------------------------------------------
                0.00    0.00     120/120         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1037]   0.0    0.00    0.00     120         common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1037]
-----------------------------------------------
                0.00    0.00     120/120         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1038]   0.0    0.00    0.00     120         void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&) [1038]
-----------------------------------------------
                0.00    0.00       5/119         std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>) [1203]
                0.00    0.00      36/119         std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&) [1058]
                0.00    0.00      36/119         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>) [1137]
                0.00    0.00      42/119         __static_initialization_and_destruction_0() [1334]
[1039]   0.0    0.00    0.00     119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1039]
-----------------------------------------------
                0.00    0.00     107/107         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1040]   0.0    0.00    0.00     107         common_arg::set_examples(std::initializer_list<llama_example>) [1040]
                0.00    0.00     107/107         void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*) [1041]
-----------------------------------------------
                0.00    0.00     107/107         common_arg::set_examples(std::initializer_list<llama_example>) [1040]
[1041]   0.0    0.00    0.00     107         void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*) [1041]
-----------------------------------------------
                0.00    0.00     105/105         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1042]   0.0    0.00    0.00     105         string_format[abi:cxx11](char const*, ...) [1042]
-----------------------------------------------
                0.00    0.00      96/96          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1043]   0.0    0.00    0.00      96         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1043]
                0.00    0.00      96/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
-----------------------------------------------
                0.00    0.00       6/71          llama_load_model_from_file [18]
                0.00    0.00      30/71          llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00      35/71          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[1044]   0.0    0.00    0.00      71         gguf_kv_to_str(gguf_context const*, int) [1044]
                0.00    0.00  816834/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
                0.00    0.00  408417/816820      gguf_get_arr_str [133]
                0.00    0.00  128292/128292      gguf_data_to_str(gguf_type, void const*, int) [981]
                0.00    0.00      65/158         gguf_get_kv_type [223]
                0.00    0.00      36/36          gguf_get_val_data [230]
                0.00    0.00      24/30          gguf_get_val_str [231]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1064]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1063]
                0.00    0.00      16/560310      std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) [970]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1062]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1061]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1065]
                0.00    0.00       5/10          gguf_get_arr_type [238]
                0.00    0.00       5/12          gguf_get_arr_n [235]
                0.00    0.00       5/6           gguf_get_arr_data [248]
-----------------------------------------------
                0.00    0.00      60/60          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1045]   0.0    0.00    0.00      60         common_arg::set_env(char const*) [1045]
-----------------------------------------------
                0.00    0.00      50/50          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1046]   0.0    0.00    0.00      50         common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [1046]
                0.00    0.00      50/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
-----------------------------------------------
                0.00    0.00      50/50          __static_initialization_and_destruction_0() [1070]
[1047]   0.0    0.00    0.00      50         std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [1047]
                0.00    0.00      50/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
-----------------------------------------------
                0.00    0.00      50/50          __static_initialization_and_destruction_0() [1070]
[1048]   0.0    0.00    0.00      50         std::__throw_regex_error(std::regex_constants::error_type, char const*) [1048]
-----------------------------------------------
                0.00    0.00       1/49          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
                0.00    0.00       5/49          bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1091]
                0.00    0.00       5/49          bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1090]
                0.00    0.00      10/49          llama_state_seq_get_size [242]
                0.00    0.00      28/49          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
[1049]   0.0    0.00    0.00      49         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1049]
-----------------------------------------------
                0.00    0.00      45/45          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1050]   0.0    0.00    0.00      45         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1050]
                0.00    0.00      45/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
-----------------------------------------------
                0.00    0.00       1/32          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1099]
                0.00    0.00       3/32          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1088]
                0.00    0.00       6/32          std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
                0.00    0.00       7/32          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
                0.00    0.00      15/32          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1056]
[1051]   0.0    0.00    0.00      32         std::__detail::_Scanner<char>::_M_advance() [1051]
-----------------------------------------------
                0.00    0.00      30/30          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1052]   0.0    0.00    0.00      30         common_arg::set_sparam() [1052]
-----------------------------------------------
                0.00    0.00      30/30          llm_load_hparams(llama_model_loader&, llama_model&) [1165]
[1053]   0.0    0.00    0.00      30         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long) [1053]
-----------------------------------------------
                0.00    0.00      10/28          llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00      18/28          llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1054]   0.0    0.00    0.00      28         bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
                0.00    0.00      28/522         format(char const*, ...) [997]
                0.00    0.00      28/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1049]
                0.00    0.00      28/58          gguf_find_key [228]
                0.00    0.00       9/158         gguf_get_kv_type [223]
                0.00    0.00       9/13          gguf_get_val_u32 [234]
-----------------------------------------------
                0.00    0.00       1/26          llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [58]
                0.00    0.00       2/26          common_init_from_params(common_params&) [17]
                0.00    0.00       5/26          llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
                0.00    0.00      18/26          main [7]
[1055]   0.0    0.00    0.00      26         void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1055]
-----------------------------------------------
                0.00    0.00       3/25          void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
                0.00    0.00       6/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [1089]
                0.00    0.00      16/25          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
[1056]   0.0    0.00    0.00      25         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1056]
                0.00    0.00      15/22          std::__detail::_Scanner<char>::_M_scan_in_bracket() [1057]
                0.00    0.00      15/32          std::__detail::_Scanner<char>::_M_advance() [1051]
-----------------------------------------------
                0.00    0.00       3/22          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1088]
                0.00    0.00       4/22          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
                0.00    0.00      15/22          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1056]
[1057]   0.0    0.00    0.00      22         std::__detail::_Scanner<char>::_M_scan_in_bracket() [1057]
                0.00    0.00       3/3           std::__detail::_Scanner<char>::_M_eat_escape_ecma() [1119]
-----------------------------------------------
                0.00    0.00      18/18          __static_initialization_and_destruction_0() [1334]
[1058]   0.0    0.00    0.00      18         std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&) [1058]
                0.00    0.00      36/119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1039]
-----------------------------------------------
                0.00    0.00      18/18          __static_initialization_and_destruction_0() [1334]
[1059]   0.0    0.00    0.00      18         std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::~vector() [1059]
-----------------------------------------------
                0.00    0.00      17/17          llama_print_system_info [349]
[1060]   0.0    0.00    0.00      17         std::__cxx11::to_string(int) [1060]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [1044]
[1061]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1061]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [1044]
[1062]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1062]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [1044]
[1063]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1063]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [1044]
[1064]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1064]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [1044]
[1065]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1065]
-----------------------------------------------
                0.00    0.00      15/15          void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
[1066]   0.0    0.00    0.00      15         bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
                0.00    0.00      16/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1056]
                0.00    0.00       7/32          std::__detail::_Scanner<char>::_M_advance() [1051]
                0.00    0.00       6/8           void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [1079]
                0.00    0.00       4/22          std::__detail::_Scanner<char>::_M_scan_in_bracket() [1057]
                0.00    0.00       3/3           void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&) [1112]
                0.00    0.00       1/4           std::__detail::_Scanner<char>::_M_scan_normal() [1098]
                0.00    0.00       1/1           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const [1242]
-----------------------------------------------
                0.00    0.00       1/13          unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
                0.00    0.00      12/13          unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1133]
[1067]   0.0    0.00    0.00      13         unicode_cpt_flags(unsigned int) [1067]
-----------------------------------------------
                0.00    0.00       1/12          std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [1233]
                0.00    0.00       2/12          std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [1117]
                0.00    0.00       2/12          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
                0.00    0.00       3/12          std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [1118]
                0.00    0.00       4/12          std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
[1068]   0.0    0.00    0.00      12         void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1068]
-----------------------------------------------
                0.00    0.00      10/10          unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
[1069]   0.0    0.00    0.00      10         unicode_byte_to_utf8[abi:cxx11](unsigned char) [1069]
                0.00    0.00     256/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [966]
                0.00    0.00     256/256         std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [1030]
                0.00    0.00      10/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [993]
-----------------------------------------------
                0.00    0.00      10/10          __static_initialization_and_destruction_0() [1334]
[1070]   0.0    0.00    0.00      10         __static_initialization_and_destruction_0() [1070]
                0.00    0.00     201/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
                0.00    0.00      50/50          std::__throw_regex_error(std::regex_constants::error_type, char const*) [1048]
                0.00    0.00      50/50          std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [1047]
                0.00    0.00       1/1           std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&) [1214]
                0.00    0.00       1/1           std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&) [1213]
                0.00    0.00       1/1           std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [1215]
                0.00    0.00       1/1           std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&) [1212]
                0.00    0.00       1/1           std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&) [1211]
-----------------------------------------------
                0.00    0.00      10/10          llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
[1071]   0.0    0.00    0.00      10         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1071]
-----------------------------------------------
                0.00    0.00       2/9           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [58]
                0.00    0.00       3/9           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
                0.00    0.00       4/9           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1077]
[1072]   0.0    0.00    0.00       9         tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1072]
-----------------------------------------------
                0.00    0.00       2/9           ggml_backend_reg_get [269]
                0.00    0.00       7/9           ggml_backend_dev_get [243]
[1073]   0.0    0.00    0.00       9         get_reg() [1073]
-----------------------------------------------
                0.00    0.00       9/9           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1074]   0.0    0.00    0.00       9         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [1074]
                0.00    0.00       9/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
-----------------------------------------------
                0.00    0.00       9/9           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
[1075]   0.0    0.00    0.00       9         void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&) [1075]
-----------------------------------------------
                0.00    0.00       9/9           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1076]   0.0    0.00    0.00       9         void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&) [1076]
-----------------------------------------------
                0.00    0.00       8/8           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
[1077]   0.0    0.00    0.00       8         llm_tokenizer_bpe_session::add_new_bigram(int, int) [1077]
                0.00    0.00       6/6           llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1084]
                0.00    0.00       4/9           tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1072]
                0.00    0.00       3/3           void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&) [1110]
-----------------------------------------------
                0.00    0.00       8/8           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1078]   0.0    0.00    0.00       8         void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&) [1078]
-----------------------------------------------
                0.00    0.00       2/8           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
                0.00    0.00       6/8           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
[1079]   0.0    0.00    0.00       8         void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [1079]
-----------------------------------------------
                0.00    0.00       7/7           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1080]   0.0    0.00    0.00       7         string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1080]
-----------------------------------------------
                0.00    0.00       7/7           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1081]   0.0    0.00    0.00       7         common_sampler_type_to_chr(common_sampler_type) [1081]
-----------------------------------------------
                0.00    0.00       7/7           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1082]   0.0    0.00    0.00       7         common_sampler_type_to_str[abi:cxx11](common_sampler_type) [1082]
-----------------------------------------------
                0.00    0.00       1/7           llama_new_context_with_model [80]
                0.00    0.00       1/7           llama_load_model_from_file [18]
                0.00    0.00       2/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       3/7           ggml_backend_dev_by_type [257]
[1083]   0.0    0.00    0.00       7         ggml_backend_cpu_device_get_type(ggml_backend_device*) [1083]
-----------------------------------------------
                0.00    0.00       6/6           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1077]
[1084]   0.0    0.00    0.00       6         llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1084]
-----------------------------------------------
                0.00    0.00       3/6           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
                0.00    0.00       3/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
[1085]   0.0    0.00    0.00       6         void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [1085]
-----------------------------------------------
                0.00    0.00       6/6           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1086]   0.0    0.00    0.00       6         std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1086]
-----------------------------------------------
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
[1087]   0.0    0.00    0.00       6         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion() [1087]
-----------------------------------------------
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
[1088]   0.0    0.00    0.00       6         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1088]
                0.00    0.00       3/22          std::__detail::_Scanner<char>::_M_scan_in_bracket() [1057]
                0.00    0.00       3/32          std::__detail::_Scanner<char>::_M_advance() [1051]
                0.00    0.00       3/3           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
-----------------------------------------------
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
[1089]   0.0    0.00    0.00       6         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [1089]
                0.00    0.00       6/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1056]
-----------------------------------------------
                0.00    0.00       1/5           llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00       4/5           llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1090]   0.0    0.00    0.00       5         bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1090]
                0.00    0.00       5/522         format(char const*, ...) [997]
                0.00    0.00       5/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1049]
                0.00    0.00       5/58          gguf_find_key [228]
-----------------------------------------------
                0.00    0.00       5/5           llm_load_hparams(llama_model_loader&, llama_model&) [1165]
[1091]   0.0    0.00    0.00       5         bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1091]
                0.00    0.00       5/522         format(char const*, ...) [997]
                0.00    0.00       5/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1049]
                0.00    0.00       5/58          gguf_find_key [228]
                0.00    0.00       2/158         gguf_get_kv_type [223]
                0.00    0.00       2/2           gguf_get_val_f32 [279]
-----------------------------------------------
                0.00    0.00       2/5           unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1133]
                0.00    0.00       3/5           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
[1092]   0.0    0.00    0.00       5         void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [1092]
-----------------------------------------------
                0.00    0.00       4/4           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1093]   0.0    0.00    0.00       4         postprocess_cpu_params(cpu_params&, cpu_params const*) [1093]
                0.00    0.00       1/1           cpu_get_num_math() [1145]
-----------------------------------------------
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [250]
                0.00    0.00       1/4           ggml_backend_cpu_init [288]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_from_ptr [287]
                0.00    0.00       1/4           ggml_backend_reg_count [246]
[1094]   0.0    0.00    0.00       4         ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1094]
                0.00    0.00       1/1           ggml_backend_cpu_device_context::ggml_backend_cpu_device_context() [1199]
-----------------------------------------------
                0.00    0.00       4/4           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[1095]   0.0    0.00    0.00       4         llama_data_write_file::write(void const*, unsigned long) [1095]
-----------------------------------------------
                0.00    0.00       4/4           gguf_data_to_str(gguf_type, void const*, int) [981]
[1096]   0.0    0.00    0.00       4         std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...) [1096]
-----------------------------------------------
                0.00    0.00       4/4           unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
[1097]   0.0    0.00    0.00       4         void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1097]
                0.00    0.00       4/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [993]
-----------------------------------------------
                0.00    0.00       1/4           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
                0.00    0.00       3/4           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
[1098]   0.0    0.00    0.00       4         std::__detail::_Scanner<char>::_M_scan_normal() [1098]
-----------------------------------------------
                0.00    0.00       4/4           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
[1099]   0.0    0.00    0.00       4         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1099]
                0.00    0.00       1/32          std::__detail::_Scanner<char>::_M_advance() [1051]
                0.00    0.00       1/1           std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back() [1216]
                0.00    0.00       1/1           std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [1233]
-----------------------------------------------
                0.00    0.00       3/3           ggml_backend_buffer_free [217]
[1100]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*) [1100]
-----------------------------------------------
                0.00    0.00       3/3           llama_new_context_with_model [80]
[1101]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*) [1101]
-----------------------------------------------
                0.00    0.00       1/3           llama_new_context_with_model [80]
                0.00    0.00       2/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1102]   0.0    0.00    0.00       3         ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) [1102]
-----------------------------------------------
                0.00    0.00       1/3           alloc_tensor_range [119]
                0.00    0.00       1/3           ggml_gallocr_reserve_n [95]
                0.00    0.00       1/3           llama_output_reserve(llama_context&, unsigned long) [1007]
[1103]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1103]
                0.00    0.00       3/705         ggml_aligned_malloc [195]
                0.00    0.00       3/183         ggml_backend_buffer_init [219]
-----------------------------------------------
                0.00    0.00       1/3           ggml_tallocr_new [323]
                0.00    0.00       1/3           ggml_gallocr_new_n [319]
                0.00    0.00       1/3           ggml_backend_alloc_ctx_tensors_from_buft [116]
[1104]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1104]
-----------------------------------------------
                0.00    0.00       3/3           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1105]   0.0    0.00    0.00       3         common_arg::has_value_from_env() [1105]
-----------------------------------------------
                0.00    0.00       3/3           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
[1106]   0.0    0.00    0.00       3         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1106]
                0.00    0.00       3/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
-----------------------------------------------
                0.00    0.00       3/3           std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() [1109]
[1107]   0.0    0.00    0.00       3         std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1107]
                0.00    0.00       3/3           std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher() [1116]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::~basic_regex() [2047]
[1108]   0.0    0.00    0.00       3         std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_destroy() [1108]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::~basic_regex() [2047]
[1109]   0.0    0.00    0.00       3         std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() [1109]
                0.00    0.00       3/3           std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1107]
-----------------------------------------------
                0.00    0.00       3/3           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1077]
[1110]   0.0    0.00    0.00       3         void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&) [1110]
-----------------------------------------------
                0.00    0.00       1/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [115]
                0.00    0.00       1/3           llama_new_context_with_model [80]
                0.00    0.00       1/3           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[1111]   0.0    0.00    0.00       3         void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1111]
-----------------------------------------------
                0.00    0.00       3/3           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
[1112]   0.0    0.00    0.00       3         void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&) [1112]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type) [1114]
[1113]   0.0    0.00    0.00       3         std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
                0.00    0.00       6/32          std::__detail::_Scanner<char>::_M_advance() [1051]
                0.00    0.00       4/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1068]
                0.00    0.00       3/4           std::__detail::_Scanner<char>::_M_scan_normal() [1098]
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [1121]
                0.00    0.00       3/5           void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [1092]
                0.00    0.00       3/3           std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [1117]
-----------------------------------------------
                0.00    0.00       3/3           __static_initialization_and_destruction_0() [1334]
[1114]   0.0    0.00    0.00       3         std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type) [1114]
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
-----------------------------------------------
                0.00    0.00       3/3           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
[1115]   0.0    0.00    0.00       3         std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [1115]
                0.00    0.00     699/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [993]
-----------------------------------------------
                0.00    0.00       3/3           std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1107]
[1116]   0.0    0.00    0.00       3         std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher() [1116]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
[1117]   0.0    0.00    0.00       3         std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [1117]
                0.00    0.00       2/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1068]
-----------------------------------------------
                0.00    0.00       3/3           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
[1118]   0.0    0.00    0.00       3         std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [1118]
                0.00    0.00       3/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1068]
-----------------------------------------------
                0.00    0.00       3/3           std::__detail::_Scanner<char>::_M_scan_in_bracket() [1057]
[1119]   0.0    0.00    0.00       3         std::__detail::_Scanner<char>::_M_eat_escape_ecma() [1119]
-----------------------------------------------
                                   3             std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [1121]
[1120]   0.0    0.00    0.00       3+3       std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion() [1087]
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1088]
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [1089]
                0.00    0.00       4/4           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1099]
                0.00    0.00       3/6           void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [1085]
                0.00    0.00       2/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1068]
                                   3             std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1113]
[1121]   0.0    0.00    0.00       3         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [1121]
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1120]
-----------------------------------------------
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1088]
[1122]   0.0    0.00    0.00       3         void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1122]
                0.00    0.00      15/15          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
                0.00    0.00       3/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1056]
                0.00    0.00       3/3           std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [1115]
                0.00    0.00       3/3           std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [1118]
                0.00    0.00       3/6           void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [1085]
                0.00    0.00       2/8           void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [1079]
-----------------------------------------------
                0.00    0.00       3/3           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1123]   0.0    0.00    0.00       3         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1123]
-----------------------------------------------
                0.00    0.00       2/2           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [59]
[1124]   0.0    0.00    0.00       2         unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
                0.00    0.00      18/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [966]
                0.00    0.00      14/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [993]
                0.00    0.00      10/10          unicode_byte_to_utf8[abi:cxx11](unsigned char) [1069]
                0.00    0.00       6/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [972]
                0.00    0.00       4/4           void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1097]
                0.00    0.00       2/2           unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1133]
                0.00    0.00       1/13          unicode_cpt_flags(unsigned int) [1067]
-----------------------------------------------
                0.00    0.00       1/2           llama_new_context_with_model [80]
                0.00    0.00       1/2           common_init_from_params(common_params&) [17]
[1125]   0.0    0.00    0.00       2         llama_token_bos_impl(llama_vocab const&) [1125]
-----------------------------------------------
                0.00    0.00       1/2           common_init_from_params(common_params&) [17]
                0.00    0.00       1/2           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[1126]   0.0    0.00    0.00       2         llama_token_eos_impl(llama_vocab const&) [1126]
-----------------------------------------------
                0.00    0.00       2/2           main [7]
[1127]   0.0    0.00    0.00       2         ggml_threadpool_params_from_cpu_params(cpu_params const&) [1127]
                0.00    0.00       2/3           ggml_threadpool_params_init [260]
-----------------------------------------------
                0.00    0.00       2/2           main [7]
[1128]   0.0    0.00    0.00       2         print_usage(int, char**) [1128]
-----------------------------------------------
                0.00    0.00       1/2           llama_sampler_init_dist [354]
                0.00    0.00       1/2           llama_sampler_init_xtc [364]
[1129]   0.0    0.00    0.00       2         get_rng_seed(unsigned int) [1129]
-----------------------------------------------
                0.00    0.00       2/2           common_context_params_to_llama(common_params const&) [1161]
[1130]   0.0    0.00    0.00       2         kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1130]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_by_name [267]
[1131]   0.0    0.00    0.00       2         ggml_backend_cpu_reg_get_name(ggml_backend_reg*) [1131]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[1132]   0.0    0.00    0.00       2         ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) [1132]
-----------------------------------------------
                0.00    0.00       2/2           unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1124]
[1133]   0.0    0.00    0.00       2         unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1133]
                0.00    0.00      12/13          unicode_cpt_flags(unsigned int) [1067]
                0.00    0.00       2/2           std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long) [1142]
                0.00    0.00       2/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [972]
                0.00    0.00       2/5           void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [1092]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_count [246]
[1134]   0.0    0.00    0.00       2         ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*) [1134]
-----------------------------------------------
                0.00    0.00       2/2           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
[1135]   0.0    0.00    0.00       2         llama_mmap::unmap_fragment(unsigned long, unsigned long) [1135]
-----------------------------------------------
                0.00    0.00       1/2           main [7]
                0.00    0.00       1/2           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1136]   0.0    0.00    0.00       2         common_params::~common_params() [1136]
-----------------------------------------------
                0.00    0.00       2/2           __static_initialization_and_destruction_0() [1334]
[1137]   0.0    0.00    0.00       2         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>) [1137]
                0.00    0.00      36/119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1039]
-----------------------------------------------
                0.00    0.00       2/2           __static_initialization_and_destruction_0() [1334]
[1138]   0.0    0.00    0.00       2         std::_Hashtable<char, char, std::allocator<char>, std::__detail::_Identity, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, true, true> >::_Hashtable<char const*>(char const*, char const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<char> const&, std::integral_constant<bool, true>) [1138]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[1139]   0.0    0.00    0.00       2         std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long) [1139]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/2           llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [113]
[1140]   0.0    0.00    0.00       2         std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [1140]
-----------------------------------------------
                0.00    0.00       2/2           llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [38]
[1141]   0.0    0.00    0.00       2         std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long) [1141]
-----------------------------------------------
                0.00    0.00       2/2           unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1133]
[1142]   0.0    0.00    0.00       2         std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long) [1142]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
                0.00    0.00       1/2           llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1143]   0.0    0.00    0.00       2         void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1143]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1144]   0.0    0.00    0.00       1         common_init() [1144]
                0.00    0.00       1/1           llama_log_set [338]
                0.00    0.00       1/962         common_log_main() [991]
                0.00    0.00       1/962         common_log_add(common_log*, ggml_log_level, char const*, ...) [990]
-----------------------------------------------
                0.00    0.00       1/1           postprocess_cpu_params(cpu_params&, cpu_params const*) [1093]
[1145]   0.0    0.00    0.00       1         cpu_get_num_math() [1145]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1146]   0.0    0.00    0.00       1         common_perf_print(llama_context const*, common_sampler const*) [1146]
                0.00    0.00       1/431         llama_log_internal(ggml_log_level, char const*, ...) [1021]
                0.00    0.00       1/1           llama_perf_sampler_print [348]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1147]   0.0    0.00    0.00       1         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
                0.00    0.00     172/172         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long) [1033]
                0.00    0.00     127/565         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [994]
                0.00    0.00     120/120         common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1037]
                0.00    0.00      42/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
                0.00    0.00       7/7           string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1080]
                0.00    0.00       6/6           std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1086]
                0.00    0.00       4/4           postprocess_cpu_params(cpu_params&, cpu_params const*) [1093]
                0.00    0.00       3/3           std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1123]
                0.00    0.00       3/3           common_arg::has_value_from_env() [1105]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
                0.00    0.00       1/1           common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*) [1234]
                0.00    0.00       1/1           common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*) [1235]
                0.00    0.00       1/2           common_params::~common_params() [1136]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1238]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1239]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int) [1240]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1148]   0.0    0.00    0.00       1         common_sampler_free(common_sampler*) [1148]
                0.00    0.00       2/2           llama_sampler_free <cycle 1> [236]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1149]   0.0    0.00    0.00       1         common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
                0.00    0.00      10/10          llama_sampler_chain_add [239]
                0.00    0.00       2/514         llama_n_vocab [203]
                0.00    0.00       1/1           llama_sampler_chain_default_params [351]
                0.00    0.00       1/1           common_sampler_params::common_sampler_params(common_sampler_params const&) [1198]
                0.00    0.00       1/1           llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*) [1162]
                0.00    0.00       1/1           llama_sampler_init_grammar [356]
                0.00    0.00       1/1           llama_sampler_chain_init [352]
                0.00    0.00       1/1           llama_sampler_init_logit_bias [357]
                0.00    0.00       1/2           llama_token_eos_impl(llama_vocab const&) [1126]
                0.00    0.00       1/2           llama_token_eos [284]
                0.00    0.00       1/1           llama_token_nl_impl(llama_vocab const&) [1150]
                0.00    0.00       1/1           llama_token_nl [366]
                0.00    0.00       1/1           llama_sampler_init_penalties [359]
                0.00    0.00       1/1           llama_sampler_init_dist [354]
                0.00    0.00       1/1           llama_sampler_init_xtc [364]
                0.00    0.00       1/1           llama_sampler_init_temp_ext [360]
                0.00    0.00       1/1           llama_sampler_init_typical [363]
                0.00    0.00       1/1           llama_sampler_init_min_p [358]
                0.00    0.00       1/1           llama_sampler_init_top_p [362]
                0.00    0.00       1/1           llama_sampler_init_top_k [361]
                0.00    0.00       1/1           llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long) [1158]
                0.00    0.00       1/1           llama_sampler_init_dry [355]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[1150]   0.0    0.00    0.00       1         llama_token_nl_impl(llama_vocab const&) [1150]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1151]   0.0    0.00    0.00       1         common_sampler_print[abi:cxx11](common_sampler const*) [1151]
                0.00    0.00      11/11          llama_sampler_chain_n [237]
                0.00    0.00      10/10          llama_sampler_chain_get [240]
                0.00    0.00      10/10          llama_sampler_name [241]
                0.00    0.00       1/1           llama_sampler_dist_name(llama_sampler const*) [1174]
                0.00    0.00       1/1           llama_sampler_temp_ext_name(llama_sampler const*) [1186]
                0.00    0.00       1/1           llama_sampler_xtc_name(llama_sampler const*) [1172]
                0.00    0.00       1/1           llama_sampler_min_p_name(llama_sampler const*) [1177]
                0.00    0.00       1/1           llama_sampler_top_p_name(llama_sampler const*) [1181]
                0.00    0.00       1/1           llama_sampler_typical_name(llama_sampler const*) [1184]
                0.00    0.00       1/1           llama_sampler_top_k_name(llama_sampler const*) [1179]
                0.00    0.00       1/1           llama_sampler_dry_name(llama_sampler const*) [1170]
                0.00    0.00       1/1           llama_sampler_penalties_name(llama_sampler const*) [1188]
                0.00    0.00       1/1           llama_sampler_logit_bias_name(llama_sampler const*) [1190]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1152]   0.0    0.00    0.00       1         set_process_priority(ggml_sched_priority) [1152]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1153]   0.0    0.00    0.00       1         common_sampler_get_seed(common_sampler const*) [1153]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1154]   0.0    0.00    0.00       1         llama_add_bos_token_impl(llama_vocab const&) [1154]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1155]   0.0    0.00    0.00       1         llama_add_eos_token_impl(llama_vocab const&) [1155]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1156]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1156]
                0.00    0.00     376/376         common_arg::~common_arg() [1026]
                0.00    0.00     203/203         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const [1031]
                0.00    0.00     173/173         common_arg::common_arg(common_arg const&) [1032]
                0.00    0.00     120/120         void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&) [1038]
                0.00    0.00     107/107         common_arg::set_examples(std::initializer_list<llama_example>) [1040]
                0.00    0.00     106/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [996]
                0.00    0.00     105/105         string_format[abi:cxx11](char const*, ...) [1042]
                0.00    0.00      96/96          common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1043]
                0.00    0.00      60/60          common_arg::set_env(char const*) [1045]
                0.00    0.00      50/50          common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [1046]
                0.00    0.00      45/45          common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1050]
                0.00    0.00      30/30          common_arg::set_sparam() [1052]
                0.00    0.00       9/9           common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [1074]
                0.00    0.00       8/8           void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&) [1078]
                0.00    0.00       7/7           common_sampler_type_to_chr(common_sampler_type) [1081]
                0.00    0.00       7/7           common_sampler_type_to_str[abi:cxx11](common_sampler_type) [1082]
                0.00    0.00       4/387162      bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [973]
                0.00    0.00       3/3           common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1106]
                0.00    0.00       1/2           llama_supports_rpc [282]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [17]
[1157]   0.0    0.00    0.00       1         common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1157]
                0.00    0.00       1/1           llama_lora_adapter_clear [339]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[1158]   0.0    0.00    0.00       1         llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long) [1158]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [17]
[1159]   0.0    0.00    0.00       1         common_model_params_to_llama(common_params const&) [1159]
                0.00    0.00       1/1           llama_model_default_params [340]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1160]   0.0    0.00    0.00       1         common_params_get_system_info[abi:cxx11](common_params const&) [1160]
                0.00    0.00       1/1           llama_print_system_info [349]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [17]
[1161]   0.0    0.00    0.00       1         common_context_params_to_llama(common_params const&) [1161]
                0.00    0.00       2/2           kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1130]
                0.00    0.00       1/1           llama_context_default_params [335]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[1162]   0.0    0.00    0.00       1         llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*) [1162]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1163]   0.0    0.00    0.00       1         llm_load_arch(llama_model_loader&, llama_model&) [1163]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1164]   0.0    0.00    0.00       1         write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&) [1164]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1165]   0.0    0.00    0.00       1         llm_load_hparams(llama_model_loader&, llama_model&) [1165]
                0.00    0.00      36/818795      gguf_get_n_kv [132]
                0.00    0.00      35/158         gguf_get_kv_type [223]
                0.00    0.00      30/1613        gguf_get_key [182]
                0.00    0.00      30/71          gguf_kv_to_str(gguf_context const*, int) [1044]
                0.00    0.00      30/30          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long) [1053]
                0.00    0.00      10/28          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1054]
                0.00    0.00       5/10          llama_state_seq_get_size [242]
                0.00    0.00       5/5           bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1091]
                0.00    0.00       2/522         format(char const*, ...) [997]
                0.00    0.00       1/5           bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1090]
                0.00    0.00       1/1           llama_rope_type [350]
-----------------------------------------------
                0.00    0.00       1/1           llama_free [336]
[1166]   0.0    0.00    0.00       1         ggml_backend_cpu_free(ggml_backend*) [1166]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1167]   0.0    0.00    0.00       1         llama_model_type_name(e_model) [1167]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1168]   0.0    0.00    0.00       1         llama_model_ftype_name(llama_ftype) [1168]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1169]   0.0    0.00    0.00       1         llama_sampler_dry_free(llama_sampler*) [1169]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1170]   0.0    0.00    0.00       1         llama_sampler_dry_name(llama_sampler const*) [1170]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1171]   0.0    0.00    0.00       1         llama_sampler_xtc_free(llama_sampler*) [1171]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1172]   0.0    0.00    0.00       1         llama_sampler_xtc_name(llama_sampler const*) [1172]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1173]   0.0    0.00    0.00       1         llama_sampler_dist_free(llama_sampler*) [1173]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1174]   0.0    0.00    0.00       1         llama_sampler_dist_name(llama_sampler const*) [1174]
-----------------------------------------------
                                   1             llama_sampler_free <cycle 1> [236]
[1175]   0.0    0.00    0.00       1         llama_sampler_chain_free(llama_sampler*) <cycle 1> [1175]
                                  10             llama_sampler_free <cycle 1> [236]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1176]   0.0    0.00    0.00       1         llama_sampler_min_p_free(llama_sampler*) [1176]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1177]   0.0    0.00    0.00       1         llama_sampler_min_p_name(llama_sampler const*) [1177]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1178]   0.0    0.00    0.00       1         llama_sampler_top_k_free(llama_sampler*) [1178]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1179]   0.0    0.00    0.00       1         llama_sampler_top_k_name(llama_sampler const*) [1179]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1180]   0.0    0.00    0.00       1         llama_sampler_top_p_free(llama_sampler*) [1180]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1181]   0.0    0.00    0.00       1         llama_sampler_top_p_name(llama_sampler const*) [1181]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1182]   0.0    0.00    0.00       1         llama_sampler_grammar_free(llama_sampler*) [1182]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1183]   0.0    0.00    0.00       1         llama_sampler_typical_free(llama_sampler*) [1183]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1184]   0.0    0.00    0.00       1         llama_sampler_typical_name(llama_sampler const*) [1184]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1185]   0.0    0.00    0.00       1         llama_sampler_temp_ext_free(llama_sampler*) [1185]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1186]   0.0    0.00    0.00       1         llama_sampler_temp_ext_name(llama_sampler const*) [1186]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1187]   0.0    0.00    0.00       1         llama_sampler_penalties_free(llama_sampler*) [1187]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1188]   0.0    0.00    0.00       1         llama_sampler_penalties_name(llama_sampler const*) [1188]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [236]
[1189]   0.0    0.00    0.00       1         llama_sampler_logit_bias_free(llama_sampler*) [1189]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1151]
[1190]   0.0    0.00    0.00       1         llama_sampler_logit_bias_name(llama_sampler const*) [1190]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1191]   0.0    0.00    0.00       1         ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*) [1191]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1192]   0.0    0.00    0.00       1         ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long) [1192]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1193]   0.0    0.00    0.00       1         ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*) [1193]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1194]   0.0    0.00    0.00       1         llama_vocab::init_tokenizer() [1194]
                0.00    0.00       1/1           llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [1196]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1195]   0.0    0.00    0.00       1         common_params::common_params() [1195]
-----------------------------------------------
                0.00    0.00       1/1           llama_vocab::init_tokenizer() [1194]
[1196]   0.0    0.00    0.00       1         llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [1196]
                0.00    0.00       1/1           std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) [1236]
-----------------------------------------------
                0.00    0.00       1/1           llama_vocab::~llama_vocab() [47]
[1197]   0.0    0.00    0.00       1         llm_tokenizer_bpe::~llm_tokenizer_bpe() [1197]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1149]
[1198]   0.0    0.00    0.00       1         common_sampler_params::common_sampler_params(common_sampler_params const&) [1198]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1094]
[1199]   0.0    0.00    0.00       1         ggml_backend_cpu_device_context::ggml_backend_cpu_device_context() [1199]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1200]   0.0    0.00    0.00       1         console::init(bool, bool) [1200]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1201]   0.0    0.00    0.00       1         common_sampler_params::print[abi:cxx11]() const [1201]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1202]   0.0    0.00    0.00       1         LLM_KV::operator()[abi:cxx11](llm_kv) const [1202]
                0.00    0.00       1/522         format(char const*, ...) [997]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1334]
[1203]   0.0    0.00    0.00       1         std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>) [1203]
                0.00    0.00       5/119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1039]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1204]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1204]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1205]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1205]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1206]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1206]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1207]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1207]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1208]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1208]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [18]
[1209]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1209]
-----------------------------------------------
                0.00    0.00       1/1           llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [986]
[1210]   0.0    0.00    0.00       1         std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand() [1210]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1070]
[1211]   0.0    0.00    0.00       1         std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&) [1211]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1070]
[1212]   0.0    0.00    0.00       1         std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&) [1212]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1070]
[1213]   0.0    0.00    0.00       1         std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&) [1213]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1070]
[1214]   0.0    0.00    0.00       1         std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&) [1214]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1070]
[1215]   0.0    0.00    0.00       1         std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [1215]
                0.00    0.00      50/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [969]
-----------------------------------------------
                0.00    0.00       1/1           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1099]
[1216]   0.0    0.00    0.00       1         std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back() [1216]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1217]   0.0    0.00    0.00       1         std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long) [1217]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1218]   0.0    0.00    0.00       1         std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long) [1218]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1219]   0.0    0.00    0.00       1         std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector() [1219]
-----------------------------------------------
                0.00    0.00       1/1           common_log_main() [991]
[1220]   0.0    0.00    0.00       1         std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long) [1220]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_sample(common_sampler*, llama_context*, int, bool) [16]
[1221]   0.0    0.00    0.00       1         std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long) [1221]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1222]   0.0    0.00    0.00       1         std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector() [1222]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1223]   0.0    0.00    0.00       1         std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long) [1223]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1224]   0.0    0.00    0.00       1         std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long) [1224]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_reg_count [246]
[1225]   0.0    0.00    0.00       1         void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&) [1225]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_reg_count [246]
[1226]   0.0    0.00    0.00       1         void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&) [1226]
-----------------------------------------------
                0.00    0.00       1/1           main [7]
[1227]   0.0    0.00    0.00       1         std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector() [1227]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [105]
[1228]   0.0    0.00    0.00       1         void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&) [1228]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1229]   0.0    0.00    0.00       1         void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&) [1229]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1230]   0.0    0.00    0.00       1         void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&) [1230]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [102]
[1231]   0.0    0.00    0.00       1         void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&) [1231]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1232]   0.0    0.00    0.00       1         std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long) [1232]
-----------------------------------------------
                0.00    0.00       1/1           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1099]
[1233]   0.0    0.00    0.00       1         std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [1233]
                0.00    0.00       1/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1068]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1234]   0.0    0.00    0.00       1         common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*) [1234]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1235]   0.0    0.00    0.00       1         common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*) [1235]
-----------------------------------------------
                0.00    0.00       1/1           llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [1196]
[1236]   0.0    0.00    0.00       1         std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) [1236]
-----------------------------------------------
                                  19             void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1237]
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [19]
[1237]   0.0    0.00    0.00       1+19      void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1237]
                                  19             void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1237]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1238]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1238]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1239]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1239]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1147]
[1240]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int) [1240]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [110]
[1241]   0.0    0.00    0.00       1         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const [1241]
-----------------------------------------------
                0.00    0.00       1/1           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1066]
[1242]   0.0    0.00    0.00       1         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const [1242]
-----------------------------------------------

 This table describes the call tree of the program, and was sorted by
 the total amount of time spent in each function and its children.

 Each entry in this table consists of several lines.  The line with the
 index number at the left hand margin lists the current function.
 The lines above it list the functions that called this function,
 and the lines below it list the functions this one called.
 This line lists:
     index	A unique number given to each element of the table.
		Index numbers are sorted numerically.
		The index number is printed next to every function name so
		it is easier to look up where the function is in the table.

     % time	This is the percentage of the `total' time that was spent
		in this function and its children.  Note that due to
		different viewpoints, functions excluded by options, etc,
		these numbers will NOT add up to 100%.

     self	This is the total amount of time spent in this function.

     children	This is the total amount of time propagated into this
		function by its children.

     called	This is the number of times the function was called.
		If the function called itself recursively, the number
		only includes non-recursive calls, and is followed by
		a `+' and the number of recursive calls.

     name	The name of the current function.  The index number is
		printed after it.  If the function is a member of a
		cycle, the cycle number is printed between the
		function's name and the index number.


 For the function's parents, the fields have the following meanings:

     self	This is the amount of time that was propagated directly
		from the function into this parent.

     children	This is the amount of time that was propagated from
		the function's children into this parent.

     called	This is the number of times this parent called the
		function `/' the total number of times the function
		was called.  Recursive calls to the function are not
		included in the number after the `/'.

     name	This is the name of the parent.  The parent's index
		number is printed after it.  If the parent is a
		member of a cycle, the cycle number is printed between
		the name and the index number.

 If the parents of the function cannot be determined, the word
 `<spontaneous>' is printed in the `name' field, and all the other
 fields are blank.

 For the function's children, the fields have the following meanings:

     self	This is the amount of time that was propagated directly
		from the child into the function.

     children	This is the amount of time that was propagated from the
		child's children to the function.

     called	This is the number of times the function called
		this child `/' the total number of times the child
		was called.  Recursive calls by the child are not
		listed in the number after the `/'.

     name	This is the name of the child.  The child's index
		number is printed after it.  If the child is a
		member of a cycle, the cycle number is printed
		between the name and the index number.

 If there are any cycles (circles) in the call graph, there is an
 entry for the cycle-as-a-whole.  This entry shows who called the
 cycle (as parents) and the members of the cycle (as children.)
 The `+' recursive calls entry shows the number of function calls that
 were internal to the cycle, and the calls entry for each member shows,
 for that member, how many times it was called from other members of
 the cycle.

Copyright (C) 2012-2024 Free Software Foundation, Inc.

Copying and distribution of this file, with or without modification,
are permitted in any medium without royalty provided the copyright
notice and this notice are preserved.

Index by function name

 [1144] common_init()       [1065] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [306] ggml_cpu_has_fma
 [1042] string_format[abi:cxx11](char const*, ...) [1002] std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [307] ggml_cpu_has_fp16_va
 [990] common_log_add(common_log*, ggml_log_level, char const*, ...) [976] std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) (std_function.h) [308] ggml_cpu_has_llamafile
 [991] common_log_main()    [1108] std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_destroy() [309] ggml_cpu_has_matmul_int8
  [64] common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1109] std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() [310] ggml_cpu_has_neon
  [65] common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1210] std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand() [311] ggml_cpu_has_riscv_v
 [1145] cpu_get_num_math()  [1211] std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&) [312] ggml_cpu_has_sse3
  [57] unicode_len_utf8(char) [123] std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [313] ggml_cpu_has_ssse3
 [1146] common_perf_print(llama_context const*, common_sampler const*) [1212] std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&) [314] ggml_cpu_has_sve
 [1067] unicode_cpt_flags(unsigned int) [1213] std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&) [315] ggml_cpu_has_vsx
 [1021] llama_log_internal(ggml_log_level, char const*, ...) [1214] std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&) [316] ggml_cpu_has_wasm_simd
 [1147] common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1215] std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [202] ggml_cpu_init
 [1148] common_sampler_free(common_sampler*) [1058] std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&) [75] ggml_cpy
 [1149] common_sampler_init(llama_model const*, common_sampler_params const&) [1085] void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [177] ggml_critical_section_end
 [1008] common_sampler_last(common_sampler const*) [1216] std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back() [178] ggml_critical_section_start
 [1150] llama_token_nl_impl(llama_vocab const&) [111] std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() (std_thread.h) [156] ggml_dup_tensor
  [66] llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [1038] void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&) [162] ggml_element_size
 [966] unicode_cpt_to_utf8[abi:cxx11](unsigned int) [1078] void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&) [273] ggml_fopen
 [1124] unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1075] void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&) [140] ggml_format_name
 [1151] common_sampler_print[abi:cxx11](common_sampler const*) [1217] std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long) [35] ggml_fp32_to_fp16_row
 [1125] llama_token_bos_impl(llama_vocab const&) [1218] std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long) [180] ggml_free
 [1126] llama_token_eos_impl(llama_vocab const&) [1110] void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&) [39] ggml_gallocr_alloc_graph
 [1152] set_process_priority(ggml_sched_priority) [1219] std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector() [103] ggml_gallocr_allocate_node (ggml-alloc.c)
 [1069] unicode_byte_to_utf8[abi:cxx11](unsigned char) [1220] std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long) [317] ggml_gallocr_free
 [967] unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1221] std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long) [318] ggml_gallocr_get_buffer_size
  [53] common_sampler_accept(common_sampler*, int, bool) [1222] std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector() [319] ggml_gallocr_new_n
  [16] common_sampler_sample(common_sampler*, llama_context*, int, bool) [1223] std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long) [95] ggml_gallocr_reserve_n
 [999] common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [1224] std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long) [245] ggml_get_first_tensor
 [965] unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&) [1097] void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [112] ggml_get_max_tensor_size
 [1093] postprocess_cpu_params(cpu_params&, cpu_params const*) [1086] std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [193] ggml_get_name
 [1080] string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1059] std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::~vector() [192] ggml_get_next_tensor
 [972] unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1068] void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [320] ggml_get_no_alloc
  [17] common_init_from_params(common_params&) [1139] std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long) [109] ggml_get_rows
 [1153] common_sampler_get_seed(common_sampler const*) [1225] void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&) [233] ggml_get_tensor
 [984] llama_token_is_eog_impl(llama_vocab const&, int) [1226] void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&) [135] ggml_get_type_traits
  [58] llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1005] std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long) [161] ggml_get_unary_op
 [1154] llama_add_bos_token_impl(llama_vocab const&) [1227] std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector() [210] ggml_graph_compute
 [1155] llama_add_eos_token_impl(llama_vocab const&) [1228] void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&) [104] ggml_graph_compute_with_ctx
 [1156] common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1140] std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [274] ggml_graph_n_nodes
 [979] llama_token_get_attr_impl(llama_vocab const&, int) [1229] void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&) [190] ggml_graph_node
 [980] llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [1111] void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [275] ggml_graph_overhead_custom
 [1157] common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1230] void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&) [82] ggml_graph_plan
 [1081] common_sampler_type_to_chr(common_sampler_type) [1076] void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&) [200] ggml_graph_view
 [1082] common_sampler_type_to_str[abi:cxx11](common_sampler_type) [1231] void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&) [184] ggml_guid_matches
 [1158] llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long) [1112] void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&) [258] ggml_hash_set_free
 [1159] common_model_params_to_llama(common_params const&) [1006] std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long) [276] ggml_hash_set_new
 [1160] common_params_get_system_info[abi:cxx11](common_params const&) [1027] std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [185] ggml_hash_set_reset
 [1161] common_context_params_to_llama(common_params const&) [1079] void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [186] ggml_hash_size
 [1162] llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*) [993] void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [181] ggml_init
 [1127] ggml_threadpool_params_from_cpu_params(cpu_params const&) [1232] std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long) [129] ggml_is_contiguous
 [1070] __static_initialization_and_destruction_0() (llama.cpp) [983] std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [40] ggml_is_contiguous_0
 [1128] print_usage(int, char**) (main.cpp) [1055] void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [99] ggml_is_contiguous_1
 [969] replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (llama-impl.h) [1141] std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long) [130] ggml_is_empty
 [1129] get_rng_seed(unsigned int) (llama-sampling.cpp) [1092] void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [169] ggml_is_matrix
  [43] llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) (llama.cpp) [1142] std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long) [154] ggml_is_numa
  [68] llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) (llama.cpp) [1113] std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [163] ggml_is_quantized
 [1163] llm_load_arch(llama_model_loader&, llama_model&) (llama.cpp) [1114] std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type) [160] ggml_is_transposed
 [1164] write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&) (main.cpp) [1060] std::__cxx11::to_string(int) [164] ggml_is_vector
 [1044] gguf_kv_to_str(gguf_context const*, int) (llama.cpp) [1047] std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [321] ggml_log_set
  [19] llm_load_vocab(llama_model_loader&, llama_model&) (llama.cpp) [1041] void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*) [91] ggml_mul
 [981] gguf_data_to_str(gguf_type, void const*, int) (llama.cpp) [1035] std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&) [78] ggml_mul_mat
 [100] llama_set_inputs(llama_context&, llama_ubatch const&) (llama.cpp) [1036] std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [170] ggml_mul_mat_set_prec
 [1165] llm_load_hparams(llama_model_loader&, llama_model&) (llama.cpp) [23] std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&) [131] ggml_n_dims
 [102] llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) (llama.cpp) [998] std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [44] ggml_nbytes
  [41] llama_build_graph(llama_context&, llama_ubatch const&, bool) (llama.cpp) [1115] std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [138] ggml_nelements
  [79] llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) (llama.cpp) [1116] std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher() [201] ggml_new_graph_custom
 [1003] llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) (llama.cpp) [1117] std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [145] ggml_new_object (ggml.c)
  [69] llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) (llama.cpp) [1233] std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [72] ggml_new_tensor
 [1022] llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) (llama.cpp) [1118] std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [108] ggml_new_tensor_1d
 [1007] llama_output_reserve(llama_context&, unsigned long) (llama.cpp) [1051] std::__detail::_Scanner<char>::_M_advance() [114] ggml_new_tensor_2d
 [1166] ggml_backend_cpu_free(ggml_backend*) (ggml-backend.cpp) [1098] std::__detail::_Scanner<char>::_M_scan_normal() [125] ggml_new_tensor_3d
  [13] llama_decode_internal(llama_context&, llama_batch) (llama.cpp) [1119] std::__detail::_Scanner<char>::_M_eat_escape_ecma() [97] ggml_new_tensor_4d
 [1167] llama_model_type_name(e_model) (llama.cpp) [1057] std::__detail::_Scanner<char>::_M_scan_in_bracket() [70] ggml_new_tensor_impl.constprop.0 (ggml.c)
 [117] weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) (llama.cpp) [1056] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [73] ggml_new_tensor_impl.constprop.1 (ggml.c)
 [1130] kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (common.cpp) [1087] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion() [84] ggml_new_tensor_impl.constprop.2 (ggml.c)
 [1168] llama_model_ftype_name(llama_ftype) (llama.cpp) [1099] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [85] ggml_new_tensor_impl.constprop.3 (ggml.c)
 [986] llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1120] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [141] ggml_nrows
 [1169] llama_sampler_dry_free(llama_sampler*) (llama-sampling.cpp) [1121] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [76] ggml_permute
 [1170] llama_sampler_dry_name(llama_sampler const*) (llama-sampling.cpp) [1066] bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [322] ggml_quantize_free
 [1171] llama_sampler_xtc_free(llama_sampler*) (llama-sampling.cpp) [1088] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [74] ggml_reshape_3d
 [1172] llama_sampler_xtc_name(llama_sampler const*) (llama-sampling.cpp) [1122] void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [92] ggml_rms_norm
 [1072] tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) (llama-vocab.cpp) [1089] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [126] ggml_rope
 [1173] llama_sampler_dist_free(llama_sampler*) (llama-sampling.cpp) [1123] std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [158] ggml_rope_cache_init (ggml-cpu.c)
 [1174] llama_sampler_dist_name(llama_sampler const*) (llama-sampling.cpp) [1029] std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&) [93] ggml_rope_ext
 [1010] llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [52] std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [159] ggml_rope_yarn_corr_dims
  [56] llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) (llama.cpp) [1030] std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [63] ggml_row_size
 [1175] llama_sampler_chain_free(llama_sampler*) (llama-sampling.cpp) [26] void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) (stl_algo.h) [179] ggml_set_input
 [1011] llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1234] common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*) [175] ggml_set_name
 [1000] llama_sampler_dry_accept(llama_sampler*, int) (llama-sampling.cpp) [1235] common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*) [277] ggml_set_no_alloc
 [1176] llama_sampler_min_p_free(llama_sampler*) (llama-sampling.cpp) [1236] std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) [171] ggml_silu
 [1177] llama_sampler_min_p_name(llama_sampler const*) (llama-sampling.cpp) [1143] void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) (stl_algo.h) [89] ggml_soft_max_ext
 [1178] llama_sampler_top_k_free(llama_sampler*) (llama-sampling.cpp) [37] void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) (stl_algo.h) [121] ggml_tallocr_alloc
  [24] llama_sampler_top_k_impl(llama_token_data_array*, int) (llama-sampling.cpp) [1237] void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) (stl_algo.h) [323] ggml_tallocr_new
 [1179] llama_sampler_top_k_name(llama_sampler const*) (llama-sampling.cpp) [1048] std::__throw_regex_error(std::regex_constants::error_type, char const*) [218] ggml_tensor_overhead
 [1180] llama_sampler_top_p_free(llama_sampler*) (llama-sampling.cpp) [973] bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [259] ggml_threadpool_free
 [1181] llama_sampler_top_p_name(llama_sampler const*) (llama-sampling.cpp) [1023] common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) (common.cpp) [324] ggml_threadpool_new
 [995] llama_format_tensor_shape(ggml_tensor const*) (llama.cpp) [1031] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const (arg.cpp) [278] ggml_threadpool_new_impl (ggml-cpu.c)
  [25] llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [996] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) (arg.cpp) [325] ggml_threadpool_params_default
 [1012] llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1238] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [260] ggml_threadpool_params_init
 [1013] llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1050] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [326] ggml_threadpool_params_match
 [1014] llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1239] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [261] ggml_time_init
  [54] llama_sampler_chain_accept(llama_sampler*, int) (llama-sampling.cpp) [994] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [176] ggml_time_us
 [1182] llama_sampler_grammar_free(llama_sampler*) (llama-sampling.cpp) [1240] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int) (arg.cpp) [86] ggml_transpose
 [987] llama_sampler_softmax_impl(llama_token_data_array*) (llama-sampling.cpp) [1034] llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) (llama.cpp) [247] ggml_type_name
 [1183] llama_sampler_typical_free(llama_sampler*) (llama-sampling.cpp) [115] llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const (llama.cpp) [48] ggml_type_size
 [1184] llama_sampler_typical_name(llama_sampler const*) (llama-sampling.cpp) [1241] llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const [96] ggml_unary
 [1015] llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1242] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const [6] ggml_vec_dot_f16 (ggml-cpu.c)
 [1185] llama_sampler_temp_ext_free(llama_sampler*) (llama-sampling.cpp) [8] _init [3] ggml_vec_dot_q4_0_q8_0_esp_riscv
 [1186] llama_sampler_temp_ext_name(llama_sampler const*) (llama-sampling.cpp) [119] alloc_tensor_range (ggml-alloc.c) [5] ggml_vec_dot_q4_1_q8_1
 [1016] llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [216] dequantize_row_q6_K [33] ggml_vec_dot_q5_K_q8_K
 [1187] llama_sampler_penalties_free(llama_sampler*) (llama-sampling.cpp) [94] ggml_add [4] ggml_vec_dot_q6_K_q8_K
 [1188] llama_sampler_penalties_name(llama_sampler const*) (llama-sampling.cpp) [194] ggml_aligned_free [22] ggml_vec_mad_f32_unroll (ggml-cpu.c)
 [1017] llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [195] ggml_aligned_malloc [27] ggml_vec_soft_max_f32 (ggml-cpu.c)
 [1001] ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) (ggml-backend.cpp) [144] ggml_are_same_shape [87] ggml_view_1d
 [1131] ggml_backend_cpu_reg_get_name(ggml_backend_reg*) (ggml-backend.cpp) [51] ggml_backend_alloc_ctx_tensors [88] ggml_view_2d
 [1189] llama_sampler_logit_bias_free(llama_sampler*) (llama-sampling.cpp) [116] ggml_backend_alloc_ctx_tensors_from_buft [77] ggml_view_3d
 [1190] llama_sampler_logit_bias_name(llama_sampler const*) (llama-sampling.cpp) [197] ggml_backend_buffer_clear [71] ggml_view_tensor
 [1018] llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [217] ggml_backend_buffer_free [61] ggml_visit_parents (ggml.c)
  [83] ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) (ggml-backend.cpp) [285] ggml_backend_buffer_get_alignment [228] gguf_find_key
 [1019] llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [153] ggml_backend_buffer_get_alloc_size [224] gguf_find_tensor
  [55] llama_sampler_penalties_accept(llama_sampler*, int) (llama-sampling.cpp) [136] ggml_backend_buffer_get_base [137] gguf_fread_str (ggml.c)
 [1094] ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) (ggml-backend.cpp) [152] ggml_backend_buffer_get_size [327] gguf_free
 [971] ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*) (ggml-backend.cpp) [151] ggml_backend_buffer_get_type [248] gguf_get_arr_data
 [1083] ggml_backend_cpu_device_get_type(ggml_backend_device*) (ggml-backend.cpp) [219] ggml_backend_buffer_init [235] gguf_get_arr_n
 [1191] ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*) (ggml-backend.cpp) [146] ggml_backend_buffer_init_tensor [133] gguf_get_arr_str
 [1132] ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) (ggml-backend.cpp) [189] ggml_backend_buffer_is_host [238] gguf_get_arr_type
 [1020] llama_sampler_grammar_accept_impl(llama_sampler*, int) (llama-sampling.cpp) [263] ggml_backend_buffer_is_multi_buffer [225] gguf_get_data_offset
 [1133] unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) (unicode.cpp) [254] ggml_backend_buffer_name [182] gguf_get_key
 [1009] ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long) (ggml-backend.cpp) [204] ggml_backend_buffer_reset [223] gguf_get_kv_type
 [985] ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long) (ggml-backend.cpp) [264] ggml_backend_buffer_set_usage [132] gguf_get_n_kv
 [1100] ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*) (ggml-backend.cpp) [220] ggml_backend_buft_alloc_buffer [226] gguf_get_n_tensors
 [975] ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) (ggml-backend.cpp) [255] ggml_backend_buft_get_alignment [167] gguf_get_tensor_name
 [977] ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) (ggml-backend.cpp) [134] ggml_backend_buft_get_alloc_size [227] gguf_get_tensor_offset
 [1101] ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*) (ggml-backend.cpp) [221] ggml_backend_buft_get_device [230] gguf_get_val_data
 [978] ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) (ggml-backend.cpp) [286] ggml_backend_buft_get_max_size [279] gguf_get_val_f32
 [1134] ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*) (ggml-backend.cpp) [148] ggml_backend_buft_is_host [231] gguf_get_val_str
 [974] ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) (ggml-backend.cpp) [249] ggml_backend_buft_name [234] gguf_get_val_u32
 [1102] ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) (ggml-backend.cpp) [287] ggml_backend_cpu_buffer_from_ptr [328] gguf_get_version
 [1103] ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) (ggml-backend.cpp) [250] ggml_backend_cpu_buffer_type [118] gguf_init_from_file
 [1104] ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) (ggml-backend.cpp) [288] ggml_backend_cpu_init [229] gguf_type_name
 [1192] ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long) (ggml-backend.cpp) [251] ggml_backend_cpu_reg [262] iq2xs_free_impl
 [1193] ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*) (ggml-backend.cpp) [205] ggml_backend_cpu_set_abort_callback [329] iq3xs_free_impl
 [997] format(char const*, ...) (llama.cpp) [206] ggml_backend_cpu_set_n_threads [330] llama_add_bos_token
 [1073] get_reg() (ggml-backend.cpp) [207] ggml_backend_cpu_set_threadpool [331] llama_add_eos_token
 [1025] common_arg::in_example(llama_example) [265] ggml_backend_dev_backend_reg [332] llama_attach_threadpool
 [1052] common_arg::set_sparam() [289] ggml_backend_dev_buffer_from_host_ptr [333] llama_backend_free
 [1040] common_arg::set_examples(std::initializer_list<llama_example>) [256] ggml_backend_dev_buffer_type [334] llama_backend_init
 [1037] common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [257] ggml_backend_dev_by_type [211] llama_batch_get_one
 [1105] common_arg::has_value_from_env() [232] ggml_backend_dev_count [335] llama_context_default_params
 [1045] common_arg::set_env(char const*) [243] ggml_backend_dev_get [12] llama_decode
 [1106] common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [290] ggml_backend_dev_get_props [336] llama_free
 [1032] common_arg::common_arg(common_arg const&) [222] ggml_backend_dev_host_buffer_type [45] llama_free_model
 [1046] common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [149] ggml_backend_dev_supports_buft [214] llama_get_logits_ith
 [1043] common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [142] ggml_backend_dev_supports_op [188] llama_get_model
 [1074] common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [244] ggml_backend_dev_type [337] llama_kv_cache_clear
 [1026] common_arg::~common_arg() [291] ggml_backend_event_free [212] llama_kv_cache_update
 [1135] llama_mmap::unmap_fragment(unsigned long, unsigned long) [266] ggml_backend_free [18] llama_load_model_from_file
  [46] llama_model::~llama_model() [292] ggml_backend_get_default_buffer_type [338] llama_log_set
 [1194] llama_vocab::init_tokenizer() [165] ggml_backend_get_device [339] llama_lora_adapter_clear
  [47] llama_vocab::~llama_vocab() [208] ggml_backend_graph_compute_async [340] llama_model_default_params
  [10] (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) (sgemm.cpp) [183] ggml_backend_is_cpu [341] llama_model_has_decoder
  [34] void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long) (sgemm.cpp) [267] ggml_backend_reg_by_name [253] llama_model_has_encoder
  [11] void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long) (sgemm.cpp) [246] ggml_backend_reg_count [280] llama_model_is_recurrent
 [992] void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long) (sgemm.cpp) [268] ggml_backend_reg_dev_count [342] llama_n_ctx
 [1024] void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long) (sgemm.cpp) [252] ggml_backend_reg_dev_get [281] llama_n_ctx_train
 [988] void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long) (sgemm.cpp) [269] ggml_backend_reg_get [203] llama_n_vocab
 [989] (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) (sgemm.cpp) [270] ggml_backend_reg_get_proc_address [80] llama_new_context_with_model
  [38] llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [271] ggml_backend_reg_name [343] llama_numa_init
 [1195] common_params::common_params() [31] ggml_backend_sched_alloc_graph [344] llama_perf_context
 [1136] common_params::~common_params() [293] ggml_backend_sched_free [345] llama_perf_context_print
  [42] llm_build_context::build_llama() [294] ggml_backend_sched_get_buffer_size [346] llama_perf_context_reset
 [1196] llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [272] ggml_backend_sched_get_n_splits [347] llama_perf_sampler
 [1197] llm_tokenizer_bpe::~llm_tokenizer_bpe() [32] ggml_backend_sched_get_tensor_backend [348] llama_perf_sampler_print
 [120] llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [81] ggml_backend_sched_graph_compute_async [349] llama_print_system_info
 [113] llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [295] ggml_backend_sched_new [350] llama_rope_type
 [110] llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [90] ggml_backend_sched_reserve [173] llama_sampler_accept
 [1090] bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [187] ggml_backend_sched_reset [174] llama_sampler_apply
 [1091] bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [209] ggml_backend_sched_set_eval_callback [239] llama_sampler_chain_add
 [1054] bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [166] ggml_backend_sched_set_tensor_backend [351] llama_sampler_chain_default_params
 [105] llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [198] ggml_backend_sched_synchronize [240] llama_sampler_chain_get
 [1198] common_sampler_params::common_sampler_params(common_sampler_params const&) [150] ggml_backend_supports_buft [352] llama_sampler_chain_init
 [1095] llama_data_write_file::write(void const*, unsigned long) [143] ggml_backend_supports_op [237] llama_sampler_chain_n
 [1077] llm_tokenizer_bpe_session::add_new_bigram(int, int) [199] ggml_backend_synchronize [236] llama_sampler_free
  [59] llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [67] ggml_backend_tensor_alloc [353] llama_sampler_get_seed
 [1199] ggml_backend_cpu_device_context::ggml_backend_cpu_device_context() [106] ggml_backend_tensor_get [354] llama_sampler_init_dist
 [1004] console::set_display(console::display_t) [107] ggml_backend_tensor_get_async [355] llama_sampler_init_dry
 [1200] console::init(bool, bool) [101] ggml_backend_tensor_set [356] llama_sampler_init_grammar
 [1096] std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...) [157] ggml_backend_view_init [357] llama_sampler_init_logit_bias
 [1084] llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [60] ggml_blck_size [358] llama_sampler_init_min_p
 [1201] common_sampler_params::print[abi:cxx11]() const [62] ggml_build_forward_expand [359] llama_sampler_init_penalties
 [1202] LLM_KV::operator()[abi:cxx11](llm_kv) const [147] ggml_can_repeat [360] llama_sampler_init_temp_ext
 [1071] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1] ggml_compute_forward (ggml-cpu.c) [361] llama_sampler_init_top_k
 [1137] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>) [49] ggml_compute_forward_add (ggml-cpu.c) [362] llama_sampler_init_top_p
 [1049] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [15] ggml_compute_forward_dup (ggml-cpu.c) [363] llama_sampler_init_typical
 [1033] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long) [172] ggml_compute_forward_get_rows (ggml-cpu.c) [364] llama_sampler_init_xtc
 [1053] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long) [28] ggml_compute_forward_mul (ggml-cpu.c) [241] llama_sampler_name
 [968] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [2] ggml_compute_forward_mul_mat (ggml-cpu.c) [242] llama_state_seq_get_size
 [982] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long) [29] ggml_compute_forward_rms_norm (ggml-cpu.c) [365] llama_supports_gpu_offload
 [1203] std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>) [20] ggml_compute_forward_rope_f32 (ggml-cpu.c) [282] llama_supports_rpc
 [1138] std::_Hashtable<char, char, std::allocator<char>, std::__detail::_Identity, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, true, true> >::_Hashtable<char const*>(char const*, char const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<char> const&, std::integral_constant<bool, true>) [14] ggml_compute_forward_soft_max (ggml-cpu.c) [213] llama_synchronize
 [1028] std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long) [36] ggml_compute_forward_unary (ggml-cpu.c) [283] llama_token_bos
 [1039] std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [168] ggml_cont_2d [284] llama_token_eos
 [1107] std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [98] ggml_cont_4d [191] llama_token_is_eog
 [1204] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [296] ggml_cpu_has_amx_int8 [366] llama_token_nl
 [1061] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [297] ggml_cpu_has_arm_fma [155] llama_token_to_piece
 [1205] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [298] ggml_cpu_has_avx [367] llama_tokenize
 [1062] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [299] ggml_cpu_has_avx2 [9] llamafile_sgemm
 [1206] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [300] ggml_cpu_has_avx512 [30] print_gemm_cfg
 [970] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [301] ggml_cpu_has_avx512_bf16 [21] quantize_row_q8_0
 [1207] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [302] ggml_cpu_has_avx512_vbmi [196] quantize_row_q8_1
 [1063] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [303] ggml_cpu_has_avx512_vnni [215] quantize_row_q8_K
 [1208] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [304] ggml_cpu_has_avx_vnni [50] quantize_row_q8_K_ref
 [1064] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [305] ggml_cpu_has_blas [128] <cycle 1>
 [1209] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [139] ggml_cpu_has_f16c
