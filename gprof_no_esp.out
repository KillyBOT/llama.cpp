Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ms/call  ms/call  name    
 67.33     10.14    10.14 30468500     0.00     0.00  ggml_vec_dot_q4_0_q8_0
 20.12     13.17     3.03  7083137     0.00     0.00  ggml_vec_dot_q6_K_q8_K
  3.39     13.68     0.51   842518     0.00     0.00  ggml_vec_dot_q4_1_q8_1
  1.66     13.93     0.25   152808     0.00     0.09  ggml_compute_forward_mul_mat
  1.53     14.16     0.23     1036     0.22     0.22  void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long)
  1.20     14.34     0.18  6964096     0.00     0.00  ggml_vec_dot_f16
  0.60     14.43     0.09      622     0.14     0.14  void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long)
  0.53     14.51     0.08   280147     0.00     0.00  std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&)
  0.33     14.56     0.05    72213     0.00     0.00  ggml_compute_forward_mul
  0.27     14.60     0.04    18931     0.00     0.00  ggml_compute_forward_soft_max
  0.27     14.64     0.04                             ggml_compute_forward
  0.20     14.67     0.03   100916     0.00     0.00  ggml_vec_soft_max_f32
  0.20     14.70     0.03    54736     0.00     0.00  ggml_compute_forward_dup
  0.20     14.73     0.03    21848     0.00     0.00  quantize_row_q8_0
  0.20     14.76     0.03      339     0.09     0.18  common_sampler_sample(common_sampler*, llama_context*, int, bool)
  0.20     14.79     0.03      339     0.09     0.09  void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>)
  0.20     14.82     0.03                             _init
  0.13     14.84     0.02   871921     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.13     14.86     0.02    56064     0.00     0.00  ggml_compute_forward_rms_norm
  0.13     14.88     0.02    46187     0.00     0.00  ggml_compute_forward_rope_f32
  0.13     14.90     0.02    23987     0.00     0.00  ggml_compute_forward_unary
  0.13     14.92     0.02      340     0.06     0.15  llama_decode_internal(llama_context&, llama_batch)
  0.10     14.94     0.02   211567     0.00     0.00  ggml_nrows
  0.07     14.95     0.01   816820     0.00     0.00  gguf_get_arr_str
  0.07     14.96     0.01   408611     0.00     0.00  gguf_fread_str
  0.07     14.97     0.01   238002     0.00     0.00  ggml_fp32_to_fp16_row
  0.07     14.98     0.01   128256     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long)
  0.07     14.99     0.01      683     0.01     0.01  ggml_backend_sched_get_tensor_backend
  0.07     15.00     0.01      415     0.02     0.02  quantize_row_q8_1
  0.07     15.01     0.01      361     0.03     0.03  llama_set_inputs(llama_context&, llama_ubatch const&)
  0.07     15.02     0.01      340     0.03     0.03  ggml_graph_compute
  0.07     15.03     0.01      224     0.04     0.04  quantize_row_q8_K
  0.07     15.04     0.01                             ggml_vec_dot_q5_K_q8_K
  0.03     15.04     0.01  3082515     0.00     0.00  ggml_blck_size
  0.03     15.05     0.01   922769     0.00     0.00  ggml_n_dims
  0.03     15.05     0.01   729057     0.00     0.00  ggml_is_contiguous
  0.03     15.06     0.01   664991     0.00     0.00  ggml_is_contiguous_0
  0.03     15.06     0.01                             ggml_is_3d
  0.00     15.06     0.00  3314228     0.00     0.00  ggml_type_size
  0.00     15.06     0.00  3182328     0.00     0.00  unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&)
  0.00     15.06     0.00  1068458     0.00     0.00  ggml_is_empty
  0.00     15.06     0.00   985152     0.00     0.00  ggml_row_size
  0.00     15.06     0.00   872707     0.00     0.00  unicode_cpt_to_utf8[abi:cxx11](unsigned int)
  0.00     15.06     0.00   871921     0.00     0.00  unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00   818795     0.00     0.00  gguf_get_n_kv
  0.00     15.06     0.00   817191     0.00     0.00  replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00   560310     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00     15.06     0.00   461275     0.00     0.00  ggml_nbytes
  0.00     15.06     0.00   409746     0.00     0.00  unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00   398486     0.00     0.00  ggml_backend_buft_get_alloc_size
  0.00     15.06     0.00   387162     0.00     0.00  bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*)
  0.00     15.06     0.00   353652     0.00     0.00  ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*)
  0.00     15.06     0.00   353652     0.00     0.00  ggml_backend_buffer_get_base
  0.00     15.06     0.00   314410     0.00     0.00  ggml_get_type_traits
  0.00     15.06     0.00   249657     0.00     0.00  ggml_cpu_has_f16c
  0.00     15.06     0.00   247678     0.00     0.00  ggml_format_name
  0.00     15.06     0.00   244998     0.00     0.00  llamafile_sgemm
  0.00     15.06     0.00   232721     0.00     0.00  ggml_nelements
  0.00     15.06     0.00   229531     0.00     0.00  ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*)
  0.00     15.06     0.00   211810     0.00     0.00  ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*)
  0.00     15.06     0.00   211810     0.00     0.00  ggml_backend_dev_supports_op
  0.00     15.06     0.00   211631     0.00     0.00  ggml_backend_supports_op
  0.00     15.06     0.00   180105     0.00     0.00  ggml_new_object
  0.00     15.06     0.00   177659     0.00     0.00  ggml_backend_buffer_init_tensor
  0.00     15.06     0.00   173887     0.00     0.00  ggml_are_same_shape
  0.00     15.06     0.00   156408     0.00     0.00  std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&)
  0.00     15.06     0.00   145575     0.00     0.00  ggml_can_repeat
  0.00     15.06     0.00   145427     0.00     0.00  ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*)
  0.00     15.06     0.00   145427     0.00     0.00  ggml_backend_buft_is_host
  0.00     15.06     0.00   144747     0.00     0.00  ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*)
  0.00     15.06     0.00   144747     0.00     0.00  ggml_backend_dev_supports_buft
  0.00     15.06     0.00   144747     0.00     0.00  ggml_backend_supports_buft
  0.00     15.06     0.00   130443     0.00     0.00  llama_token_get_attr_impl(llama_vocab const&, int)
  0.00     15.06     0.00   130443     0.00     0.00  llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool)
  0.00     15.06     0.00   130443     0.00     0.00  llama_token_to_piece
  0.00     15.06     0.00   128292     0.00     0.00  gguf_data_to_str(gguf_type, void const*, int)
  0.00     15.06     0.00   128256     0.00     0.00  std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00   119394     0.00     0.00  ggml_new_tensor
  0.00     15.06     0.00   118535     0.00     0.00  ggml_backend_buffer_get_type
  0.00     15.06     0.00   118197     0.00     0.00  ggml_backend_buffer_get_size
  0.00     15.06     0.00   117851     0.00     0.00  ggml_backend_buffer_get_alloc_size
  0.00     15.06     0.00   117819     0.00     0.00  ggml_backend_tensor_alloc
  0.00     15.06     0.00    80977     0.00     0.00  void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>)
  0.00     15.06     0.00    72030     0.00     0.00  ggml_visit_parents
  0.00     15.06     0.00    68721     0.00     0.00  ggml_is_numa
  0.00     15.06     0.00    61266     0.00     0.00  ggml_dup_tensor
  0.00     15.06     0.00    59840     0.00     0.00  ggml_backend_view_init
  0.00     15.06     0.00    49848     0.00     0.00  ggml_is_transposed
  0.00     15.06     0.00    49848     0.00     0.00  ggml_mul_mat
  0.00     15.06     0.00    46703     0.00     0.00  ggml_rope_cache_init
  0.00     15.06     0.00    45029     0.00     0.00  ggml_compute_forward_add
  0.00     15.06     0.00    44346     0.00     0.00  ggml_rope_yarn_corr_dims
  0.00     15.06     0.00    38759     0.00     0.00  llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*)
  0.00     15.06     0.00    33271     0.00     0.00  ggml_build_forward_expand
  0.00     15.06     0.00    29514     0.00     0.00  ggml_get_unary_op
  0.00     15.06     0.00    27440     0.00     0.00  ggml_new_tensor_impl.constprop.0
  0.00     15.06     0.00    27440     0.00     0.00  ggml_view_tensor
  0.00     15.06     0.00    22632     0.00     0.00  ggml_element_size
  0.00     15.06     0.00    21952     0.00     0.00  ggml_new_tensor_impl.constprop.1
  0.00     15.06     0.00    21761     0.00     0.00  ggml_is_quantized
  0.00     15.06     0.00    16840     0.00     0.00  ggml_mul
  0.00     15.06     0.00    11319     0.00     0.00  ggml_rms_norm
  0.00     15.06     0.00    11008     0.00     0.00  ggml_is_vector
  0.00     15.06     0.00    10992     0.00     0.00  ggml_rope_ext
  0.00     15.06     0.00    10976     0.00     0.00  llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int)
  0.00     15.06     0.00    10976     0.00     0.00  ggml_add
  0.00     15.06     0.00    10976     0.00     0.00  ggml_cpy
  0.00     15.06     0.00    10976     0.00     0.00  ggml_permute
  0.00     15.06     0.00    10976     0.00     0.00  ggml_reshape_3d
  0.00     15.06     0.00    10976     0.00     0.00  ggml_view_3d
  0.00     15.06     0.00    10913     0.00     0.00  ggml_backend_get_device
  0.00     15.06     0.00    10912     0.00     0.00  ggml_backend_sched_set_tensor_backend
  0.00     15.06     0.00    10878     0.00     0.00  gguf_get_tensor_name
  0.00     15.06     0.00     6631     0.00     0.00  ggml_new_tensor_4d
  0.00     15.06     0.00     5488     0.00     0.00  llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int)
  0.00     15.06     0.00     5488     0.00     0.00  llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long)
  0.00     15.06     0.00     5488     0.00     0.00  ggml_cont_2d
  0.00     15.06     0.00     5488     0.00     0.00  ggml_cont_4d
  0.00     15.06     0.00     5488     0.00     0.00  ggml_is_contiguous_1
  0.00     15.06     0.00     5488     0.00     0.00  ggml_is_matrix
  0.00     15.06     0.00     5488     0.00     0.00  ggml_mul_mat_set_prec
  0.00     15.06     0.00     5488     0.00     0.00  ggml_new_tensor_impl.constprop.2
  0.00     15.06     0.00     5488     0.00     0.00  ggml_new_tensor_impl.constprop.3
  0.00     15.06     0.00     5488     0.00     0.00  ggml_silu
  0.00     15.06     0.00     5488     0.00     0.00  ggml_soft_max_ext
  0.00     15.06     0.00     5488     0.00     0.00  ggml_transpose
  0.00     15.06     0.00     5488     0.00     0.00  ggml_unary
  0.00     15.06     0.00     5488     0.00     0.00  ggml_view_1d
  0.00     15.06     0.00     5488     0.00     0.00  ggml_view_2d
  0.00     15.06     0.00     4833     0.00     0.00  ggml_gallocr_allocate_node
  0.00     15.06     0.00     4709     0.00     0.00  ggml_compute_forward_get_rows
  0.00     15.06     0.00     4123     0.00     0.00  llama_sampler_accept
  0.00     15.06     0.00     4068     0.00     0.00  llama_sampler_apply
  0.00     15.06     0.00     3038     0.00     0.00  ggml_set_name
  0.00     15.06     0.00     2053     0.00     0.00  ggml_time_us
  0.00     15.06     0.00     1613     0.00     0.00  gguf_get_key
  0.00     15.06     0.00     1554     0.00     0.00  ggml_critical_section_end
  0.00     15.06     0.00     1554     0.00     0.00  ggml_critical_section_start
  0.00     15.06     0.00     1372     0.00     0.00  ggml_set_input
  0.00     15.06     0.00     1212     0.00     0.00  ggml_free
  0.00     15.06     0.00     1211     0.00     0.00  ggml_init
  0.00     15.06     0.00     1110     0.00     0.00  ggml_new_tensor_1d
  0.00     15.06     0.00     1030     0.00     0.00  ggml_get_rows
  0.00     15.06     0.00     1029     0.00     0.31  (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long)
  0.00     15.06     0.00     1022     0.00     0.00  ggml_backend_is_cpu
  0.00     15.06     0.00     1022     0.00     0.00  ggml_guid_matches
  0.00     15.06     0.00      988     0.00     0.00  void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long)
  0.00     15.06     0.00      927     0.00     0.00  void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long)
  0.00     15.06     0.00      913     0.00     0.00  (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long)
  0.00     15.06     0.00      799     0.00     0.00  ggml_get_next_tensor
  0.00     15.06     0.00      790     0.00     0.00  common_log_add(common_log*, ggml_log_level, char const*, ...)
  0.00     15.06     0.00      790     0.00     0.00  common_log_main()
  0.00     15.06     0.00      735     0.00     0.00  ggml_get_name
  0.00     15.06     0.00      733     0.00     0.00  void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&)
  0.00     15.06     0.00      693     0.00     0.00  ggml_graph_compute_with_ctx
  0.00     15.06     0.00      690     0.00     0.00  ggml_hash_set_reset
  0.00     15.06     0.00      690     0.00     0.00  ggml_hash_size
  0.00     15.06     0.00      687     0.00     0.00  std::vector<int, std::allocator<int> >::_M_default_append(unsigned long)
  0.00     15.06     0.00      684     0.00     0.00  ggml_backend_sched_reset
  0.00     15.06     0.00      684     0.00     0.00  llama_get_model
  0.00     15.06     0.00      680     0.00     0.00  llama_token_is_eog_impl(llama_vocab const&, int)
  0.00     15.06     0.00      680     0.00     0.00  ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long)
  0.00     15.06     0.00      680     0.00     0.00  ggml_backend_buffer_is_host
  0.00     15.06     0.00      680     0.00     0.00  ggml_backend_tensor_set
  0.00     15.06     0.00      680     0.00     0.00  ggml_graph_node
  0.00     15.06     0.00      680     0.00     0.00  llama_token_is_eog
  0.00     15.06     0.00      678     0.00     0.00  llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      678     0.00     0.00  llama_sampler_softmax_impl(llama_token_data_array*)
  0.00     15.06     0.00      565     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00      532     0.00     0.00  ggml_aligned_free
  0.00     15.06     0.00      532     0.00     0.00  ggml_aligned_malloc
  0.00     15.06     0.00      524     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&)
  0.00     15.06     0.00      522     0.00     0.00  format(char const*, ...)
  0.00     15.06     0.00      479     0.00     0.00  void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long)
  0.00     15.06     0.00      431     0.00     0.00  llama_log_internal(ggml_log_level, char const*, ...)
  0.00     15.06     0.00      431     0.00     0.00  llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*)
  0.00     15.06     0.00      431     0.00     0.00  common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*)
  0.00     15.06     0.00      385     0.00     0.00  common_arg::in_example(llama_example)
  0.00     15.06     0.00      376     0.00     0.00  common_arg::~common_arg()
  0.00     15.06     0.00      376     0.00     0.00  ggml_new_tensor_2d
  0.00     15.06     0.00      358     0.00     0.00  llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool)
  0.00     15.06     0.00      355     0.00     0.00  llama_format_tensor_shape(ggml_tensor const*)
  0.00     15.06     0.00      347     0.00     0.00  std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&)
  0.00     15.06     0.00      344     0.00     0.00  common_sampler_accept(common_sampler*, int, bool)
  0.00     15.06     0.00      344     0.00     0.00  common_token_to_piece[abi:cxx11](llama_context const*, int, bool)
  0.00     15.06     0.00      344     0.00     0.00  llama_sampler_dry_accept(llama_sampler*, int)
  0.00     15.06     0.00      344     0.00     0.00  llama_sampler_chain_accept(llama_sampler*, int)
  0.00     15.06     0.00      344     0.00     0.00  llama_sampler_penalties_accept(llama_sampler*, int)
  0.00     15.06     0.00      343     0.00     0.00  llama_build_graph(llama_context&, llama_ubatch const&, bool)
  0.00     15.06     0.00      343     0.00     0.00  ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char)
  0.00     15.06     0.00      343     0.00     0.00  llm_build_context::build_llama()
  0.00     15.06     0.00      343     0.00     0.00  std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00      343     0.00     0.00  std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run()
  0.00     15.06     0.00      343     0.00     0.00  ggml_backend_buffer_clear
  0.00     15.06     0.00      343     0.00     0.00  ggml_backend_sched_synchronize
  0.00     15.06     0.00      343     0.00     0.00  ggml_backend_synchronize
  0.00     15.06     0.00      343     0.00     0.00  ggml_graph_view
  0.00     15.06     0.00      343     0.00     0.00  ggml_new_graph_custom
  0.00     15.06     0.00      342     0.00     0.00  llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int)
  0.00     15.06     0.00      342     0.00     0.00  console::set_display(console::display_t)
  0.00     15.06     0.00      342     0.00     0.00  std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long)
  0.00     15.06     0.00      342     0.00     0.00  std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long)
  0.00     15.06     0.00      342     0.00     0.00  ggml_cpu_init
  0.00     15.06     0.00      341     0.00     0.00  llama_output_reserve(llama_context&, unsigned long)
  0.00     15.06     0.00      341     0.00     0.00  llama_n_vocab
  0.00     15.06     0.00      340     0.00     0.00  common_sampler_last(common_sampler const*)
  0.00     15.06     0.00      340     0.00     0.00  llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&)
  0.00     15.06     0.00      340     0.00     0.03  ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*)
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long)
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_buffer_reset
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_cpu_set_abort_callback
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_cpu_set_n_threads
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_cpu_set_threadpool
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_graph_compute_async
  0.00     15.06     0.00      340     0.00     0.02  ggml_backend_sched_alloc_graph
  0.00     15.06     0.00      340     0.00     0.03  ggml_backend_sched_graph_compute_async
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_sched_set_eval_callback
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_tensor_get
  0.00     15.06     0.00      340     0.00     0.00  ggml_backend_tensor_get_async
  0.00     15.06     0.00      340     0.00     0.00  ggml_gallocr_alloc_graph
  0.00     15.06     0.00      340     0.00     0.00  ggml_graph_plan
  0.00     15.06     0.00      340     0.00     0.00  llama_batch_get_one
  0.00     15.06     0.00      340     0.00     0.15  llama_decode
  0.00     15.06     0.00      340     0.00     0.00  llama_kv_cache_update
  0.00     15.06     0.00      340     0.00     0.00  llama_synchronize
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.09  llama_sampler_top_k_impl(llama_token_data_array*, int)
  0.00     15.06     0.00      339     0.00     0.09  llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*)
  0.00     15.06     0.00      339     0.00     0.00  llama_sampler_grammar_accept_impl(llama_sampler*, int)
  0.00     15.06     0.00      339     0.00     0.00  llama_get_logits_ith
  0.00     15.06     0.00      276     0.00     0.00  llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const
  0.00     15.06     0.00      258     0.00     0.00  std::vector<char, std::allocator<char> >::_M_default_append(unsigned long)
  0.00     15.06     0.00      256     0.00     0.00  std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long)
  0.00     15.06     0.00      256     0.00     0.00  std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&)
  0.00     15.06     0.00      256     0.00     0.00  std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&)
  0.00     15.06     0.00      252     0.00     0.00  quantize_row_q8_K_ref
  0.00     15.06     0.00      248     0.00     0.00  dequantize_row_q6_K
  0.00     15.06     0.00      203     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const
  0.00     15.06     0.00      184     0.00     0.00  ggml_backend_buffer_free
  0.00     15.06     0.00      184     0.00     0.00  ggml_tensor_overhead
  0.00     15.06     0.00      183     0.00     0.00  ggml_backend_buffer_init
  0.00     15.06     0.00      182     0.00     0.00  ggml_backend_buft_alloc_buffer
  0.00     15.06     0.00      173     0.00     0.00  common_arg::common_arg(common_arg const&)
  0.00     15.06     0.00      172     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long)
  0.00     15.06     0.00      164     0.00     0.00  ggml_backend_buft_get_device
  0.00     15.06     0.00      164     0.00     0.00  ggml_backend_dev_host_buffer_type
  0.00     15.06     0.00      163     0.00     0.00  weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*)
  0.00     15.06     0.00      158     0.00     0.00  gguf_get_kv_type
  0.00     15.06     0.00      148     0.00     0.00  llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*)
  0.00     15.06     0.00      147     0.00     0.00  llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int)
  0.00     15.06     0.00      147     0.00     0.00  std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&)
  0.00     15.06     0.00      147     0.00     0.00  std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00      147     0.00     0.00  gguf_find_tensor
  0.00     15.06     0.00      147     0.00     0.00  gguf_get_data_offset
  0.00     15.06     0.00      147     0.00     0.00  gguf_get_n_tensors
  0.00     15.06     0.00      147     0.00     0.00  gguf_get_tensor_offset
  0.00     15.06     0.00      120     0.00     0.00  common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)
  0.00     15.06     0.00      120     0.00     0.00  void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&)
  0.00     15.06     0.00      119     0.00     0.00  std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00      107     0.00     0.00  common_arg::set_examples(std::initializer_list<llama_example>)
  0.00     15.06     0.00      107     0.00     0.00  void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*)
  0.00     15.06     0.00      105     0.00     0.00  string_format[abi:cxx11](char const*, ...)
  0.00     15.06     0.00       96     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&))
  0.00     15.06     0.00       71     0.00     0.07  gguf_kv_to_str(gguf_context const*, int)
  0.00     15.06     0.00       60     0.00     0.00  common_arg::set_env(char const*)
  0.00     15.06     0.00       58     0.00     0.00  gguf_find_key
  0.00     15.06     0.00       50     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&))
  0.00     15.06     0.00       50     0.00     0.00  std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&)
  0.00     15.06     0.00       50     0.00     0.00  std::__throw_regex_error(std::regex_constants::error_type, char const*)
  0.00     15.06     0.00       49     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00       45     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00       40     0.00     0.00  gguf_type_name
  0.00     15.06     0.00       36     0.00     0.00  gguf_get_val_data
  0.00     15.06     0.00       32     0.00     0.00  std::__detail::_Scanner<char>::_M_advance()
  0.00     15.06     0.00       32     0.00     0.00  ggml_tallocr_alloc
  0.00     15.06     0.00       30     0.00     0.00  common_arg::set_sparam()
  0.00     15.06     0.00       30     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long)
  0.00     15.06     0.00       30     0.00     0.00  gguf_get_val_str
  0.00     15.06     0.00       28     0.00     0.00  bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool)
  0.00     15.06     0.00       26     0.00     0.00  void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&)
  0.00     15.06     0.00       25     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char()
  0.00     15.06     0.00       22     0.00     0.00  std::__detail::_Scanner<char>::_M_scan_in_bracket()
  0.00     15.06     0.00       19     0.00     0.00  ggml_backend_dev_count
  0.00     15.06     0.00       18     0.00     0.00  std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&)
  0.00     15.06     0.00       18     0.00     0.00  std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::~vector()
  0.00     15.06     0.00       17     0.00     0.00  std::__cxx11::to_string(int)
  0.00     15.06     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00     15.06     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00     15.06     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00     15.06     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00     15.06     0.00       16     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&)
  0.00     15.06     0.00       16     0.00     0.00  ggml_get_tensor
  0.00     15.06     0.00       16     0.00     0.00  ggml_new_tensor_3d
  0.00     15.06     0.00       16     0.00     0.00  ggml_rope
  0.00     15.06     0.00       15     0.00     0.00  bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)
  0.00     15.06     0.00       13     0.00     0.00  unicode_cpt_flags(unsigned int)
  0.00     15.06     0.00       13     0.00     0.00  gguf_get_val_u32
  0.00     15.06     0.00       12     0.00     0.00  void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&)
  0.00     15.06     0.00       12     0.00     0.00  gguf_get_arr_n
  0.00     15.06     0.00       12     0.00     0.00  llama_sampler_free
  0.00     15.06     0.00       11     0.00     0.00  llama_sampler_chain_n
  0.00     15.06     0.00       10     0.00     0.00  unicode_byte_to_utf8[abi:cxx11](unsigned char)
  0.00     15.06     0.00       10     0.00     0.00  __static_initialization_and_destruction_0()
  0.00     15.06     0.00       10     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const
  0.00     15.06     0.00       10     0.00     0.00  gguf_get_arr_type
  0.00     15.06     0.00       10     0.00     0.00  llama_sampler_chain_add
  0.00     15.06     0.00       10     0.00     0.00  llama_sampler_chain_get
  0.00     15.06     0.00       10     0.00     0.00  llama_sampler_name
  0.00     15.06     0.00       10     0.00     0.00  llama_state_seq_get_size
  0.00     15.06     0.00        9     0.00     0.00  tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool)
  0.00     15.06     0.00        9     0.00     0.00  get_reg()
  0.00     15.06     0.00        9     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int))
  0.00     15.06     0.00        9     0.00     0.00  void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&)
  0.00     15.06     0.00        9     0.00     0.00  void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&)
  0.00     15.06     0.00        8     0.00     0.00  llm_tokenizer_bpe_session::add_new_bigram(int, int)
  0.00     15.06     0.00        8     0.00     0.00  void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&)
  0.00     15.06     0.00        8     0.00     0.00  void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&)
  0.00     15.06     0.00        7     0.00     0.00  string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)
  0.00     15.06     0.00        7     0.00     0.00  common_sampler_type_to_chr(common_sampler_type)
  0.00     15.06     0.00        7     0.00     0.00  common_sampler_type_to_str[abi:cxx11](common_sampler_type)
  0.00     15.06     0.00        7     0.00     0.00  ggml_backend_cpu_device_get_type(ggml_backend_device*)
  0.00     15.06     0.00        7     0.00     0.00  ggml_backend_dev_get
  0.00     15.06     0.00        7     0.00     0.00  ggml_backend_dev_type
  0.00     15.06     0.00        7     0.00     0.00  ggml_get_first_tensor
  0.00     15.06     0.00        6     0.00     0.00  unicode_len_utf8(char)
  0.00     15.06     0.00        6     0.00     0.00  llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const
  0.00     15.06     0.00        6     0.00     0.00  void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&)
  0.00     15.06     0.00        6     0.00     0.00  std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&)
  0.00     15.06     0.00        6     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion()
  0.00     15.06     0.00        6     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression()
  0.00     15.06     0.00        6     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom()
  0.00     15.06     0.00        6     0.00     0.00  ggml_backend_reg_count
  0.00     15.06     0.00        6     0.00     0.00  ggml_type_name
  0.00     15.06     0.00        6     0.00     0.00  gguf_get_arr_data
  0.00     15.06     0.00        5     0.00     0.00  bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool)
  0.00     15.06     0.00        5     0.00     0.00  bool llama_model_loader::get_key<float>(llm_kv, float&, bool)
  0.00     15.06     0.00        5     0.00     0.00  void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&)
  0.00     15.06     0.00        4     0.00     0.00  postprocess_cpu_params(cpu_params&, cpu_params const*)
  0.00     15.06     0.00        4     0.00     0.00  ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long)
  0.00     15.06     0.00        4     0.00     0.00  llama_data_write_file::write(void const*, unsigned long)
  0.00     15.06     0.00        4     0.00     0.00  std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...)
  0.00     15.06     0.00        4     0.00     0.00  void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&)
  0.00     15.06     0.00        4     0.00     0.00  std::__detail::_Scanner<char>::_M_scan_normal()
  0.00     15.06     0.00        4     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier()
  0.00     15.06     0.00        4     0.00     0.00  ggml_backend_buft_name
  0.00     15.06     0.00        4     0.00     0.00  ggml_backend_cpu_buffer_type
  0.00     15.06     0.00        4     0.00     0.00  ggml_backend_cpu_reg
  0.00     15.06     0.00        4     0.00     0.00  ggml_backend_reg_dev_get
  0.00     15.06     0.00        4     0.00     0.00  llama_model_has_encoder
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*)
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*)
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*)
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long)
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*)
  0.00     15.06     0.00        3     0.00     0.00  common_arg::has_value_from_env()
  0.00     15.06     0.00        3     0.00     0.00  common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&))
  0.00     15.06     0.00        3     0.00     0.00  std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00        3     0.00     0.00  std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_destroy()
  0.00     15.06     0.00        3     0.00     0.00  std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()
  0.00     15.06     0.00        3     0.00     0.00  void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&)
  0.00     15.06     0.00        3     0.00     0.00  void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&)
  0.00     15.06     0.00        3     0.00     0.00  void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&)
  0.00     15.06     0.00        3     0.00     0.00  std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type)
  0.00     15.06     0.00        3     0.00     0.00  std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type)
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready()
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher()
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>)
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>)
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_Scanner<char>::_M_eat_escape_ecma()
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative()
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction()
  0.00     15.06     0.00        3     0.00     0.00  void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool)
  0.00     15.06     0.00        3     0.00     0.00  std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_buffer_name
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_buft_get_alignment
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_dev_buffer_type
  0.00     15.06     0.00        3     0.00     0.00  ggml_backend_dev_by_type
  0.00     15.06     0.00        3     0.00     0.02  ggml_backend_sched_reserve
  0.00     15.06     0.00        3     0.00     0.00  ggml_gallocr_reserve_n
  0.00     15.06     0.00        3     0.00     0.00  ggml_hash_set_free
  0.00     15.06     0.00        3     0.00     0.00  ggml_threadpool_free
  0.00     15.06     0.00        3     0.00     0.00  ggml_threadpool_params_init
  0.00     15.06     0.00        3     0.00     0.00  ggml_time_init
  0.00     15.06     0.00        3     0.00     0.00  iq2xs_free_impl
  0.00     15.06     0.00        2     0.00     0.00  unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&)
  0.00     15.06     0.00        2     0.00     0.00  llama_token_bos_impl(llama_vocab const&)
  0.00     15.06     0.00        2     0.00     0.00  llama_token_eos_impl(llama_vocab const&)
  0.00     15.06     0.00        2     0.00     0.00  llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool)
  0.00     15.06     0.00        2     0.00     0.00  ggml_threadpool_params_from_cpu_params(cpu_params const&)
  0.00     15.06     0.00        2     0.00     0.00  print_usage(int, char**)
  0.00     15.06     0.00        2     0.00     0.00  get_rng_seed(unsigned int)
  0.00     15.06     0.00        2     0.00     0.00  kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_cpu_reg_get_name(ggml_backend_reg*)
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*)
  0.00     15.06     0.00        2     0.00     0.00  unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&)
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*)
  0.00     15.06     0.00        2     0.00     0.00  llama_mmap::unmap_fragment(unsigned long, unsigned long)
  0.00     15.06     0.00        2     0.00     0.00  common_params::~common_params()
  0.00     15.06     0.00        2     0.00     0.00  llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&)
  0.00     15.06     0.00        2     0.00     0.00  std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>)
  0.00     15.06     0.00        2     0.00     0.00  std::_Hashtable<char, char, std::allocator<char>, std::__detail::_Identity, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, true, true> >::_Hashtable<char const*>(char const*, char const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<char> const&, std::integral_constant<bool, true>)
  0.00     15.06     0.00        2     0.00     0.00  std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long)
  0.00     15.06     0.00        2     0.00     0.00  std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long)
  0.00     15.06     0.00        2     0.00     0.00  std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        2     0.00     0.00  std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long)
  0.00     15.06     0.00        2     0.00     0.00  void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>)
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_buffer_is_multi_buffer
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_buffer_set_usage
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_dev_backend_reg
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_free
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_reg_by_name
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_reg_dev_count
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_reg_get
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_reg_get_proc_address
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_reg_name
  0.00     15.06     0.00        2     0.00     0.00  ggml_backend_sched_get_n_splits
  0.00     15.06     0.00        2     0.00     0.00  ggml_fopen
  0.00     15.06     0.00        2     0.00     0.00  ggml_graph_n_nodes
  0.00     15.06     0.00        2     0.00     0.00  ggml_graph_overhead_custom
  0.00     15.06     0.00        2     0.00     0.00  ggml_hash_set_new
  0.00     15.06     0.00        2     0.00     0.00  ggml_set_no_alloc
  0.00     15.06     0.00        2     0.00     0.00  ggml_threadpool_new_impl
  0.00     15.06     0.00        2     0.00     0.00  gguf_get_val_f32
  0.00     15.06     0.00        2     0.00     0.00  llama_model_is_recurrent
  0.00     15.06     0.00        2     0.00     0.00  llama_n_ctx_train
  0.00     15.06     0.00        2     0.00     0.00  llama_supports_rpc
  0.00     15.06     0.00        2     0.00     0.00  llama_token_bos
  0.00     15.06     0.00        2     0.00     0.00  llama_token_eos
  0.00     15.06     0.00        1     0.00     0.00  common_init()
  0.00     15.06     0.00        1     0.00     0.00  common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool)
  0.00     15.06     0.00        1     0.00     0.00  common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool)
  0.00     15.06     0.00        1     0.00     0.00  cpu_get_num_math()
  0.00     15.06     0.00        1     0.00     0.00  common_perf_print(llama_context const*, common_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**))
  0.00     15.06     0.00        1     0.00     0.00  common_sampler_free(common_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  common_sampler_init(llama_model const*, common_sampler_params const&)
  0.00     15.06     0.00        1     0.00     0.00  llama_token_nl_impl(llama_vocab const&)
  0.00     15.06     0.00        1     0.00     0.00  llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool)
  0.00     15.06     0.00        1     0.00     0.00  common_sampler_print[abi:cxx11](common_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  set_process_priority(ggml_sched_priority)
  0.00     15.06     0.00        1     0.00   130.39  common_init_from_params(common_params&)
  0.00     15.06     0.00        1     0.00     0.00  common_sampler_get_seed(common_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_add_bos_token_impl(llama_vocab const&)
  0.00     15.06     0.00        1     0.00     0.00  llama_add_eos_token_impl(llama_vocab const&)
  0.00     15.06     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))
  0.00     15.06     0.00        1     0.00     0.00  common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  common_model_params_to_llama(common_params const&)
  0.00     15.06     0.00        1     0.00     0.00  common_params_get_system_info[abi:cxx11](common_params const&)
  0.00     15.06     0.00        1     0.00     0.00  common_context_params_to_llama(common_params const&)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*)
  0.00     15.06     0.00        1     0.00     0.00  llm_load_arch(llama_model_loader&, llama_model&)
  0.00     15.06     0.00        1     0.00     0.00  write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&)
  0.00     15.06     0.00        1     0.00   114.98  llm_load_vocab(llama_model_loader&, llama_model&)
  0.00     15.06     0.00        1     0.00     2.11  llm_load_hparams(llama_model_loader&, llama_model&)
  0.00     15.06     0.00        1     0.00     0.06  llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_cpu_free(ggml_backend*)
  0.00     15.06     0.00        1     0.00     0.00  llama_model_type_name(e_model)
  0.00     15.06     0.00        1     0.00     0.00  llama_model_ftype_name(llama_ftype)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_dry_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_dry_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_xtc_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_xtc_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_dist_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_dist_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_chain_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_min_p_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_min_p_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_top_k_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_top_k_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_top_p_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_top_p_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_grammar_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_typical_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_typical_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_temp_ext_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_temp_ext_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_penalties_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_penalties_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_logit_bias_free(llama_sampler*)
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_logit_bias_name(llama_sampler const*)
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*)
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*)
  0.00     15.06     0.00        1     0.00     0.00  llama_model::~llama_model()
  0.00     15.06     0.00        1     0.00     0.00  llama_vocab::init_tokenizer()
  0.00     15.06     0.00        1     0.00     0.00  llama_vocab::~llama_vocab()
  0.00     15.06     0.00        1     0.00     0.00  common_params::common_params()
  0.00     15.06     0.00        1     0.00     0.00  llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&)
  0.00     15.06     0.00        1     0.00     0.00  llm_tokenizer_bpe::~llm_tokenizer_bpe()
  0.00     15.06     0.00        1     0.00     0.00  llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*)
  0.00     15.06     0.00        1     0.00     0.00  llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)
  0.00     15.06     0.00        1     0.00    12.61  llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*)
  0.00     15.06     0.00        1     0.00     0.00  common_sampler_params::common_sampler_params(common_sampler_params const&)
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_cpu_device_context::ggml_backend_cpu_device_context()
  0.00     15.06     0.00        1     0.00     0.00  console::init(bool, bool)
  0.00     15.06     0.00        1     0.00     0.00  common_sampler_params::print[abi:cxx11]() const
  0.00     15.06     0.00        1     0.00     0.00  LLM_KV::operator()[abi:cxx11](llm_kv) const
  0.00     15.06     0.00        1     0.00     0.00  std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>)
  0.00     15.06     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00        1     0.00     0.00  std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation)
  0.00     15.06     0.00        1     0.00     0.00  std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand()
  0.00     15.06     0.00        1     0.00     0.00  std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&)
  0.00     15.06     0.00        1     0.00     0.14  std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map()
  0.00     15.06     0.00        1     0.00     0.00  std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&)
  0.00     15.06     0.00        1     0.00     0.00  std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&)
  0.00     15.06     0.00        1     0.00     0.00  std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&)
  0.00     15.06     0.00        1     0.00     0.00  std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&)
  0.00     15.06     0.00        1     0.00     0.00  std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back()
  0.00     15.06     0.00        1     0.00     0.00  std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector()
  0.00     15.06     0.00        1     0.00     0.00  std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector()
  0.00     15.06     0.00        1     0.00     0.00  std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&)
  0.00     15.06     0.00        1     0.00     0.00  void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&)
  0.00     15.06     0.00        1     0.00     0.00  std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector()
  0.00     15.06     0.00        1     0.00     0.00  void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&)
  0.00     15.06     0.00        1     0.00     0.00  void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&)
  0.00     15.06     0.00        1     0.00     0.00  void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&)
  0.00     15.06     0.00        1     0.00     0.00  void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&)
  0.00     15.06     0.00        1     0.00     0.00  std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long)
  0.00     15.06     0.00        1     0.00     0.00  std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool)
  0.00     15.06     0.00        1     0.00     0.00  common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*)
  0.00     15.06     0.00        1     0.00     0.00  common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*)
  0.00     15.06     0.00        1     0.00     0.00  std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*)
  0.00     15.06     0.00        1     0.00     0.00  void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>)
  0.00     15.06     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)
  0.00     15.06     0.00        1     0.00     0.00  common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int)
  0.00     15.06     0.00        1     0.00     0.00  llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const
  0.00     15.06     0.00        1     0.00     0.00  std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const
  0.00     15.06     0.00        1     0.00     0.00  alloc_tensor_range
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_alloc_ctx_tensors_from_buft
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_buffer_get_alignment
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_buft_get_max_size
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_cpu_buffer_from_ptr
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_cpu_init
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_dev_buffer_from_host_ptr
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_dev_get_props
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_event_free
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_get_default_buffer_type
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_sched_free
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_sched_get_buffer_size
  0.00     15.06     0.00        1     0.00     0.00  ggml_backend_sched_new
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_amx_int8
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_arm_fma
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_avx
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_avx2
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_avx512
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_avx512_bf16
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_avx512_vbmi
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_avx512_vnni
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_avx_vnni
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_blas
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_fma
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_fp16_va
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_llamafile
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_matmul_int8
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_neon
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_riscv_v
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_sse3
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_ssse3
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_sve
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_vsx
  0.00     15.06     0.00        1     0.00     0.00  ggml_cpu_has_wasm_simd
  0.00     15.06     0.00        1     0.00     0.00  ggml_gallocr_free
  0.00     15.06     0.00        1     0.00     0.00  ggml_gallocr_get_buffer_size
  0.00     15.06     0.00        1     0.00     0.00  ggml_gallocr_new_n
  0.00     15.06     0.00        1     0.00     0.00  ggml_get_max_tensor_size
  0.00     15.06     0.00        1     0.00     0.00  ggml_get_no_alloc
  0.00     15.06     0.00        1     0.00     0.00  ggml_log_set
  0.00     15.06     0.00        1     0.00     0.00  ggml_quantize_free
  0.00     15.06     0.00        1     0.00     0.00  ggml_tallocr_new
  0.00     15.06     0.00        1     0.00     0.00  ggml_threadpool_new
  0.00     15.06     0.00        1     0.00     0.00  ggml_threadpool_params_default
  0.00     15.06     0.00        1     0.00     0.00  ggml_threadpool_params_match
  0.00     15.06     0.00        1     0.00     0.00  gguf_free
  0.00     15.06     0.00        1     0.00     0.00  gguf_get_version
  0.00     15.06     0.00        1     0.00    10.00  gguf_init_from_file
  0.00     15.06     0.00        1     0.00     0.00  iq3xs_free_impl
  0.00     15.06     0.00        1     0.00     0.00  llama_add_bos_token
  0.00     15.06     0.00        1     0.00     0.00  llama_add_eos_token
  0.00     15.06     0.00        1     0.00     0.00  llama_attach_threadpool
  0.00     15.06     0.00        1     0.00     0.00  llama_backend_free
  0.00     15.06     0.00        1     0.00     0.00  llama_backend_init
  0.00     15.06     0.00        1     0.00     0.00  llama_context_default_params
  0.00     15.06     0.00        1     0.00     0.00  llama_free
  0.00     15.06     0.00        1     0.00     0.00  llama_free_model
  0.00     15.06     0.00        1     0.00     0.00  llama_kv_cache_clear
  0.00     15.06     0.00        1     0.00   130.17  llama_load_model_from_file
  0.00     15.06     0.00        1     0.00     0.00  llama_log_set
  0.00     15.06     0.00        1     0.00     0.00  llama_lora_adapter_clear
  0.00     15.06     0.00        1     0.00     0.00  llama_model_default_params
  0.00     15.06     0.00        1     0.00     0.00  llama_model_has_decoder
  0.00     15.06     0.00        1     0.00     0.00  llama_n_ctx
  0.00     15.06     0.00        1     0.00     0.06  llama_new_context_with_model
  0.00     15.06     0.00        1     0.00     0.00  llama_numa_init
  0.00     15.06     0.00        1     0.00     0.00  llama_perf_context
  0.00     15.06     0.00        1     0.00     0.00  llama_perf_context_print
  0.00     15.06     0.00        1     0.00     0.00  llama_perf_context_reset
  0.00     15.06     0.00        1     0.00     0.00  llama_perf_sampler
  0.00     15.06     0.00        1     0.00     0.00  llama_perf_sampler_print
  0.00     15.06     0.00        1     0.00     0.00  llama_print_system_info
  0.00     15.06     0.00        1     0.00     0.00  llama_rope_type
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_chain_default_params
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_chain_init
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_get_seed
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_dist
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_dry
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_grammar
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_logit_bias
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_min_p
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_penalties
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_temp_ext
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_top_k
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_top_p
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_typical
  0.00     15.06     0.00        1     0.00     0.00  llama_sampler_init_xtc
  0.00     15.06     0.00        1     0.00     0.00  llama_supports_gpu_offload
  0.00     15.06     0.00        1     0.00     0.00  llama_token_nl
  0.00     15.06     0.00        1     0.00     0.00  llama_tokenize

 %         the percentage of the total running time of the
time       program used by this function.

cumulative a running sum of the number of seconds accounted
 seconds   for by this function and those listed above it.

 self      the number of seconds accounted for by this
seconds    function alone.  This is the major sort for this
           listing.

calls      the number of times this function was invoked, if
           this function is profiled, else blank.

 self      the average number of milliseconds spent in this
ms/call    function per call, if this function is profiled,
	   else blank.

 total     the average number of milliseconds spent in this
ms/call    function and its descendents per call, if this
	   function is profiled, else blank.

name       the name of the function.  This is the minor sort
           for this listing. The index shows the location of
	   the function in the gprof listing. If the index is
	   in parenthesis it shows where it would appear in
	   the gprof listing if it were to be printed.

Copyright (C) 2012-2024 Free Software Foundation, Inc.

Copying and distribution of this file, with or without modification,
are permitted in any medium without royalty provided the copyright
notice and this notice are preserved.

		     Call graph (explanation follows)


granularity: each sample hit covers 2 byte(s) for 0.07% of 15.06 seconds

index % time    self  children    called     name
                              736579             ggml_compute_forward [1]
[1]     98.1    0.04   14.73       0+736579  ggml_compute_forward [1]
                0.25   14.26  152808/152808      ggml_compute_forward_mul_mat [2]
                0.04    0.03   18931/18931       ggml_compute_forward_soft_max [16]
                0.05    0.01   72213/72213       ggml_compute_forward_mul [18]
                0.03    0.00   54736/54736       ggml_compute_forward_dup [21]
                0.02    0.00   46187/46187       ggml_compute_forward_rope_f32 [28]
                0.02    0.00   23987/23987       ggml_compute_forward_unary [29]
                0.02    0.00   56064/56064       ggml_compute_forward_rms_norm [30]
                0.00    0.00   45029/45029       ggml_compute_forward_add [57]
                0.00    0.00  750583/1068458     ggml_is_empty [124]
                0.00    0.00    4709/4709        ggml_compute_forward_get_rows [164]
                0.00    0.00    1300/68721       ggml_is_numa [146]
                              736579             ggml_compute_forward [1]
-----------------------------------------------
                0.25   14.26  152808/152808      ggml_compute_forward [1]
[2]     96.3    0.25   14.26  152808         ggml_compute_forward_mul_mat [2]
               10.14    0.00 30468500/30468500     ggml_vec_dot_q4_0_q8_0 [3]
                3.03    0.00 7083137/7083137     ggml_vec_dot_q6_K_q8_K [4]
                0.51    0.00  842518/842518      ggml_vec_dot_q4_1_q8_1 [5]
                0.00    0.32  244998/244998      llamafile_sgemm [6]
                0.18    0.00 6964096/6964096     ggml_vec_dot_f16 [10]
                0.03    0.00   21848/21848       quantize_row_q8_0 [23]
                0.01    0.00     415/415         quantize_row_q8_1 [44]
                0.01    0.00     224/224         quantize_row_q8_K [46]
                0.01    0.00  213049/238002      ggml_fp32_to_fp16_row [42]
                0.00    0.00  555601/664991      ggml_is_contiguous_0 [50]
                0.01    0.00  922769/922769      ggml_n_dims [54]
                0.00    0.00  620853/729057      ggml_is_contiguous [56]
                0.00    0.00  739479/985152      ggml_row_size [59]
                0.00    0.00  235855/3082515     ggml_blck_size [53]
                0.00    0.00  997664/3314228     ggml_type_size [123]
                0.00    0.00  279622/314410      ggml_get_type_traits [128]
                0.00    0.00   67080/68721       ggml_is_numa [146]
                0.00    0.00     252/252         quantize_row_q8_K_ref [205]
-----------------------------------------------
               10.14    0.00 30468500/30468500     ggml_compute_forward_mul_mat [2]
[3]     67.3   10.14    0.00 30468500         ggml_vec_dot_q4_0_q8_0 [3]
-----------------------------------------------
                3.03    0.00 7083137/7083137     ggml_compute_forward_mul_mat [2]
[4]     20.1    3.03    0.00 7083137         ggml_vec_dot_q6_K_q8_K [4]
-----------------------------------------------
                0.51    0.00  842518/842518      ggml_compute_forward_mul_mat [2]
[5]      3.4    0.51    0.00  842518         ggml_vec_dot_q4_1_q8_1 [5]
-----------------------------------------------
                0.00    0.32  244998/244998      ggml_compute_forward_mul_mat [2]
[6]      2.1    0.00    0.32  244998         llamafile_sgemm [6]
                0.00    0.32    1029/1029        (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [7]
                0.00    0.00     913/913         (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [966]
-----------------------------------------------
                0.00    0.32    1029/1029        llamafile_sgemm [6]
[7]      2.1    0.00    0.32    1029         (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [7]
                0.23    0.00    1036/1036        void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long) [9]
                0.09    0.00     622/622         void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long) [14]
-----------------------------------------------
                                                 <spontaneous>
[8]      1.6    0.00    0.24                 main [8]
                0.00    0.13       1/1           common_init_from_params(common_params&) [11]
                0.03    0.03     339/339         common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
                0.00    0.05     339/340         llama_decode [19]
                0.00    0.00     344/344         common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [83]
                0.00    0.00     680/680         llama_token_is_eog_impl(llama_vocab const&, int) [971]
                0.00    0.00     680/680         llama_token_is_eog [185]
                0.00    0.00     357/790         common_log_main() [968]
                0.00    0.00     357/790         common_log_add(common_log*, ggml_log_level, char const*, ...) [967]
                0.00    0.00     344/344         common_sampler_accept(common_sampler*, int, bool) [987]
                0.00    0.00     341/342         console::set_display(console::display_t) [994]
                0.00    0.00     340/340         common_sampler_last(common_sampler const*) [998]
                0.00    0.00     339/340         llama_batch_get_one [201]
                0.00    0.00      18/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1039]
                0.00    0.00       2/2           ggml_threadpool_params_from_cpu_params(cpu_params const&) [1113]
                0.00    0.00       2/2           print_usage(int, char**) [1114]
                0.00    0.00       2/4           llama_model_has_encoder [243]
                0.00    0.00       2/3           ggml_threadpool_free [249]
                0.00    0.00       1/1           common_params::common_params() [1186]
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
                0.00    0.00       1/2           common_params::~common_params() [1122]
                0.00    0.00       1/1           common_init() [1131]
                0.00    0.00       1/1           console::init(bool, bool) [1191]
                0.00    0.00       1/1           llama_numa_init [334]
                0.00    0.00       1/1212        ggml_free [173]
                0.00    0.00       1/1           llama_backend_init [324]
                0.00    0.00       1/1           set_process_priority(ggml_sched_priority) [1142]
                0.00    0.00       1/1           ggml_threadpool_params_match [316]
                0.00    0.00       1/2           ggml_threadpool_new_impl [268]
                0.00    0.00       1/1           ggml_threadpool_new [314]
                0.00    0.00       1/1           llama_attach_threadpool [322]
                0.00    0.00       1/2           llama_n_ctx_train [271]
                0.00    0.00       1/1           llama_n_ctx [333]
                0.00    0.00       1/1           llama_add_bos_token_impl(llama_vocab const&) [1144]
                0.00    0.00       1/1           llama_add_bos_token [320]
                0.00    0.00       1/1           std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector() [1210]
                0.00    0.00       1/1           std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector() [1213]
                0.00    0.00       1/1           common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1133]
                0.00    0.00       1/1           common_params_get_system_info[abi:cxx11](common_params const&) [1150]
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
                0.00    0.00       1/1           llama_add_eos_token_impl(llama_vocab const&) [1145]
                0.00    0.00       1/1           llama_add_eos_token [321]
                0.00    0.00       1/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00       1/1           llama_perf_context_print [336]
                0.00    0.00       1/1           common_perf_print(llama_context const*, common_sampler const*) [1135]
                0.00    0.00       1/1           write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&) [1154]
                0.00    0.00       1/1           llama_free [326]
                0.00    0.00       1/1           common_sampler_free(common_sampler*) [1137]
                0.00    0.00       1/1554        ggml_critical_section_end [170]
                0.00    0.00       1/1           ggml_quantize_free [312]
                0.00    0.00       1/1           llama_backend_free [323]
                0.00    0.00       1/1           llama_free_model [327]
                0.00    0.00       1/532         ggml_aligned_free [186]
                0.00    0.00       1/1           std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector() [1218]
                0.00    0.00       1/1           llama_sampler_get_seed [344]
                0.00    0.00       1/1           common_sampler_get_seed(common_sampler const*) [1143]
                0.00    0.00       1/1           common_sampler_params::print[abi:cxx11]() const [1192]
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
-----------------------------------------------
                0.23    0.00    1036/1036        (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [7]
[9]      1.5    0.23    0.00    1036         void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long) [9]
-----------------------------------------------
                0.18    0.00 6964096/6964096     ggml_compute_forward_mul_mat [2]
[10]     1.2    0.18    0.00 6964096         ggml_vec_dot_f16 [10]
-----------------------------------------------
                0.00    0.13       1/1           main [8]
[11]     0.9    0.00    0.13       1         common_init_from_params(common_params&) [11]
                0.00    0.13       1/1           llama_load_model_from_file [12]
                0.00    0.00       1/340         llama_decode [19]
                0.00    0.00       1/1           llama_new_context_with_model [80]
                0.00    0.00       2/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1039]
                0.00    0.00       1/1           common_model_params_to_llama(common_params const&) [1149]
                0.00    0.00       1/1           common_context_params_to_llama(common_params const&) [1151]
                0.00    0.00       1/790         common_log_main() [968]
                0.00    0.00       1/790         common_log_add(common_log*, ggml_log_level, char const*, ...) [967]
                0.00    0.00       1/2           llama_token_bos_impl(llama_vocab const&) [1110]
                0.00    0.00       1/2           llama_token_bos [273]
                0.00    0.00       1/2           llama_token_eos_impl(llama_vocab const&) [1111]
                0.00    0.00       1/2           llama_token_eos [274]
                0.00    0.00       1/4           llama_model_has_encoder [243]
                0.00    0.00       1/1           llama_model_has_decoder [332]
                0.00    0.00       1/340         llama_batch_get_one [201]
                0.00    0.00       1/1           llama_kv_cache_clear [328]
                0.00    0.00       1/1           llama_perf_context_reset [337]
                0.00    0.00       1/340         llama_synchronize [203]
                0.00    0.00       1/1           common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1147]
-----------------------------------------------
                0.00    0.13       1/1           common_init_from_params(common_params&) [11]
[12]     0.9    0.00    0.13       1         llama_load_model_from_file [12]
                0.00    0.11       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.01       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00       1/1           llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00       6/71          gguf_kv_to_str(gguf_context const*, int) [52]
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00      52/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00       7/355         llama_format_tensor_shape(ggml_tensor const*) [985]
                0.00    0.00       2/19          ggml_backend_dev_count [222]
                0.00    0.00       2/2053        ggml_time_us [168]
                0.00    0.00       1/3           ggml_time_init [251]
                0.00    0.00       1/7           ggml_backend_dev_get [233]
                0.00    0.00       1/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1067]
                0.00    0.00       1/7           ggml_backend_dev_type [234]
                0.00    0.00       1/1           llm_load_arch(llama_model_loader&, llama_model&) [1153]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1200]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1195]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1196]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1197]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1198]
                0.00    0.00       1/1           std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1199]
                0.00    0.00       1/1           llama_model_type_name(e_model) [1156]
                0.00    0.00       1/1           llama_model_ftype_name(llama_ftype) [1157]
                0.00    0.00       1/1212        ggml_free [173]
                0.00    0.00       1/1           gguf_free [317]
-----------------------------------------------
                0.00    0.11       1/1           llama_load_model_from_file [12]
[13]     0.8    0.00    0.11       1         llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.08    0.00  280147/280147      std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&) [15]
                0.00    0.02  130099/130443      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [33]
                0.00    0.01  128256/128256      std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [49]
                0.00    0.00  408403/816820      gguf_get_arr_str [40]
                0.00    0.00       1/361         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00  560294/560310      std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) [952]
                0.00    0.00  387158/387162      bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [954]
                0.00    0.00  280147/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [953]
                0.00    0.00  130099/130443      llama_token_to_piece [141]
                0.00    0.00     256/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00      25/522         format(char const*, ...) [977]
                0.00    0.00      18/28          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
                0.00    0.00       4/10          llama_state_seq_get_size [232]
                0.00    0.00       4/5           bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1075]
                0.00    0.00       4/58          gguf_find_key [218]
                0.00    0.00       2/12          gguf_get_arr_n [225]
                0.00    0.00       2/347         std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [986]
                0.00    0.00       1/6           gguf_get_arr_data [238]
                0.00    0.00       1/1           llama_vocab::init_tokenizer() [1184]
                0.00    0.00       1/2           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1112]
                0.00    0.00       1/355         llama_format_tensor_shape(ggml_tensor const*) [985]
                0.00    0.00       1/1           void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1228]
                0.00    0.00       1/2           void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1130]
                0.00    0.00       1/1           std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long) [1215]
                0.00    0.00       1/1           LLM_KV::operator()[abi:cxx11](llm_kv) const [1193]
-----------------------------------------------
                0.09    0.00     622/622         (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) [7]
[14]     0.6    0.09    0.00     622         void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long) [14]
-----------------------------------------------
                0.08    0.00  280147/280147      llm_load_vocab(llama_model_loader&, llama_model&) [13]
[15]     0.5    0.08    0.00  280147         std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&) [15]
-----------------------------------------------
                0.04    0.03   18931/18931       ggml_compute_forward [1]
[16]     0.5    0.04    0.03   18931         ggml_compute_forward_soft_max [16]
                0.03    0.00  100916/100916      ggml_vec_soft_max_f32 [22]
                0.00    0.00   18796/211567      ggml_nrows [34]
-----------------------------------------------
                0.03    0.03     339/339         main [8]
[17]     0.4    0.03    0.03     339         common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
                0.00    0.03     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.00     678/4068        llama_sampler_apply [166]
                0.00    0.00     339/339         llama_get_logits_ith [204]
                0.00    0.00     339/684         llama_get_model [182]
                0.00    0.00     339/341         llama_n_vocab [194]
                0.00    0.00     339/339         llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*) [1006]
                0.00    0.00       1/1           std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long) [1212]
-----------------------------------------------
                0.05    0.01   72213/72213       ggml_compute_forward [1]
[18]     0.4    0.05    0.01   72213         ggml_compute_forward_mul [18]
                0.01    0.00   72643/211567      ggml_nrows [34]
                0.00    0.00   72625/173887      ggml_are_same_shape [136]
                0.00    0.00   72426/145575      ggml_can_repeat [137]
-----------------------------------------------
                0.00    0.00       1/340         common_init_from_params(common_params&) [11]
                0.00    0.05     339/340         main [8]
[19]     0.3    0.00    0.05     340         llama_decode [19]
                0.02    0.03     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
-----------------------------------------------
                0.02    0.03     340/340         llama_decode [19]
[20]     0.3    0.02    0.03     340         llama_decode_internal(llama_context&, llama_batch) [20]
                0.00    0.01     340/340         ggml_backend_sched_graph_compute_async [36]
                0.01    0.00     340/361         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.01     340/340         ggml_backend_sched_alloc_graph [51]
                0.00    0.00     340/683         ggml_backend_sched_get_tensor_backend [43]
                0.00    0.00     340/343         llama_build_graph(llama_context&, llama_ubatch const&, bool) [60]
                0.00    0.00     340/340         ggml_backend_tensor_get [111]
                0.00    0.00     340/340         ggml_backend_tensor_get_async [112]
                0.00    0.00     686/687         std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [970]
                0.00    0.00     680/684         ggml_backend_sched_reset [181]
                0.00    0.00     680/680         ggml_graph_node [184]
                0.00    0.00     342/342         std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long) [995]
                0.00    0.00     342/342         std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long) [996]
                0.00    0.00     340/358         llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [984]
                0.00    0.00     340/341         llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00     340/340         llama_kv_cache_update [202]
                0.00    0.00     340/340         llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) [999]
                0.00    0.00     340/340         ggml_backend_sched_set_eval_callback [200]
                0.00    0.00     340/340         ggml_backend_cpu_set_threadpool [198]
                0.00    0.00     340/340         ggml_backend_cpu_set_abort_callback [196]
                0.00    0.00     340/340         ggml_backend_cpu_set_n_threads [197]
                0.00    0.00     340/340         ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long) [1000]
                0.00    0.00     340/342         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [993]
                0.00    0.00     340/2053        ggml_time_us [168]
-----------------------------------------------
                0.03    0.00   54736/54736       ggml_compute_forward [1]
[21]     0.2    0.03    0.00   54736         ggml_compute_forward_dup [21]
                0.00    0.00   24953/238002      ggml_fp32_to_fp16_row [42]
                0.00    0.00   87438/664991      ggml_is_contiguous_0 [50]
                0.00    0.00   86252/729057      ggml_is_contiguous [56]
                0.00    0.00   17037/3082515     ggml_blck_size [53]
                0.00    0.00  140089/232721      ggml_nelements [131]
                0.00    0.00   33551/314410      ggml_get_type_traits [128]
                0.00    0.00   14813/3314228     ggml_type_size [123]
-----------------------------------------------
                0.03    0.00  100916/100916      ggml_compute_forward_soft_max [16]
[22]     0.2    0.03    0.00  100916         ggml_vec_soft_max_f32 [22]
-----------------------------------------------
                0.03    0.00   21848/21848       ggml_compute_forward_mul_mat [2]
[23]     0.2    0.03    0.00   21848         quantize_row_q8_0 [23]
-----------------------------------------------
                0.00    0.03     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[24]     0.2    0.00    0.03     339         llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
                0.03    0.00     339/339         void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) [26]
                0.00    0.00   13221/80977       void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) [963]
-----------------------------------------------
                0.00    0.03     339/339         common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
[25]     0.2    0.00    0.03     339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.03     339/339         llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
                0.00    0.00    3390/4068        llama_sampler_apply [166]
                0.00    0.00     678/2053        ggml_time_us [168]
                0.00    0.00     339/339         llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1002]
                0.00    0.00     339/339         llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*) [1008]
                0.00    0.00     339/678         llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [973]
                0.00    0.00     339/339         llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*) [1003]
                0.00    0.00     339/339         llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) [1005]
                0.00    0.00     339/339         llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*) [1007]
                0.00    0.00     339/339         llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*) [1004]
                0.00    0.00     339/339         llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*) [1001]
                0.00    0.00     339/339         llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*) [1009]
                0.00    0.00     339/339         llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*) [1010]
-----------------------------------------------
                0.03    0.00     339/339         llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
[26]     0.2    0.03    0.00     339         void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) [26]
                0.00    0.00   67756/80977       void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) [963]
-----------------------------------------------
                                                 <spontaneous>
[27]     0.2    0.03    0.00                 _init [27]
-----------------------------------------------
                0.02    0.00   46187/46187       ggml_compute_forward [1]
[28]     0.2    0.02    0.00   46187         ggml_compute_forward_rope_f32 [28]
                0.00    0.00   45272/211567      ggml_nrows [34]
                0.00    0.00   46703/46703       ggml_rope_cache_init [150]
                0.00    0.00   44346/44346       ggml_rope_yarn_corr_dims [151]
-----------------------------------------------
                0.02    0.00   23987/23987       ggml_compute_forward [1]
[29]     0.1    0.02    0.00   23987         ggml_compute_forward_unary [29]
                0.00    0.00   24248/211567      ggml_nrows [34]
                0.00    0.00   24074/29514       ggml_get_unary_op [153]
-----------------------------------------------
                0.02    0.00   56064/56064       ggml_compute_forward [1]
[30]     0.1    0.02    0.00   56064         ggml_compute_forward_rms_norm [30]
                0.00    0.00   56236/173887      ggml_are_same_shape [136]
-----------------------------------------------
                0.00    0.02  871921/871921      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [33]
[31]     0.1    0.00    0.02  871921         unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [31]
                0.02    0.00  871921/871921      std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [32]
                0.00    0.00     512/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [950]
                0.00    0.00     256/256         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&) [1014]
-----------------------------------------------
                0.02    0.00  871921/871921      unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [31]
[32]     0.1    0.02    0.00  871921         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [32]
-----------------------------------------------
                0.00    0.00     344/130443      common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [83]
                0.00    0.02  130099/130443      llm_load_vocab(llama_model_loader&, llama_model&) [13]
[33]     0.1    0.00    0.02  130443         llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [33]
                0.00    0.02  871921/871921      unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [31]
                0.00    0.00  871921/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [950]
                0.00    0.00  130443/130443      llama_token_get_attr_impl(llama_vocab const&, int) [961]
                0.00    0.00  129591/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [953]
-----------------------------------------------
                0.00    0.00    5440/211567      ggml_graph_plan [65]
                0.00    0.00   18796/211567      ggml_compute_forward_soft_max [16]
                0.00    0.00   24248/211567      ggml_compute_forward_unary [29]
                0.00    0.00   45168/211567      ggml_compute_forward_add [57]
                0.00    0.00   45272/211567      ggml_compute_forward_rope_f32 [28]
                0.01    0.00   72643/211567      ggml_compute_forward_mul [18]
[34]     0.1    0.02    0.00  211567         ggml_nrows [34]
-----------------------------------------------
                0.00    0.01       1/1           llama_load_model_from_file [12]
[35]     0.1    0.00    0.01       1         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.01       1/1           gguf_init_from_file [38]
                0.00    0.00      35/71          gguf_kv_to_str(gguf_context const*, int) [52]
                0.00    0.00       1/1           std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [73]
                0.00    0.00     441/461275      ggml_nbytes [62]
                0.00    0.00     147/147         std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1021]
                0.00    0.00     147/232721      ggml_nelements [131]
                0.00    0.00     147/735         ggml_get_name [178]
                0.00    0.00     147/147         gguf_find_tensor [214]
                0.00    0.00     147/147         gguf_get_data_offset [215]
                0.00    0.00     147/147         gguf_get_tensor_offset [217]
                0.00    0.00     147/147         std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&) [1020]
                0.00    0.00     147/799         ggml_get_next_tensor [177]
                0.00    0.00      41/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00      40/40          gguf_type_name [219]
                0.00    0.00      35/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
                0.00    0.00      35/1613        gguf_get_key [169]
                0.00    0.00      35/158         gguf_get_kv_type [213]
                0.00    0.00      14/522         format(char const*, ...) [977]
                0.00    0.00       5/12          gguf_get_arr_n [225]
                0.00    0.00       5/10          gguf_get_arr_type [228]
                0.00    0.00       4/4           llama_data_write_file::write(void const*, unsigned long) [1080]
                0.00    0.00       4/6           ggml_type_name [237]
                0.00    0.00       2/58          gguf_find_key [218]
                0.00    0.00       1/10          llama_state_seq_get_size [232]
                0.00    0.00       1/2           ggml_fopen [263]
                0.00    0.00       1/7           ggml_get_first_tensor [235]
                0.00    0.00       1/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1033]
                0.00    0.00       1/818795      gguf_get_n_kv [125]
                0.00    0.00       1/1           gguf_get_version [318]
                0.00    0.00       1/1           void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&) [1219]
                0.00    0.00       1/3           void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1096]
                0.00    0.00       1/13          gguf_get_val_u32 [224]
-----------------------------------------------
                0.00    0.01     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[36]     0.1    0.00    0.01     340         ggml_backend_sched_graph_compute_async [36]
                0.00    0.01     340/340         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [37]
                0.00    0.00     340/340         ggml_backend_graph_compute_async [199]
-----------------------------------------------
                0.00    0.01     340/340         ggml_backend_sched_graph_compute_async [36]
[37]     0.1    0.00    0.01     340         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [37]
                0.01    0.00     340/340         ggml_graph_compute [45]
                0.00    0.00     340/340         ggml_graph_plan [65]
-----------------------------------------------
                0.00    0.01       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[38]     0.1    0.00    0.01       1         gguf_init_from_file [38]
                0.01    0.00  408611/408611      gguf_fread_str [41]
                0.00    0.00     294/3082515     ggml_blck_size [53]
                0.00    0.00     147/119394      ggml_new_tensor [67]
                0.00    0.00     147/985152      ggml_row_size [59]
                0.00    0.00     147/3038        ggml_set_name [167]
                0.00    0.00       2/184         ggml_tensor_overhead [208]
                0.00    0.00       2/2           ggml_set_no_alloc [267]
                0.00    0.00       1/2           ggml_fopen [263]
                0.00    0.00       1/58          gguf_find_key [218]
                0.00    0.00       1/1211        ggml_init [174]
-----------------------------------------------
                                   2             llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00       1/361         llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00       2/361         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       2/361         std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::~map() [82]
                0.00    0.00       5/361         std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [73]
                0.00    0.00       5/361         std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::~map() [74]
                0.00    0.00       6/361         std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::~map() [71]
                0.01    0.00     340/361         llama_decode_internal(llama_context&, llama_batch) [20]
[39]     0.1    0.01    0.00     361+2       llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00     680/680         ggml_backend_tensor_set [109]
                0.00    0.00     680/3314228     ggml_type_size [123]
                0.00    0.00     680/22632       ggml_element_size [154]
                0.00    0.00     680/680         ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long) [972]
                0.00    0.00     680/145427      ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [959]
                0.00    0.00     680/145427      ggml_backend_buft_is_host [138]
                0.00    0.00     680/680         ggml_backend_buffer_is_host [183]
                                   2             llama_set_inputs(llama_context&, llama_ubatch const&) [39]
-----------------------------------------------
                0.00    0.00  408403/816820      llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.01    0.00  408417/816820      gguf_kv_to_str(gguf_context const*, int) [52]
[40]     0.1    0.01    0.00  816820         gguf_get_arr_str [40]
                0.00    0.00  816820/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.01    0.00  408611/408611      gguf_init_from_file [38]
[41]     0.1    0.01    0.00  408611         gguf_fread_str [41]
-----------------------------------------------
                0.00    0.00   24953/238002      ggml_compute_forward_dup [21]
                0.01    0.00  213049/238002      ggml_compute_forward_mul_mat [2]
[42]     0.1    0.01    0.00  238002         ggml_fp32_to_fp16_row [42]
                0.00    0.00  249656/249657      ggml_cpu_has_f16c [129]
-----------------------------------------------
                0.00    0.00       3/683         ggml_backend_sched_reserve [88]
                0.00    0.00     340/683         ggml_backend_sched_alloc_graph [51]
                0.00    0.00     340/683         llama_decode_internal(llama_context&, llama_batch) [20]
[43]     0.1    0.01    0.00     683         ggml_backend_sched_get_tensor_backend [43]
                0.00    0.00  229531/229531      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
                0.00    0.00   55973/211810      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [957]
                0.00    0.00   55973/211810      ggml_backend_dev_supports_op [132]
                0.00    0.00   55973/211631      ggml_backend_supports_op [133]
                0.00    0.00     343/343         ggml_graph_view [191]
-----------------------------------------------
                0.01    0.00     415/415         ggml_compute_forward_mul_mat [2]
[44]     0.1    0.01    0.00     415         quantize_row_q8_1 [44]
-----------------------------------------------
                0.01    0.00     340/340         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [37]
[45]     0.1    0.01    0.00     340         ggml_graph_compute [45]
                0.00    0.00     340/1554        ggml_critical_section_end [170]
                0.00    0.00     340/342         ggml_cpu_init [193]
                0.00    0.00     340/68721       ggml_is_numa [146]
                0.00    0.00       1/532         ggml_aligned_free [186]
                0.00    0.00       1/3           ggml_threadpool_free [249]
                0.00    0.00       1/1           ggml_threadpool_params_default [315]
                0.00    0.00       1/2           ggml_threadpool_new_impl [268]
-----------------------------------------------
                0.01    0.00     224/224         ggml_compute_forward_mul_mat [2]
[46]     0.1    0.01    0.00     224         quantize_row_q8_K [46]
-----------------------------------------------
                                                 <spontaneous>
[47]     0.1    0.01    0.00                 ggml_vec_dot_q5_K_q8_K [47]
-----------------------------------------------
                0.01    0.00  128256/128256      std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [49]
[48]     0.1    0.01    0.00  128256         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long) [48]
-----------------------------------------------
                0.00    0.01  128256/128256      llm_load_vocab(llama_model_loader&, llama_model&) [13]
[49]     0.1    0.00    0.01  128256         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [49]
                0.01    0.00  128256/128256      std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long) [48]
-----------------------------------------------
                0.00    0.00   10976/664991      ggml_reshape_3d [68]
                0.00    0.00   10976/664991      ggml_soft_max_ext [69]
                0.00    0.00   87438/664991      ggml_compute_forward_dup [21]
                0.00    0.00  555601/664991      ggml_compute_forward_mul_mat [2]
[50]     0.0    0.01    0.00  664991         ggml_is_contiguous_0 [50]
                0.00    0.00 1264535/3082515     ggml_blck_size [53]
                0.00    0.00  705767/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.01     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[51]     0.0    0.00    0.01     340         ggml_backend_sched_alloc_graph [51]
                0.00    0.00     340/683         ggml_backend_sched_get_tensor_backend [43]
                0.00    0.00     340/340         ggml_gallocr_alloc_graph [64]
                0.00    0.00     340/1212        ggml_free [173]
                0.00    0.00     340/1211        ggml_init [174]
-----------------------------------------------
                0.00    0.00       6/71          llama_load_model_from_file [12]
                0.00    0.00      30/71          llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00      35/71          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[52]     0.0    0.00    0.01      71         gguf_kv_to_str(gguf_context const*, int) [52]
                0.01    0.00  408417/816820      gguf_get_arr_str [40]
                0.00    0.00  816834/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
                0.00    0.00  128292/128292      gguf_data_to_str(gguf_type, void const*, int) [962]
                0.00    0.00      65/158         gguf_get_kv_type [213]
                0.00    0.00      36/36          gguf_get_val_data [220]
                0.00    0.00      24/30          gguf_get_val_str [221]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1048]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1047]
                0.00    0.00      16/560310      std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) [952]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1046]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1045]
                0.00    0.00      16/16          std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1049]
                0.00    0.00       5/10          gguf_get_arr_type [228]
                0.00    0.00       5/12          gguf_get_arr_n [225]
                0.00    0.00       5/6           gguf_get_arr_data [238]
-----------------------------------------------
                0.00    0.00       2/3082515     llama_new_context_with_model [80]
                0.00    0.00     294/3082515     gguf_init_from_file [38]
                0.00    0.00    5488/3082515     ggml_new_tensor_impl.constprop.2 [94]
                0.00    0.00    5488/3082515     ggml_new_tensor_impl.constprop.3 [95]
                0.00    0.00   10976/3082515     ggml_is_contiguous_1 [99]
                0.00    0.00   17037/3082515     ggml_compute_forward_dup [21]
                0.00    0.00   21952/3082515     ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   27440/3082515     ggml_new_tensor_impl.constprop.0 [76]
                0.00    0.00  119394/3082515     ggml_new_tensor [67]
                0.00    0.00  235855/3082515     ggml_compute_forward_mul_mat [2]
                0.00    0.00  461275/3082515     ggml_nbytes [62]
                0.00    0.00  912779/3082515     ggml_row_size [59]
                0.00    0.00 1264535/3082515     ggml_is_contiguous_0 [50]
[53]     0.0    0.01    0.00 3082515         ggml_blck_size [53]
-----------------------------------------------
                0.01    0.00  922769/922769      ggml_compute_forward_mul_mat [2]
[54]     0.0    0.01    0.00  922769         ggml_n_dims [54]
-----------------------------------------------
                                                 <spontaneous>
[55]     0.0    0.01    0.00                 ggml_is_3d [55]
-----------------------------------------------
                0.00    0.00   10976/729057      ggml_reshape_3d [68]
                0.00    0.00   10976/729057      ggml_soft_max_ext [69]
                0.00    0.00   86252/729057      ggml_compute_forward_dup [21]
                0.00    0.00  620853/729057      ggml_compute_forward_mul_mat [2]
[56]     0.0    0.01    0.00  729057         ggml_is_contiguous [56]
-----------------------------------------------
                0.00    0.00   45029/45029       ggml_compute_forward [1]
[57]     0.0    0.00    0.00   45029         ggml_compute_forward_add [57]
                0.00    0.00   45168/211567      ggml_nrows [34]
                0.00    0.00   45333/145575      ggml_can_repeat [137]
                0.00    0.00   45026/173887      ggml_are_same_shape [136]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[58]     0.0    0.00    0.00       1         llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00      30/71          gguf_kv_to_str(gguf_context const*, int) [52]
                0.00    0.00      36/818795      gguf_get_n_kv [125]
                0.00    0.00      35/158         gguf_get_kv_type [213]
                0.00    0.00      30/1613        gguf_get_key [169]
                0.00    0.00      30/30          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long) [1037]
                0.00    0.00      10/28          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
                0.00    0.00       5/10          llama_state_seq_get_size [232]
                0.00    0.00       5/5           bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1076]
                0.00    0.00       2/522         format(char const*, ...) [977]
                0.00    0.00       1/5           bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1075]
                0.00    0.00       1/1           llama_rope_type [341]
-----------------------------------------------
                0.00    0.00     147/985152      gguf_init_from_file [38]
                0.00    0.00    5488/985152      ggml_new_tensor_impl.constprop.2 [94]
                0.00    0.00    5488/985152      ggml_new_tensor_impl.constprop.3 [95]
                0.00    0.00    5488/985152      llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
                0.00    0.00   10976/985152      llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00   21952/985152      ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   27440/985152      ggml_new_tensor_impl.constprop.0 [76]
                0.00    0.00   49300/985152      ggml_graph_plan [65]
                0.00    0.00  119394/985152      ggml_new_tensor [67]
                0.00    0.00  739479/985152      ggml_compute_forward_mul_mat [2]
[59]     0.0    0.00    0.00  985152         ggml_row_size [59]
                0.00    0.00  912779/3082515     ggml_blck_size [53]
                0.00    0.00  911411/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00       3/343         llama_new_context_with_model [80]
                0.00    0.00     340/343         llama_decode_internal(llama_context&, llama_batch) [20]
[60]     0.0    0.00    0.00     343         llama_build_graph(llama_context&, llama_ubatch const&, bool) [60]
                0.00    0.00     343/343         llm_build_context::build_llama() [61]
                0.00    0.00     343/1211        ggml_init [174]
                0.00    0.00     343/1212        ggml_free [173]
                0.00    0.00     343/343         std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [992]
-----------------------------------------------
                0.00    0.00     343/343         llama_build_graph(llama_context&, llama_ubatch const&, bool) [60]
[61]     0.0    0.00    0.00     343         llm_build_context::build_llama() [61]
                0.00    0.00   10976/10976       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
                0.00    0.00   10976/10976       ggml_reshape_3d [68]
                0.00    0.00   16807/38759       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [78]
                0.00    0.00   11319/11319       ggml_rms_norm [89]
                0.00    0.00   11319/16840       ggml_mul [84]
                0.00    0.00   10976/10976       ggml_add [92]
                0.00    0.00   10976/10992       ggml_rope_ext [91]
                0.00    0.00     686/1110        ggml_new_tensor_1d [102]
                0.00    0.00     686/1030        ggml_get_rows [103]
                0.00    0.00     343/343         std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [104]
                0.00    0.00     343/376         ggml_new_tensor_2d [106]
                0.00    0.00   73402/156408      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00    1029/1372        ggml_set_input [172]
                0.00    0.00     343/343         ggml_new_graph_custom [192]
                0.00    0.00     343/33271       ggml_build_forward_expand [152]
-----------------------------------------------
                0.00    0.00      32/461275      ggml_tallocr_alloc [119]
                0.00    0.00      32/461275      ggml_backend_alloc_ctx_tensors_from_buft [117]
                0.00    0.00      32/461275      llama_new_context_with_model [80]
                0.00    0.00     147/461275      ggml_get_max_tensor_size [115]
                0.00    0.00     147/461275      llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00     147/461275      llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [116]
                0.00    0.00     147/461275      llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00     340/461275      ggml_backend_tensor_get [111]
                0.00    0.00     340/461275      ggml_backend_tensor_get_async [112]
                0.00    0.00     441/461275      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00     680/461275      ggml_backend_tensor_set [109]
                0.00    0.00     693/461275      ggml_graph_compute_with_ctx [108]
                0.00    0.00     696/461275      ggml_gallocr_allocate_node [107]
                0.00    0.00    2454/461275      ggml_gallocr_reserve_n [101]
                0.00    0.00    5488/461275      ggml_new_tensor_impl.constprop.2 [94]
                0.00    0.00    5488/461275      ggml_new_tensor_impl.constprop.3 [95]
                0.00    0.00   21952/461275      ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   27440/461275      ggml_new_tensor_impl.constprop.0 [76]
                0.00    0.00  117819/461275      ggml_backend_tensor_alloc [70]
                0.00    0.00  276760/461275      ggml_gallocr_alloc_graph [64]
[62]     0.0    0.00    0.00  461275         ggml_nbytes [62]
                0.00    0.00  461275/3082515     ggml_blck_size [53]
                0.00    0.00  460371/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00   10976/10976       llm_build_context::build_llama() [61]
[63]     0.0    0.00    0.00   10976         llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
                0.00    0.00    5488/5488        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00    5488/5488        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
                0.00    0.00   16464/38759       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [78]
                0.00    0.00    5488/5488        ggml_unary [90]
                0.00    0.00    5488/16840       ggml_mul [84]
                0.00    0.00   27440/156408      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00   21952/33271       ggml_build_forward_expand [152]
                0.00    0.00    5488/5488        ggml_silu [163]
-----------------------------------------------
                0.00    0.00     340/340         ggml_backend_sched_alloc_graph [51]
[64]     0.0    0.00    0.00     340         ggml_gallocr_alloc_graph [64]
                0.00    0.00  276760/461275      ggml_nbytes [62]
                0.00    0.00  117640/117819      ggml_backend_tensor_alloc [70]
                0.00    0.00  276760/398486      ggml_backend_buft_get_alloc_size [126]
                0.00    0.00  177480/177659      ggml_backend_buffer_init_tensor [135]
                0.00    0.00  117640/353652      ggml_backend_buffer_get_base [127]
                0.00    0.00   59840/59840       ggml_backend_view_init [148]
                0.00    0.00     340/340         ggml_backend_buffer_reset [195]
-----------------------------------------------
                0.00    0.00     340/340         ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) [37]
[65]     0.0    0.00    0.00     340         ggml_graph_plan [65]
                0.00    0.00    5440/211567      ggml_nrows [34]
                0.00    0.00   49300/985152      ggml_row_size [59]
                0.00    0.00  176120/1068458     ggml_is_empty [124]
                0.00    0.00   49300/232721      ggml_nelements [131]
                0.00    0.00   21760/21761       ggml_is_quantized [155]
                0.00    0.00   16320/3314228     ggml_type_size [123]
                0.00    0.00    5440/29514       ggml_get_unary_op [153]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
[66]     0.0    0.00    0.00    5488         llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00    5488/5488        ggml_soft_max_ext [69]
                0.00    0.00   10976/10976       ggml_permute [86]
                0.00    0.00   10976/10976       ggml_view_3d [87]
                0.00    0.00   10976/49848       ggml_mul_mat [72]
                0.00    0.00    5488/5488        ggml_cont_4d [100]
                0.00    0.00    5488/38759       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [78]
                0.00    0.00   10976/985152      ggml_row_size [59]
                0.00    0.00   43904/156408      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00   10976/3314228     ggml_type_size [123]
                0.00    0.00   10976/22632       ggml_element_size [154]
                0.00    0.00    5488/5488        ggml_mul_mat_set_prec [162]
                0.00    0.00    5488/5488        ggml_cont_2d [160]
                0.00    0.00    5488/33271       ggml_build_forward_expand [152]
-----------------------------------------------
                0.00    0.00      16/119394      ggml_new_tensor_3d [120]
                0.00    0.00      16/119394      ggml_rope [121]
                0.00    0.00     147/119394      gguf_init_from_file [38]
                0.00    0.00     147/119394      llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [114]
                0.00    0.00     376/119394      ggml_new_tensor_2d [106]
                0.00    0.00    1110/119394      ggml_new_tensor_1d [102]
                0.00    0.00    5488/119394      ggml_soft_max_ext [69]
                0.00    0.00    5488/119394      ggml_unary [90]
                0.00    0.00    6631/119394      ggml_new_tensor_4d [98]
                0.00    0.00   10976/119394      ggml_add [92]
                0.00    0.00   10992/119394      ggml_rope_ext [91]
                0.00    0.00   11319/119394      ggml_rms_norm [89]
                0.00    0.00   16840/119394      ggml_mul [84]
                0.00    0.00   49848/119394      ggml_mul_mat [72]
[67]     0.0    0.00    0.00  119394         ggml_new_tensor [67]
                0.00    0.00  119394/3082515     ggml_blck_size [53]
                0.00    0.00  119394/985152      ggml_row_size [59]
                0.00    0.00  119394/180105      ggml_new_object [134]
                0.00    0.00  119394/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00   10976/10976       llm_build_context::build_llama() [61]
[68]     0.0    0.00    0.00   10976         ggml_reshape_3d [68]
                0.00    0.00   10976/664991      ggml_is_contiguous_0 [50]
                0.00    0.00   10976/729057      ggml_is_contiguous [56]
                0.00    0.00   10976/21952       ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   10976/232721      ggml_nelements [131]
                0.00    0.00   10976/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
[69]     0.0    0.00    0.00    5488         ggml_soft_max_ext [69]
                0.00    0.00   10976/664991      ggml_is_contiguous_0 [50]
                0.00    0.00   10976/729057      ggml_is_contiguous [56]
                0.00    0.00    5488/119394      ggml_new_tensor [67]
                0.00    0.00    5488/5488        ggml_is_matrix [161]
                0.00    0.00    5488/61266       ggml_dup_tensor [147]
-----------------------------------------------
                0.00    0.00      32/117819      alloc_tensor_range [118]
                0.00    0.00     147/117819      llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00  117640/117819      ggml_gallocr_alloc_graph [64]
[70]     0.0    0.00    0.00  117819         ggml_backend_tensor_alloc [70]
                0.00    0.00  117819/461275      ggml_nbytes [62]
                0.00    0.00  235638/353652      ggml_backend_buffer_get_base [127]
                0.00    0.00  117819/398486      ggml_backend_buft_get_alloc_size [126]
                0.00    0.00  117819/117851      ggml_backend_buffer_get_alloc_size [144]
                0.00    0.00  117819/118197      ggml_backend_buffer_get_size [143]
-----------------------------------------------
                                                 <spontaneous>
[71]     0.0    0.00    0.00                 std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::~map() [71]
                0.00    0.00       6/361         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
-----------------------------------------------
                0.00    0.00     113/49848       weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00   10976/49848       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00   38759/49848       llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [78]
[72]     0.0    0.00    0.00   49848         ggml_mul_mat [72]
                0.00    0.00   49848/119394      ggml_new_tensor [67]
                0.00    0.00   49848/49848       ggml_is_transposed [149]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[73]     0.0    0.00    0.00       1         std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [73]
                0.00    0.00       5/361         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
-----------------------------------------------
                                                 <spontaneous>
[74]     0.0    0.00    0.00                 std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::~map() [74]
                0.00    0.00       5/361         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
[75]     0.0    0.00    0.00    5488         llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
                0.00    0.00   10976/10976       ggml_cpy [85]
                0.00    0.00    5488/5488        ggml_transpose [93]
                0.00    0.00    5488/5488        ggml_view_1d [96]
                0.00    0.00    5488/5488        ggml_view_2d [97]
                0.00    0.00    5488/985152      ggml_row_size [59]
                0.00    0.00   10976/156408      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00   10976/3314228     ggml_type_size [123]
                0.00    0.00   10976/22632       ggml_element_size [154]
                0.00    0.00    5488/33271       ggml_build_forward_expand [152]
-----------------------------------------------
                0.00    0.00   27440/27440       ggml_view_tensor [77]
[76]     0.0    0.00    0.00   27440         ggml_new_tensor_impl.constprop.0 [76]
                0.00    0.00   27440/3082515     ggml_blck_size [53]
                0.00    0.00   27440/461275      ggml_nbytes [62]
                0.00    0.00   27440/985152      ggml_row_size [59]
                0.00    0.00   27440/180105      ggml_new_object [134]
                0.00    0.00   27440/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00    5488/27440       ggml_transpose [93]
                0.00    0.00   10976/27440       ggml_cpy [85]
                0.00    0.00   10976/27440       ggml_permute [86]
[77]     0.0    0.00    0.00   27440         ggml_view_tensor [77]
                0.00    0.00   27440/27440       ggml_new_tensor_impl.constprop.0 [76]
                0.00    0.00   27440/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00    5488/38759       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00   16464/38759       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
                0.00    0.00   16807/38759       llm_build_context::build_llama() [61]
[78]     0.0    0.00    0.00   38759         llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) [78]
                0.00    0.00   38759/49848       ggml_mul_mat [72]
-----------------------------------------------
                0.00    0.00   10976/21952       ggml_reshape_3d [68]
                0.00    0.00   10976/21952       ggml_view_3d [87]
[79]     0.0    0.00    0.00   21952         ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   21952/3082515     ggml_blck_size [53]
                0.00    0.00   21952/461275      ggml_nbytes [62]
                0.00    0.00   21952/985152      ggml_row_size [59]
                0.00    0.00   21952/180105      ggml_new_object [134]
                0.00    0.00   21952/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [11]
[80]     0.0    0.00    0.00       1         llama_new_context_with_model [80]
                0.00    0.00       3/3           ggml_backend_sched_reserve [88]
                0.00    0.00       3/343         llama_build_graph(llama_context&, llama_ubatch const&, bool) [60]
                0.00    0.00      64/1110        ggml_new_tensor_1d [102]
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [117]
                0.00    0.00      32/461275      ggml_nbytes [62]
                0.00    0.00      16/16          ggml_rope [121]
                0.00    0.00       2/3082515     ggml_blck_size [53]
                0.00    0.00      32/247678      ggml_format_name [130]
                0.00    0.00      18/184         ggml_tensor_overhead [208]
                0.00    0.00      17/1211        ggml_init [174]
                0.00    0.00      16/182         ggml_backend_buft_alloc_buffer [210]
                0.00    0.00      16/211810      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [957]
                0.00    0.00      16/211810      ggml_backend_dev_supports_op [132]
                0.00    0.00      16/1212        ggml_free [173]
                0.00    0.00      16/184         ggml_backend_buffer_free [207]
                0.00    0.00      15/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00       3/3           ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*) [1086]
                0.00    0.00       3/4           ggml_backend_buft_name [239]
                0.00    0.00       3/118197      ggml_backend_buffer_get_size [143]
                0.00    0.00       2/2           llama_model_is_recurrent [270]
                0.00    0.00       2/19          ggml_backend_dev_count [222]
                0.00    0.00       2/2           std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long) [1126]
                0.00    0.00       2/3           ggml_backend_buffer_name [244]
                0.00    0.00       2/6           ggml_type_name [237]
                0.00    0.00       2/2           ggml_backend_sched_get_n_splits [262]
                0.00    0.00       2/2           ggml_graph_n_nodes [264]
                0.00    0.00       1/21761       ggml_is_quantized [155]
                0.00    0.00       1/4           llama_model_has_encoder [243]
                0.00    0.00       1/7           ggml_backend_dev_get [233]
                0.00    0.00       1/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1067]
                0.00    0.00       1/7           ggml_backend_dev_type [234]
                0.00    0.00       1/1           ggml_backend_cpu_init [278]
                0.00    0.00       1/10913       ggml_backend_get_device [157]
                0.00    0.00       1/2           ggml_backend_dev_backend_reg [255]
                0.00    0.00       1/2           ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) [1118]
                0.00    0.00       1/2           ggml_backend_reg_get_proc_address [260]
                0.00    0.00       1/343         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [991]
                0.00    0.00       1/343         ggml_backend_buffer_clear [188]
                0.00    0.00       1/355         llama_format_tensor_shape(ggml_tensor const*) [985]
                0.00    0.00       1/342         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [993]
                0.00    0.00       1/341         llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00       1/1022        ggml_guid_matches [176]
                0.00    0.00       1/1022        ggml_backend_is_cpu [175]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [240]
                0.00    0.00       1/3           ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) [1087]
                0.00    0.00       1/3           ggml_backend_dev_buffer_type [246]
                0.00    0.00       1/1           ggml_backend_get_default_buffer_type [282]
                0.00    0.00       1/2           ggml_graph_overhead_custom [265]
                0.00    0.00       1/1           ggml_backend_sched_new [285]
                0.00    0.00       1/2           llama_token_bos_impl(llama_vocab const&) [1110]
                0.00    0.00       1/2           llama_token_bos [273]
                0.00    0.00       1/1           ggml_gallocr_get_buffer_size [308]
                0.00    0.00       1/1           ggml_backend_sched_get_buffer_size [284]
                0.00    0.00       1/1           void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&) [1221]
                0.00    0.00       1/1           std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long) [1209]
                0.00    0.00       1/3           void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1096]
                0.00    0.00       1/1           std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long) [1223]
                0.00    0.00       1/1           void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&) [1220]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[81]     0.0    0.00    0.00       1         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       2/361         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00     276/276         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
                0.00    0.00       1/1           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00     147/461275      ggml_nbytes [62]
                0.00    0.00       1/1           llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [116]
                0.00    0.00       1/1           ggml_get_max_tensor_size [115]
                0.00    0.00     294/799         ggml_get_next_tensor [177]
                0.00    0.00     294/735         ggml_get_name [178]
                0.00    0.00       9/9           void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&) [1060]
                0.00    0.00       4/19          ggml_backend_dev_count [222]
                0.00    0.00       3/7           ggml_get_first_tensor [235]
                0.00    0.00       2/7           ggml_backend_dev_get [233]
                0.00    0.00       2/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1067]
                0.00    0.00       2/7           ggml_backend_dev_type [234]
                0.00    0.00       2/3           ggml_backend_dev_by_type [247]
                0.00    0.00       2/4           ggml_backend_cpu_buffer_type [240]
                0.00    0.00       2/3           ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) [1087]
                0.00    0.00       2/3           ggml_backend_dev_buffer_type [246]
                0.00    0.00       1/2           ggml_backend_dev_backend_reg [255]
                0.00    0.00       1/2           ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) [1118]
                0.00    0.00       1/2           ggml_backend_reg_get_proc_address [260]
                0.00    0.00       1/184         ggml_tensor_overhead [208]
                0.00    0.00       1/1           void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&) [1222]
                0.00    0.00       1/1           std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long) [1208]
                0.00    0.00       1/1           std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long) [1214]
                0.00    0.00       1/2           std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [1127]
                0.00    0.00       1/164         ggml_backend_buft_get_device [211]
                0.00    0.00       1/1           ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*) [1180]
                0.00    0.00       1/1           ggml_backend_dev_get_props [280]
                0.00    0.00       1/2           ggml_backend_buffer_set_usage [254]
                0.00    0.00       1/2           void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1130]
                0.00    0.00       1/2           llama_supports_rpc [272]
                0.00    0.00       1/1           llama_supports_gpu_offload [356]
                0.00    0.00       1/1           ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*) [1182]
                0.00    0.00       1/4           ggml_backend_buft_name [239]
                0.00    0.00       1/3           ggml_backend_buffer_name [244]
                0.00    0.00       1/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00       1/118197      ggml_backend_buffer_get_size [143]
                0.00    0.00       1/342         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [993]
                0.00    0.00       1/1           ggml_backend_cpu_buffer_from_ptr [277]
                0.00    0.00       1/1           ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long) [1181]
                0.00    0.00       1/1           ggml_backend_dev_buffer_from_host_ptr [279]
-----------------------------------------------
                                                 <spontaneous>
[82]     0.0    0.00    0.00                 std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::~map() [82]
                0.00    0.00       2/361         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
-----------------------------------------------
                0.00    0.00     344/344         main [8]
[83]     0.0    0.00    0.00     344         common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [83]
                0.00    0.00     344/130443      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [33]
                0.00    0.00     344/684         llama_get_model [182]
                0.00    0.00     344/130443      llama_token_to_piece [141]
-----------------------------------------------
                0.00    0.00      33/16840       weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00    5488/16840       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
                0.00    0.00   11319/16840       llm_build_context::build_llama() [61]
[84]     0.0    0.00    0.00   16840         ggml_mul [84]
                0.00    0.00   16840/119394      ggml_new_tensor [67]
                0.00    0.00   16840/145575      ggml_can_repeat [137]
                0.00    0.00   16840/61266       ggml_dup_tensor [147]
-----------------------------------------------
                0.00    0.00   10976/10976       llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
[85]     0.0    0.00    0.00   10976         ggml_cpy [85]
                0.00    0.00   10976/27440       ggml_view_tensor [77]
                0.00    0.00   21952/232721      ggml_nelements [131]
                0.00    0.00   10976/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00   10976/10976       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
[86]     0.0    0.00    0.00   10976         ggml_permute [86]
                0.00    0.00   10976/27440       ggml_view_tensor [77]
                0.00    0.00   10976/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00   10976/10976       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
[87]     0.0    0.00    0.00   10976         ggml_view_3d [87]
                0.00    0.00   10976/21952       ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   10976/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00       3/3           llama_new_context_with_model [80]
[88]     0.0    0.00    0.00       3         ggml_backend_sched_reserve [88]
                0.00    0.00       3/683         ggml_backend_sched_get_tensor_backend [43]
                0.00    0.00       3/3           ggml_gallocr_reserve_n [101]
                0.00    0.00       3/1212        ggml_free [173]
                0.00    0.00       3/1211        ggml_init [174]
                0.00    0.00       3/343         ggml_backend_sched_synchronize [189]
                0.00    0.00       3/684         ggml_backend_sched_reset [181]
-----------------------------------------------
                0.00    0.00   11319/11319       llm_build_context::build_llama() [61]
[89]     0.0    0.00    0.00   11319         ggml_rms_norm [89]
                0.00    0.00   11319/119394      ggml_new_tensor [67]
                0.00    0.00   11319/61266       ggml_dup_tensor [147]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
[90]     0.0    0.00    0.00    5488         ggml_unary [90]
                0.00    0.00    5488/5488        ggml_is_contiguous_1 [99]
                0.00    0.00    5488/119394      ggml_new_tensor [67]
                0.00    0.00    5488/61266       ggml_dup_tensor [147]
-----------------------------------------------
                0.00    0.00      16/10992       weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00   10976/10992       llm_build_context::build_llama() [61]
[91]     0.0    0.00    0.00   10992         ggml_rope_ext [91]
                0.00    0.00   10992/119394      ggml_new_tensor [67]
                0.00    0.00   10992/11008       ggml_is_vector [156]
                0.00    0.00   10992/61266       ggml_dup_tensor [147]
-----------------------------------------------
                0.00    0.00   10976/10976       llm_build_context::build_llama() [61]
[92]     0.0    0.00    0.00   10976         ggml_add [92]
                0.00    0.00   10976/119394      ggml_new_tensor [67]
                0.00    0.00   10976/145575      ggml_can_repeat [137]
                0.00    0.00   10976/61266       ggml_dup_tensor [147]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
[93]     0.0    0.00    0.00    5488         ggml_transpose [93]
                0.00    0.00    5488/27440       ggml_view_tensor [77]
                0.00    0.00    5488/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00    5488/5488        ggml_view_2d [97]
[94]     0.0    0.00    0.00    5488         ggml_new_tensor_impl.constprop.2 [94]
                0.00    0.00    5488/3082515     ggml_blck_size [53]
                0.00    0.00    5488/461275      ggml_nbytes [62]
                0.00    0.00    5488/985152      ggml_row_size [59]
                0.00    0.00    5488/180105      ggml_new_object [134]
                0.00    0.00    5488/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00    5488/5488        ggml_view_1d [96]
[95]     0.0    0.00    0.00    5488         ggml_new_tensor_impl.constprop.3 [95]
                0.00    0.00    5488/3082515     ggml_blck_size [53]
                0.00    0.00    5488/461275      ggml_nbytes [62]
                0.00    0.00    5488/985152      ggml_row_size [59]
                0.00    0.00    5488/180105      ggml_new_object [134]
                0.00    0.00    5488/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
[96]     0.0    0.00    0.00    5488         ggml_view_1d [96]
                0.00    0.00    5488/5488        ggml_new_tensor_impl.constprop.3 [95]
                0.00    0.00    5488/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
[97]     0.0    0.00    0.00    5488         ggml_view_2d [97]
                0.00    0.00    5488/5488        ggml_new_tensor_impl.constprop.2 [94]
                0.00    0.00    5488/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00     113/6631        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00    1030/6631        ggml_get_rows [103]
                0.00    0.00    5488/6631        ggml_cont_4d [100]
[98]     0.0    0.00    0.00    6631         ggml_new_tensor_4d [98]
                0.00    0.00    6631/119394      ggml_new_tensor [67]
-----------------------------------------------
                0.00    0.00    5488/5488        ggml_unary [90]
[99]     0.0    0.00    0.00    5488         ggml_is_contiguous_1 [99]
                0.00    0.00   10976/3082515     ggml_blck_size [53]
                0.00    0.00    5488/3314228     ggml_type_size [123]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
[100]    0.0    0.00    0.00    5488         ggml_cont_4d [100]
                0.00    0.00    5488/6631        ggml_new_tensor_4d [98]
                0.00    0.00    5488/232721      ggml_nelements [131]
                0.00    0.00    5488/247678      ggml_format_name [130]
-----------------------------------------------
                0.00    0.00       3/3           ggml_backend_sched_reserve [88]
[101]    0.0    0.00    0.00       3         ggml_gallocr_reserve_n [101]
                0.00    0.00    2454/461275      ggml_nbytes [62]
                0.00    0.00    4833/4833        ggml_gallocr_allocate_node [107]
                0.00    0.00     693/693         ggml_graph_compute_with_ctx [108]
                0.00    0.00    2454/398486      ggml_backend_buft_get_alloc_size [126]
                0.00    0.00       3/690         ggml_hash_set_reset [179]
                0.00    0.00       2/118197      ggml_backend_buffer_get_size [143]
                0.00    0.00       1/184         ggml_backend_buffer_free [207]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1088]
                0.00    0.00       1/182         ggml_backend_buft_alloc_buffer [210]
                0.00    0.00       1/2           ggml_backend_buffer_set_usage [254]
                0.00    0.00       1/3           ggml_hash_set_free [248]
                0.00    0.00       1/2           ggml_hash_set_new [266]
-----------------------------------------------
                0.00    0.00      17/1110        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00      64/1110        llama_new_context_with_model [80]
                0.00    0.00     343/1110        std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [104]
                0.00    0.00     686/1110        llm_build_context::build_llama() [61]
[102]    0.0    0.00    0.00    1110         ggml_new_tensor_1d [102]
                0.00    0.00    1110/119394      ggml_new_tensor [67]
-----------------------------------------------
                0.00    0.00       1/1030        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00     343/1030        std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [104]
                0.00    0.00     686/1030        llm_build_context::build_llama() [61]
[103]    0.0    0.00    0.00    1030         ggml_get_rows [103]
                0.00    0.00    1030/6631        ggml_new_tensor_4d [98]
-----------------------------------------------
                0.00    0.00     343/343         llm_build_context::build_llama() [61]
[104]    0.0    0.00    0.00     343         std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [104]
                0.00    0.00     343/1110        ggml_new_tensor_1d [102]
                0.00    0.00     343/1030        ggml_get_rows [103]
                0.00    0.00     686/156408      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00     343/1372        ggml_set_input [172]
-----------------------------------------------
                0.00    0.00     276/276         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[105]    0.0    0.00    0.00     276         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
                0.00    0.00     163/163         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00     147/147         llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [114]
                0.00    0.00     439/522         format(char const*, ...) [977]
                0.00    0.00     163/164         ggml_backend_buft_get_device [211]
                0.00    0.00     163/164         ggml_backend_dev_host_buffer_type [212]
                0.00    0.00      16/16          ggml_get_tensor [223]
                0.00    0.00       1/1211        ggml_init [174]
                0.00    0.00       1/355         llama_format_tensor_shape(ggml_tensor const*) [985]
                0.00    0.00       1/3           void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1096]
-----------------------------------------------
                0.00    0.00      33/376         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00     343/376         llm_build_context::build_llama() [61]
[106]    0.0    0.00    0.00     376         ggml_new_tensor_2d [106]
                0.00    0.00     376/119394      ggml_new_tensor [67]
-----------------------------------------------
                0.00    0.00    4833/4833        ggml_gallocr_reserve_n [101]
[107]    0.0    0.00    0.00    4833         ggml_gallocr_allocate_node [107]
                0.00    0.00     696/461275      ggml_nbytes [62]
                0.00    0.00     696/398486      ggml_backend_buft_get_alloc_size [126]
-----------------------------------------------
                0.00    0.00     693/693         ggml_gallocr_reserve_n [101]
[108]    0.0    0.00    0.00     693         ggml_graph_compute_with_ctx [108]
                0.00    0.00     693/461275      ggml_nbytes [62]
                0.00    0.00     693/398486      ggml_backend_buft_get_alloc_size [126]
-----------------------------------------------
                0.00    0.00     680/680         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
[109]    0.0    0.00    0.00     680         ggml_backend_tensor_set [109]
                0.00    0.00     680/461275      ggml_nbytes [62]
-----------------------------------------------
                0.00    0.00     163/163         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
[110]    0.0    0.00    0.00     163         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00     113/6631        ggml_new_tensor_4d [98]
                0.00    0.00     113/49848       ggml_mul_mat [72]
                0.00    0.00      33/376         ggml_new_tensor_2d [106]
                0.00    0.00      33/16840       ggml_mul [84]
                0.00    0.00      17/1110        ggml_new_tensor_1d [102]
                0.00    0.00      16/16          ggml_new_tensor_3d [120]
                0.00    0.00      16/10992       ggml_rope_ext [91]
                0.00    0.00       1/1030        ggml_get_rows [103]
                0.00    0.00     163/184         ggml_tensor_overhead [208]
                0.00    0.00     163/1211        ggml_init [174]
                0.00    0.00     163/211810      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [957]
                0.00    0.00     163/211810      ggml_backend_dev_supports_op [132]
                0.00    0.00     163/182         ggml_backend_buft_alloc_buffer [210]
                0.00    0.00     163/184         ggml_backend_buffer_free [207]
                0.00    0.00     163/1212        ggml_free [173]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[111]    0.0    0.00    0.00     340         ggml_backend_tensor_get [111]
                0.00    0.00     340/461275      ggml_nbytes [62]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[112]    0.0    0.00    0.00     340         ggml_backend_tensor_get_async [112]
                0.00    0.00     340/461275      ggml_nbytes [62]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[113]    0.0    0.00    0.00       1         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00     147/461275      ggml_nbytes [62]
                0.00    0.00     147/117819      ggml_backend_tensor_alloc [70]
                0.00    0.00     148/148         llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) [1019]
                0.00    0.00     147/735         ggml_get_name [178]
                0.00    0.00     147/799         ggml_get_next_tensor [177]
                0.00    0.00     147/177659      ggml_backend_buffer_init_tensor [135]
                0.00    0.00       2/2           llama_mmap::unmap_fragment(unsigned long, unsigned long) [1121]
                0.00    0.00       1/1           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const [1232]
                0.00    0.00       1/7           ggml_get_first_tensor [235]
                0.00    0.00       1/2           ggml_backend_free [256]
-----------------------------------------------
                0.00    0.00     147/147         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
[114]    0.0    0.00    0.00     147         llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [114]
                0.00    0.00     147/119394      ggml_new_tensor [67]
                0.00    0.00     147/61266       ggml_dup_tensor [147]
                0.00    0.00     147/735         ggml_get_name [178]
                0.00    0.00     147/3038        ggml_set_name [167]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[115]    0.0    0.00    0.00       1         ggml_get_max_tensor_size [115]
                0.00    0.00     147/461275      ggml_nbytes [62]
                0.00    0.00     147/799         ggml_get_next_tensor [177]
                0.00    0.00       1/7           ggml_get_first_tensor [235]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[116]    0.0    0.00    0.00       1         llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [116]
                0.00    0.00     147/461275      ggml_nbytes [62]
                0.00    0.00       1/2           std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [1127]
                0.00    0.00       1/68721       ggml_is_numa [146]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[117]    0.0    0.00    0.00       1         ggml_backend_alloc_ctx_tensors_from_buft [117]
                0.00    0.00       1/1           alloc_tensor_range [118]
                0.00    0.00      32/461275      ggml_nbytes [62]
                0.00    0.00      32/799         ggml_get_next_tensor [177]
                0.00    0.00      32/398486      ggml_backend_buft_get_alloc_size [126]
                0.00    0.00       1/1           ggml_get_no_alloc [310]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1089]
                0.00    0.00       1/3           ggml_backend_buft_get_alignment [245]
                0.00    0.00       1/1           ggml_backend_buft_get_max_size [276]
                0.00    0.00       1/7           ggml_get_first_tensor [235]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [117]
[118]    0.0    0.00    0.00       1         alloc_tensor_range [118]
                0.00    0.00      32/32          ggml_tallocr_alloc [119]
                0.00    0.00      32/117819      ggml_backend_tensor_alloc [70]
                0.00    0.00      32/799         ggml_get_next_tensor [177]
                0.00    0.00      32/177659      ggml_backend_buffer_init_tensor [135]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1088]
                0.00    0.00       1/182         ggml_backend_buft_alloc_buffer [210]
                0.00    0.00       1/1           ggml_tallocr_new [313]
-----------------------------------------------
                0.00    0.00      32/32          alloc_tensor_range [118]
[119]    0.0    0.00    0.00      32         ggml_tallocr_alloc [119]
                0.00    0.00      32/461275      ggml_nbytes [62]
                0.00    0.00      32/398486      ggml_backend_buft_get_alloc_size [126]
                0.00    0.00      32/117851      ggml_backend_buffer_get_alloc_size [144]
                0.00    0.00      32/118197      ggml_backend_buffer_get_size [143]
                0.00    0.00      32/353652      ggml_backend_buffer_get_base [127]
-----------------------------------------------
                0.00    0.00      16/16          weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
[120]    0.0    0.00    0.00      16         ggml_new_tensor_3d [120]
                0.00    0.00      16/119394      ggml_new_tensor [67]
-----------------------------------------------
                0.00    0.00      16/16          llama_new_context_with_model [80]
[121]    0.0    0.00    0.00      16         ggml_rope [121]
                0.00    0.00      16/119394      ggml_new_tensor [67]
                0.00    0.00      16/11008       ggml_is_vector [156]
                0.00    0.00      16/61266       ggml_dup_tensor [147]
-----------------------------------------------
[122]    0.0    0.00    0.00       2+11      <cycle 1 as a whole> [122]
                0.00    0.00      12             llama_sampler_free <cycle 1> [226]
                0.00    0.00       1             llama_sampler_chain_free(llama_sampler*) <cycle 1> [1164]
-----------------------------------------------
                0.00    0.00     680/3314228     llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00    5488/3314228     ggml_new_tensor_impl.constprop.2 [94]
                0.00    0.00    5488/3314228     ggml_new_tensor_impl.constprop.3 [95]
                0.00    0.00    5488/3314228     ggml_is_contiguous_1 [99]
                0.00    0.00   10976/3314228     llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
                0.00    0.00   10976/3314228     llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00   14813/3314228     ggml_compute_forward_dup [21]
                0.00    0.00   16320/3314228     ggml_graph_plan [65]
                0.00    0.00   21952/3314228     ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   27440/3314228     ggml_new_tensor_impl.constprop.0 [76]
                0.00    0.00  119394/3314228     ggml_new_tensor [67]
                0.00    0.00  460371/3314228     ggml_nbytes [62]
                0.00    0.00  705767/3314228     ggml_is_contiguous_0 [50]
                0.00    0.00  911411/3314228     ggml_row_size [59]
                0.00    0.00  997664/3314228     ggml_compute_forward_mul_mat [2]
[123]    0.0    0.00    0.00 3314228         ggml_type_size [123]
-----------------------------------------------
                0.00    0.00  141755/1068458     ggml_can_repeat [137]
                0.00    0.00  176120/1068458     ggml_graph_plan [65]
                0.00    0.00  750583/1068458     ggml_compute_forward [1]
[124]    0.0    0.00    0.00 1068458         ggml_is_empty [124]
-----------------------------------------------
                0.00    0.00       1/818795      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00       2/818795      gguf_get_val_f32 [269]
                0.00    0.00       6/818795      gguf_get_arr_data [238]
                0.00    0.00      10/818795      gguf_get_arr_type [228]
                0.00    0.00      12/818795      gguf_get_arr_n [225]
                0.00    0.00      13/818795      gguf_get_val_u32 [224]
                0.00    0.00      30/818795      gguf_get_val_str [221]
                0.00    0.00      36/818795      gguf_get_val_data [220]
                0.00    0.00      36/818795      llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00      58/818795      gguf_find_key [218]
                0.00    0.00     158/818795      gguf_get_kv_type [213]
                0.00    0.00    1613/818795      gguf_get_key [169]
                0.00    0.00  816820/818795      gguf_get_arr_str [40]
[125]    0.0    0.00    0.00  818795         gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00      32/398486      ggml_tallocr_alloc [119]
                0.00    0.00      32/398486      ggml_backend_alloc_ctx_tensors_from_buft [117]
                0.00    0.00     693/398486      ggml_graph_compute_with_ctx [108]
                0.00    0.00     696/398486      ggml_gallocr_allocate_node [107]
                0.00    0.00    2454/398486      ggml_gallocr_reserve_n [101]
                0.00    0.00  117819/398486      ggml_backend_tensor_alloc [70]
                0.00    0.00  276760/398486      ggml_gallocr_alloc_graph [64]
[126]    0.0    0.00    0.00  398486         ggml_backend_buft_get_alloc_size [126]
-----------------------------------------------
                0.00    0.00       1/353652      ggml_tallocr_new [313]
                0.00    0.00      32/353652      ggml_tallocr_alloc [119]
                0.00    0.00     341/353652      llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00  117640/353652      ggml_gallocr_alloc_graph [64]
                0.00    0.00  235638/353652      ggml_backend_tensor_alloc [70]
[127]    0.0    0.00    0.00  353652         ggml_backend_buffer_get_base [127]
                0.00    0.00  353652/353652      ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*) [955]
-----------------------------------------------
                0.00    0.00    1237/314410      ggml_compute_forward_get_rows [164]
                0.00    0.00   33551/314410      ggml_compute_forward_dup [21]
                0.00    0.00  279622/314410      ggml_compute_forward_mul_mat [2]
[128]    0.0    0.00    0.00  314410         ggml_get_type_traits [128]
-----------------------------------------------
                0.00    0.00       1/249657      llama_print_system_info [340]
                0.00    0.00  249656/249657      ggml_fp32_to_fp16_row [42]
[129]    0.0    0.00    0.00  249657         ggml_cpu_has_f16c [129]
-----------------------------------------------
                0.00    0.00      32/247678      llama_new_context_with_model [80]
                0.00    0.00     686/247678      ggml_visit_parents [145]
                0.00    0.00    5488/247678      ggml_cont_4d [100]
                0.00    0.00    5488/247678      ggml_view_1d [96]
                0.00    0.00    5488/247678      ggml_view_2d [97]
                0.00    0.00    5488/247678      ggml_transpose [93]
                0.00    0.00   10976/247678      ggml_cpy [85]
                0.00    0.00   10976/247678      ggml_reshape_3d [68]
                0.00    0.00   10976/247678      ggml_view_3d [87]
                0.00    0.00   10976/247678      ggml_permute [86]
                0.00    0.00   27440/247678      ggml_view_tensor [77]
                0.00    0.00  153664/247678      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
[130]    0.0    0.00    0.00  247678         ggml_format_name [130]
-----------------------------------------------
                0.00    0.00     147/232721      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00    4769/232721      ggml_compute_forward_get_rows [164]
                0.00    0.00    5488/232721      ggml_cont_4d [100]
                0.00    0.00   10976/232721      ggml_reshape_3d [68]
                0.00    0.00   21952/232721      ggml_cpy [85]
                0.00    0.00   49300/232721      ggml_graph_plan [65]
                0.00    0.00  140089/232721      ggml_compute_forward_dup [21]
[131]    0.0    0.00    0.00  232721         ggml_nelements [131]
-----------------------------------------------
                0.00    0.00      16/211810      llama_new_context_with_model [80]
                0.00    0.00     163/211810      weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00   10912/211810      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00   55973/211810      ggml_backend_sched_get_tensor_backend [43]
                0.00    0.00  144746/211810      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[132]    0.0    0.00    0.00  211810         ggml_backend_dev_supports_op [132]
-----------------------------------------------
                0.00    0.00   10912/211631      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00   55973/211631      ggml_backend_sched_get_tensor_backend [43]
                0.00    0.00  144746/211631      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[133]    0.0    0.00    0.00  211631         ggml_backend_supports_op [133]
-----------------------------------------------
                0.00    0.00     343/180105      ggml_new_graph_custom [192]
                0.00    0.00    5488/180105      ggml_new_tensor_impl.constprop.2 [94]
                0.00    0.00    5488/180105      ggml_new_tensor_impl.constprop.3 [95]
                0.00    0.00   21952/180105      ggml_new_tensor_impl.constprop.1 [79]
                0.00    0.00   27440/180105      ggml_new_tensor_impl.constprop.0 [76]
                0.00    0.00  119394/180105      ggml_new_tensor [67]
[134]    0.0    0.00    0.00  180105         ggml_new_object [134]
-----------------------------------------------
                0.00    0.00      32/177659      alloc_tensor_range [118]
                0.00    0.00     147/177659      llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00  177480/177659      ggml_gallocr_alloc_graph [64]
[135]    0.0    0.00    0.00  177659         ggml_backend_buffer_init_tensor [135]
-----------------------------------------------
                0.00    0.00   45026/173887      ggml_compute_forward_add [57]
                0.00    0.00   56236/173887      ggml_compute_forward_rms_norm [30]
                0.00    0.00   72625/173887      ggml_compute_forward_mul [18]
[136]    0.0    0.00    0.00  173887         ggml_are_same_shape [136]
-----------------------------------------------
                0.00    0.00   10976/145575      ggml_add [92]
                0.00    0.00   16840/145575      ggml_mul [84]
                0.00    0.00   45333/145575      ggml_compute_forward_add [57]
                0.00    0.00   72426/145575      ggml_compute_forward_mul [18]
[137]    0.0    0.00    0.00  145575         ggml_can_repeat [137]
                0.00    0.00  141755/1068458     ggml_is_empty [124]
-----------------------------------------------
                0.00    0.00       1/145427      ggml_backend_sched_new [285]
                0.00    0.00     680/145427      llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00  144746/145427      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[138]    0.0    0.00    0.00  145427         ggml_backend_buft_is_host [138]
-----------------------------------------------
                0.00    0.00       1/144747      ggml_backend_sched_new [285]
                0.00    0.00  144746/144747      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[139]    0.0    0.00    0.00  144747         ggml_backend_dev_supports_buft [139]
-----------------------------------------------
                0.00    0.00       1/144747      ggml_backend_sched_new [285]
                0.00    0.00  144746/144747      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[140]    0.0    0.00    0.00  144747         ggml_backend_supports_buft [140]
-----------------------------------------------
                0.00    0.00     344/130443      common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [83]
                0.00    0.00  130099/130443      llm_load_vocab(llama_model_loader&, llama_model&) [13]
[141]    0.0    0.00    0.00  130443         llama_token_to_piece [141]
-----------------------------------------------
                0.00    0.00       1/118535      ggml_backend_buffer_get_alignment [275]
                0.00    0.00       3/118535      ggml_backend_buffer_name [244]
                0.00    0.00     680/118535      ggml_backend_buffer_is_host [183]
                0.00    0.00  117851/118535      ggml_backend_buffer_get_alloc_size [144]
[142]    0.0    0.00    0.00  118535         ggml_backend_buffer_get_type [142]
-----------------------------------------------
                0.00    0.00       1/118197      llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       2/118197      ggml_gallocr_reserve_n [101]
                0.00    0.00       3/118197      llama_new_context_with_model [80]
                0.00    0.00      32/118197      ggml_tallocr_alloc [119]
                0.00    0.00     340/118197      llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00  117819/118197      ggml_backend_tensor_alloc [70]
[143]    0.0    0.00    0.00  118197         ggml_backend_buffer_get_size [143]
-----------------------------------------------
                0.00    0.00      32/117851      ggml_tallocr_alloc [119]
                0.00    0.00  117819/117851      ggml_backend_tensor_alloc [70]
[144]    0.0    0.00    0.00  117851         ggml_backend_buffer_get_alloc_size [144]
                0.00    0.00  117851/118535      ggml_backend_buffer_get_type [142]
-----------------------------------------------
                              222607             ggml_visit_parents [145]
                0.00    0.00   72030/72030       ggml_build_forward_expand [152]
[145]    0.0    0.00    0.00   72030+222607  ggml_visit_parents [145]
                0.00    0.00     686/247678      ggml_format_name [130]
                              222607             ggml_visit_parents [145]
-----------------------------------------------
                0.00    0.00       1/68721       llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [116]
                0.00    0.00     340/68721       ggml_graph_compute [45]
                0.00    0.00    1300/68721       ggml_compute_forward [1]
                0.00    0.00   67080/68721       ggml_compute_forward_mul_mat [2]
[146]    0.0    0.00    0.00   68721         ggml_is_numa [146]
-----------------------------------------------
                0.00    0.00      16/61266       ggml_rope [121]
                0.00    0.00     147/61266       llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [114]
                0.00    0.00    5488/61266       ggml_soft_max_ext [69]
                0.00    0.00    5488/61266       ggml_unary [90]
                0.00    0.00   10976/61266       ggml_add [92]
                0.00    0.00   10992/61266       ggml_rope_ext [91]
                0.00    0.00   11319/61266       ggml_rms_norm [89]
                0.00    0.00   16840/61266       ggml_mul [84]
[147]    0.0    0.00    0.00   61266         ggml_dup_tensor [147]
-----------------------------------------------
                0.00    0.00   59840/59840       ggml_gallocr_alloc_graph [64]
[148]    0.0    0.00    0.00   59840         ggml_backend_view_init [148]
-----------------------------------------------
                0.00    0.00   49848/49848       ggml_mul_mat [72]
[149]    0.0    0.00    0.00   49848         ggml_is_transposed [149]
-----------------------------------------------
                0.00    0.00   46703/46703       ggml_compute_forward_rope_f32 [28]
[150]    0.0    0.00    0.00   46703         ggml_rope_cache_init [150]
-----------------------------------------------
                0.00    0.00   44346/44346       ggml_compute_forward_rope_f32 [28]
[151]    0.0    0.00    0.00   44346         ggml_rope_yarn_corr_dims [151]
-----------------------------------------------
                0.00    0.00     343/33271       llm_build_context::build_llama() [61]
                0.00    0.00    5488/33271       llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
                0.00    0.00    5488/33271       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00   21952/33271       llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
[152]    0.0    0.00    0.00   33271         ggml_build_forward_expand [152]
                0.00    0.00   72030/72030       ggml_visit_parents [145]
-----------------------------------------------
                0.00    0.00    5440/29514       ggml_graph_plan [65]
                0.00    0.00   24074/29514       ggml_compute_forward_unary [29]
[153]    0.0    0.00    0.00   29514         ggml_get_unary_op [153]
-----------------------------------------------
                0.00    0.00     680/22632       llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00   10976/22632       llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
                0.00    0.00   10976/22632       llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
[154]    0.0    0.00    0.00   22632         ggml_element_size [154]
-----------------------------------------------
                0.00    0.00       1/21761       llama_new_context_with_model [80]
                0.00    0.00   21760/21761       ggml_graph_plan [65]
[155]    0.0    0.00    0.00   21761         ggml_is_quantized [155]
-----------------------------------------------
                0.00    0.00      16/11008       ggml_rope [121]
                0.00    0.00   10992/11008       ggml_rope_ext [91]
[156]    0.0    0.00    0.00   11008         ggml_is_vector [156]
-----------------------------------------------
                0.00    0.00       1/10913       llama_new_context_with_model [80]
                0.00    0.00   10912/10913       std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
[157]    0.0    0.00    0.00   10913         ggml_backend_get_device [157]
-----------------------------------------------
                0.00    0.00   10912/10912       std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
[158]    0.0    0.00    0.00   10912         ggml_backend_sched_set_tensor_backend [158]
-----------------------------------------------
                0.00    0.00   10878/10878       gguf_find_tensor [214]
[159]    0.0    0.00    0.00   10878         gguf_get_tensor_name [159]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
[160]    0.0    0.00    0.00    5488         ggml_cont_2d [160]
-----------------------------------------------
                0.00    0.00    5488/5488        ggml_soft_max_ext [69]
[161]    0.0    0.00    0.00    5488         ggml_is_matrix [161]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
[162]    0.0    0.00    0.00    5488         ggml_mul_mat_set_prec [162]
-----------------------------------------------
                0.00    0.00    5488/5488        llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
[163]    0.0    0.00    0.00    5488         ggml_silu [163]
-----------------------------------------------
                0.00    0.00    4709/4709        ggml_compute_forward [1]
[164]    0.0    0.00    0.00    4709         ggml_compute_forward_get_rows [164]
                0.00    0.00    4769/232721      ggml_nelements [131]
                0.00    0.00    1237/314410      ggml_get_type_traits [128]
                0.00    0.00     248/248         dequantize_row_q6_K [206]
-----------------------------------------------
                0.00    0.00     683/4123        common_sampler_accept(common_sampler*, int, bool) [987]
                0.00    0.00    3440/4123        llama_sampler_chain_accept(llama_sampler*, int) [989]
[165]    0.0    0.00    0.00    4123         llama_sampler_accept [165]
-----------------------------------------------
                0.00    0.00     678/4068        common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
                0.00    0.00    3390/4068        llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[166]    0.0    0.00    0.00    4068         llama_sampler_apply [166]
-----------------------------------------------
                0.00    0.00     147/3038        gguf_init_from_file [38]
                0.00    0.00     147/3038        llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [114]
                0.00    0.00    2744/3038        std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
[167]    0.0    0.00    0.00    3038         ggml_set_name [167]
-----------------------------------------------
                0.00    0.00       1/2053        llama_perf_context_reset [337]
                0.00    0.00       1/2053        llama_perf_context_print [336]
                0.00    0.00       2/2053        ggml_cpu_init [193]
                0.00    0.00       2/2053        llama_load_model_from_file [12]
                0.00    0.00     340/2053        llama_decode_internal(llama_context&, llama_batch) [20]
                0.00    0.00     341/2053        llama_synchronize [203]
                0.00    0.00     678/2053        llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.00     688/2053        llama_sampler_chain_accept(llama_sampler*, int) [989]
[168]    0.0    0.00    0.00    2053         ggml_time_us [168]
-----------------------------------------------
                0.00    0.00      30/1613        llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00      35/1613        llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00    1548/1613        gguf_find_key [218]
[169]    0.0    0.00    0.00    1613         gguf_get_key [169]
                0.00    0.00    1613/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00       1/1554        main [8]
                0.00    0.00       1/1554        ggml_backend_cpu_init [278]
                0.00    0.00       1/1554        llama_print_system_info [340]
                0.00    0.00     340/1554        ggml_graph_compute [45]
                0.00    0.00    1211/1554        ggml_init [174]
[170]    0.0    0.00    0.00    1554         ggml_critical_section_end [170]
-----------------------------------------------
                0.00    0.00       1/1554        ggml_quantize_free [312]
                0.00    0.00     342/1554        ggml_cpu_init [193]
                0.00    0.00    1211/1554        ggml_init [174]
[171]    0.0    0.00    0.00    1554         ggml_critical_section_start [171]
-----------------------------------------------
                0.00    0.00     343/1372        std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [104]
                0.00    0.00    1029/1372        llm_build_context::build_llama() [61]
[172]    0.0    0.00    0.00    1372         ggml_set_input [172]
-----------------------------------------------
                0.00    0.00       1/1212        main [8]
                0.00    0.00       1/1212        ggml_backend_sched_free [283]
                0.00    0.00       1/1212        llama_free [326]
                0.00    0.00       1/1212        llama_load_model_from_file [12]
                0.00    0.00       1/1212        llama_model::~llama_model() [1183]
                0.00    0.00       3/1212        ggml_backend_sched_reserve [88]
                0.00    0.00      16/1212        llama_new_context_with_model [80]
                0.00    0.00     163/1212        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00     340/1212        ggml_backend_sched_alloc_graph [51]
                0.00    0.00     342/1212        ggml_cpu_init [193]
                0.00    0.00     343/1212        llama_build_graph(llama_context&, llama_ubatch const&, bool) [60]
[173]    0.0    0.00    0.00    1212         ggml_free [173]
                0.00    0.00     525/532         ggml_aligned_free [186]
-----------------------------------------------
                0.00    0.00       1/1211        gguf_init_from_file [38]
                0.00    0.00       1/1211        llama_backend_init [324]
                0.00    0.00       1/1211        llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
                0.00    0.00       3/1211        ggml_backend_sched_reserve [88]
                0.00    0.00      17/1211        llama_new_context_with_model [80]
                0.00    0.00     163/1211        weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00     340/1211        ggml_backend_sched_alloc_graph [51]
                0.00    0.00     342/1211        ggml_cpu_init [193]
                0.00    0.00     343/1211        llama_build_graph(llama_context&, llama_ubatch const&, bool) [60]
[174]    0.0    0.00    0.00    1211         ggml_init [174]
                0.00    0.00    1211/1554        ggml_critical_section_start [171]
                0.00    0.00    1211/1554        ggml_critical_section_end [170]
                0.00    0.00     525/532         ggml_aligned_malloc [187]
                0.00    0.00       1/3           ggml_time_init [251]
-----------------------------------------------
                0.00    0.00       1/1022        ggml_backend_sched_new [285]
                0.00    0.00       1/1022        llama_new_context_with_model [80]
                0.00    0.00     340/1022        ggml_backend_cpu_set_n_threads [197]
                0.00    0.00     340/1022        ggml_backend_cpu_set_threadpool [198]
                0.00    0.00     340/1022        ggml_backend_cpu_set_abort_callback [196]
[175]    0.0    0.00    0.00    1022         ggml_backend_is_cpu [175]
-----------------------------------------------
                0.00    0.00       1/1022        ggml_backend_sched_new [285]
                0.00    0.00       1/1022        llama_new_context_with_model [80]
                0.00    0.00     340/1022        ggml_backend_cpu_set_n_threads [197]
                0.00    0.00     340/1022        ggml_backend_cpu_set_threadpool [198]
                0.00    0.00     340/1022        ggml_backend_cpu_set_abort_callback [196]
[176]    0.0    0.00    0.00    1022         ggml_guid_matches [176]
-----------------------------------------------
                0.00    0.00      32/799         alloc_tensor_range [118]
                0.00    0.00      32/799         ggml_backend_alloc_ctx_tensors_from_buft [117]
                0.00    0.00     147/799         ggml_get_max_tensor_size [115]
                0.00    0.00     147/799         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00     147/799         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00     294/799         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[177]    0.0    0.00    0.00     799         ggml_get_next_tensor [177]
-----------------------------------------------
                0.00    0.00     147/735         llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [114]
                0.00    0.00     147/735         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00     147/735         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00     294/735         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[178]    0.0    0.00    0.00     735         ggml_get_name [178]
-----------------------------------------------
                0.00    0.00       3/690         ggml_gallocr_reserve_n [101]
                0.00    0.00     343/690         ggml_new_graph_custom [192]
                0.00    0.00     344/690         ggml_backend_sched_reset [181]
[179]    0.0    0.00    0.00     690         ggml_hash_set_reset [179]
-----------------------------------------------
                0.00    0.00       2/690         ggml_hash_set_new [266]
                0.00    0.00       2/690         ggml_graph_overhead_custom [265]
                0.00    0.00     686/690         ggml_new_graph_custom [192]
[180]    0.0    0.00    0.00     690         ggml_hash_size [180]
-----------------------------------------------
                0.00    0.00       1/684         ggml_backend_sched_new [285]
                0.00    0.00       3/684         ggml_backend_sched_reserve [88]
                0.00    0.00     680/684         llama_decode_internal(llama_context&, llama_batch) [20]
[181]    0.0    0.00    0.00     684         ggml_backend_sched_reset [181]
                0.00    0.00     344/690         ggml_hash_set_reset [179]
-----------------------------------------------
                0.00    0.00       1/684         common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1133]
                0.00    0.00     339/684         common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
                0.00    0.00     344/684         common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [83]
[182]    0.0    0.00    0.00     684         llama_get_model [182]
-----------------------------------------------
                0.00    0.00     680/680         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
[183]    0.0    0.00    0.00     680         ggml_backend_buffer_is_host [183]
                0.00    0.00     680/118535      ggml_backend_buffer_get_type [142]
-----------------------------------------------
                0.00    0.00     680/680         llama_decode_internal(llama_context&, llama_batch) [20]
[184]    0.0    0.00    0.00     680         ggml_graph_node [184]
-----------------------------------------------
                0.00    0.00     680/680         main [8]
[185]    0.0    0.00    0.00     680         llama_token_is_eog [185]
-----------------------------------------------
                0.00    0.00       1/532         main [8]
                0.00    0.00       1/532         ggml_graph_compute [45]
                0.00    0.00       2/532         ggml_threadpool_free [249]
                0.00    0.00       3/532         ggml_backend_buffer_free [207]
                0.00    0.00     525/532         ggml_free [173]
[186]    0.0    0.00    0.00     532         ggml_aligned_free [186]
-----------------------------------------------
                0.00    0.00       3/532         ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1088]
                0.00    0.00       4/532         ggml_threadpool_new_impl [268]
                0.00    0.00     525/532         ggml_init [174]
[187]    0.0    0.00    0.00     532         ggml_aligned_malloc [187]
-----------------------------------------------
                0.00    0.00       1/343         llama_kv_cache_clear [328]
                0.00    0.00       1/343         llama_new_context_with_model [80]
                0.00    0.00     341/343         llama_output_reserve(llama_context&, unsigned long) [997]
[188]    0.0    0.00    0.00     343         ggml_backend_buffer_clear [188]
-----------------------------------------------
                0.00    0.00       3/343         ggml_backend_sched_reserve [88]
                0.00    0.00     340/343         llama_synchronize [203]
[189]    0.0    0.00    0.00     343         ggml_backend_sched_synchronize [189]
                0.00    0.00     343/343         ggml_backend_synchronize [190]
-----------------------------------------------
                0.00    0.00     343/343         ggml_backend_sched_synchronize [189]
[190]    0.0    0.00    0.00     343         ggml_backend_synchronize [190]
-----------------------------------------------
                0.00    0.00     343/343         ggml_backend_sched_get_tensor_backend [43]
[191]    0.0    0.00    0.00     343         ggml_graph_view [191]
-----------------------------------------------
                0.00    0.00     343/343         llm_build_context::build_llama() [61]
[192]    0.0    0.00    0.00     343         ggml_new_graph_custom [192]
                0.00    0.00     686/690         ggml_hash_size [180]
                0.00    0.00     343/180105      ggml_new_object [134]
                0.00    0.00     343/690         ggml_hash_set_reset [179]
-----------------------------------------------
                0.00    0.00       1/342         ggml_backend_cpu_init [278]
                0.00    0.00       1/342         llama_print_system_info [340]
                0.00    0.00     340/342         ggml_graph_compute [45]
[193]    0.0    0.00    0.00     342         ggml_cpu_init [193]
                0.00    0.00     342/1212        ggml_free [173]
                0.00    0.00     342/1211        ggml_init [174]
                0.00    0.00     342/1554        ggml_critical_section_start [171]
                0.00    0.00       2/2053        ggml_time_us [168]
-----------------------------------------------
                0.00    0.00       2/341         common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
                0.00    0.00     339/341         common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
[194]    0.0    0.00    0.00     341         llama_n_vocab [194]
-----------------------------------------------
                0.00    0.00     340/340         ggml_gallocr_alloc_graph [64]
[195]    0.0    0.00    0.00     340         ggml_backend_buffer_reset [195]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[196]    0.0    0.00    0.00     340         ggml_backend_cpu_set_abort_callback [196]
                0.00    0.00     340/1022        ggml_guid_matches [176]
                0.00    0.00     340/1022        ggml_backend_is_cpu [175]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[197]    0.0    0.00    0.00     340         ggml_backend_cpu_set_n_threads [197]
                0.00    0.00     340/1022        ggml_guid_matches [176]
                0.00    0.00     340/1022        ggml_backend_is_cpu [175]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[198]    0.0    0.00    0.00     340         ggml_backend_cpu_set_threadpool [198]
                0.00    0.00     340/1022        ggml_guid_matches [176]
                0.00    0.00     340/1022        ggml_backend_is_cpu [175]
-----------------------------------------------
                0.00    0.00     340/340         ggml_backend_sched_graph_compute_async [36]
[199]    0.0    0.00    0.00     340         ggml_backend_graph_compute_async [199]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[200]    0.0    0.00    0.00     340         ggml_backend_sched_set_eval_callback [200]
-----------------------------------------------
                0.00    0.00       1/340         common_init_from_params(common_params&) [11]
                0.00    0.00     339/340         main [8]
[201]    0.0    0.00    0.00     340         llama_batch_get_one [201]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[202]    0.0    0.00    0.00     340         llama_kv_cache_update [202]
-----------------------------------------------
                0.00    0.00       1/340         common_init_from_params(common_params&) [11]
                0.00    0.00     339/340         llama_get_logits_ith [204]
[203]    0.0    0.00    0.00     340         llama_synchronize [203]
                0.00    0.00     341/2053        ggml_time_us [168]
                0.00    0.00     340/343         ggml_backend_sched_synchronize [189]
-----------------------------------------------
                0.00    0.00     339/339         common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
[204]    0.0    0.00    0.00     339         llama_get_logits_ith [204]
                0.00    0.00     339/340         llama_synchronize [203]
-----------------------------------------------
                0.00    0.00     252/252         ggml_compute_forward_mul_mat [2]
[205]    0.0    0.00    0.00     252         quantize_row_q8_K_ref [205]
-----------------------------------------------
                0.00    0.00     248/248         ggml_compute_forward_get_rows [164]
[206]    0.0    0.00    0.00     248         dequantize_row_q6_K [206]
-----------------------------------------------
                0.00    0.00       1/184         ggml_gallocr_free [307]
                0.00    0.00       1/184         ggml_gallocr_reserve_n [101]
                0.00    0.00       1/184         llama_model::~llama_model() [1183]
                0.00    0.00       2/184         llama_free [326]
                0.00    0.00      16/184         llama_new_context_with_model [80]
                0.00    0.00     163/184         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
[207]    0.0    0.00    0.00     184         ggml_backend_buffer_free [207]
                0.00    0.00       3/532         ggml_aligned_free [186]
                0.00    0.00       3/3           ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*) [1085]
-----------------------------------------------
                0.00    0.00       1/184         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       2/184         gguf_init_from_file [38]
                0.00    0.00      18/184         llama_new_context_with_model [80]
                0.00    0.00     163/184         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
[208]    0.0    0.00    0.00     184         ggml_tensor_overhead [208]
-----------------------------------------------
                0.00    0.00       1/183         ggml_backend_cpu_buffer_from_ptr [277]
                0.00    0.00       3/183         ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1088]
                0.00    0.00     179/183         ggml_backend_buft_alloc_buffer [210]
[209]    0.0    0.00    0.00     183         ggml_backend_buffer_init [209]
-----------------------------------------------
                0.00    0.00       1/182         alloc_tensor_range [118]
                0.00    0.00       1/182         ggml_gallocr_reserve_n [101]
                0.00    0.00       1/182         llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00      16/182         llama_new_context_with_model [80]
                0.00    0.00     163/182         weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
[210]    0.0    0.00    0.00     182         ggml_backend_buft_alloc_buffer [210]
                0.00    0.00     179/183         ggml_backend_buffer_init [209]
-----------------------------------------------
                0.00    0.00       1/164         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00     163/164         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
[211]    0.0    0.00    0.00     164         ggml_backend_buft_get_device [211]
-----------------------------------------------
                0.00    0.00       1/164         llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00     163/164         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
[212]    0.0    0.00    0.00     164         ggml_backend_dev_host_buffer_type [212]
-----------------------------------------------
                0.00    0.00       2/158         bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1076]
                0.00    0.00       9/158         bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
                0.00    0.00      12/158         llama_state_seq_get_size [232]
                0.00    0.00      35/158         llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00      35/158         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00      65/158         gguf_kv_to_str(gguf_context const*, int) [52]
[213]    0.0    0.00    0.00     158         gguf_get_kv_type [213]
                0.00    0.00     158/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[214]    0.0    0.00    0.00     147         gguf_find_tensor [214]
                0.00    0.00   10878/10878       gguf_get_tensor_name [159]
                0.00    0.00     147/147         gguf_get_n_tensors [216]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[215]    0.0    0.00    0.00     147         gguf_get_data_offset [215]
-----------------------------------------------
                0.00    0.00     147/147         gguf_find_tensor [214]
[216]    0.0    0.00    0.00     147         gguf_get_n_tensors [216]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[217]    0.0    0.00    0.00     147         gguf_get_tensor_offset [217]
-----------------------------------------------
                0.00    0.00       1/58          gguf_init_from_file [38]
                0.00    0.00       2/58          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00       4/58          llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00       5/58          bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1076]
                0.00    0.00       5/58          bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1075]
                0.00    0.00      13/58          llama_state_seq_get_size [232]
                0.00    0.00      28/58          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
[218]    0.0    0.00    0.00      58         gguf_find_key [218]
                0.00    0.00    1548/1613        gguf_get_key [169]
                0.00    0.00      58/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00      40/40          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[219]    0.0    0.00    0.00      40         gguf_type_name [219]
-----------------------------------------------
                0.00    0.00      36/36          gguf_kv_to_str(gguf_context const*, int) [52]
[220]    0.0    0.00    0.00      36         gguf_get_val_data [220]
                0.00    0.00      36/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00       6/30          llama_state_seq_get_size [232]
                0.00    0.00      24/30          gguf_kv_to_str(gguf_context const*, int) [52]
[221]    0.0    0.00    0.00      30         gguf_get_val_str [221]
                0.00    0.00      30/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00       2/19          llama_new_context_with_model [80]
                0.00    0.00       2/19          llama_load_model_from_file [12]
                0.00    0.00       4/19          ggml_backend_dev_by_type [247]
                0.00    0.00       4/19          llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       7/19          ggml_backend_dev_get [233]
[222]    0.0    0.00    0.00      19         ggml_backend_dev_count [222]
-----------------------------------------------
                0.00    0.00      16/16          llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
[223]    0.0    0.00    0.00      16         ggml_get_tensor [223]
-----------------------------------------------
                0.00    0.00       1/13          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00       3/13          llama_state_seq_get_size [232]
                0.00    0.00       9/13          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
[224]    0.0    0.00    0.00      13         gguf_get_val_u32 [224]
                0.00    0.00      13/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00       2/12          llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00       5/12          gguf_kv_to_str(gguf_context const*, int) [52]
                0.00    0.00       5/12          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[225]    0.0    0.00    0.00      12         gguf_get_arr_n [225]
                0.00    0.00      12/818795      gguf_get_n_kv [125]
-----------------------------------------------
                                  10             llama_sampler_chain_free(llama_sampler*) <cycle 1> [1164]
                0.00    0.00       2/2           common_sampler_free(common_sampler*) [1137]
[226]    0.0    0.00    0.00      12         llama_sampler_free <cycle 1> [226]
                0.00    0.00       1/1           llama_sampler_dist_free(llama_sampler*) [1162]
                0.00    0.00       1/1           llama_sampler_temp_ext_free(llama_sampler*) [1174]
                0.00    0.00       1/1           llama_sampler_xtc_free(llama_sampler*) [1160]
                0.00    0.00       1/1           llama_sampler_min_p_free(llama_sampler*) [1165]
                0.00    0.00       1/1           llama_sampler_top_p_free(llama_sampler*) [1169]
                0.00    0.00       1/1           llama_sampler_typical_free(llama_sampler*) [1172]
                0.00    0.00       1/1           llama_sampler_top_k_free(llama_sampler*) [1167]
                0.00    0.00       1/1           llama_sampler_dry_free(llama_sampler*) [1158]
                0.00    0.00       1/1           llama_sampler_penalties_free(llama_sampler*) [1176]
                0.00    0.00       1/1           llama_sampler_logit_bias_free(llama_sampler*) [1178]
                0.00    0.00       1/1           llama_sampler_grammar_free(llama_sampler*) [1171]
                                   1             llama_sampler_chain_free(llama_sampler*) <cycle 1> [1164]
-----------------------------------------------
                0.00    0.00      11/11          common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[227]    0.0    0.00    0.00      11         llama_sampler_chain_n [227]
-----------------------------------------------
                0.00    0.00       5/10          gguf_kv_to_str(gguf_context const*, int) [52]
                0.00    0.00       5/10          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[228]    0.0    0.00    0.00      10         gguf_get_arr_type [228]
                0.00    0.00      10/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00      10/10          common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[229]    0.0    0.00    0.00      10         llama_sampler_chain_add [229]
-----------------------------------------------
                0.00    0.00      10/10          common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[230]    0.0    0.00    0.00      10         llama_sampler_chain_get [230]
-----------------------------------------------
                0.00    0.00      10/10          common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[231]    0.0    0.00    0.00      10         llama_sampler_name [231]
-----------------------------------------------
                0.00    0.00       1/10          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00       4/10          llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00       5/10          llm_load_hparams(llama_model_loader&, llama_model&) [58]
[232]    0.0    0.00    0.00      10         llama_state_seq_get_size [232]
                0.00    0.00      13/58          gguf_find_key [218]
                0.00    0.00      12/158         gguf_get_kv_type [213]
                0.00    0.00      10/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1033]
                0.00    0.00       6/30          gguf_get_val_str [221]
                0.00    0.00       3/522         format(char const*, ...) [977]
                0.00    0.00       3/13          gguf_get_val_u32 [224]
-----------------------------------------------
                0.00    0.00       1/7           llama_new_context_with_model [80]
                0.00    0.00       1/7           llama_load_model_from_file [12]
                0.00    0.00       2/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       3/7           ggml_backend_dev_by_type [247]
[233]    0.0    0.00    0.00       7         ggml_backend_dev_get [233]
                0.00    0.00       7/19          ggml_backend_dev_count [222]
                0.00    0.00       7/9           get_reg() [1057]
-----------------------------------------------
                0.00    0.00       1/7           llama_new_context_with_model [80]
                0.00    0.00       1/7           llama_load_model_from_file [12]
                0.00    0.00       2/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       3/7           ggml_backend_dev_by_type [247]
[234]    0.0    0.00    0.00       7         ggml_backend_dev_type [234]
-----------------------------------------------
                0.00    0.00       1/7           ggml_get_max_tensor_size [115]
                0.00    0.00       1/7           ggml_backend_alloc_ctx_tensors_from_buft [117]
                0.00    0.00       1/7           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
                0.00    0.00       1/7           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00       3/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[235]    0.0    0.00    0.00       7         ggml_get_first_tensor [235]
-----------------------------------------------
                0.00    0.00       2/6           ggml_backend_reg_get [259]
                0.00    0.00       4/6           ggml_backend_reg_by_name [257]
[236]    0.0    0.00    0.00       6         ggml_backend_reg_count [236]
                0.00    0.00       2/2           ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*) [1120]
                0.00    0.00       2/2           ggml_backend_reg_dev_count [258]
                0.00    0.00       1/4           ggml_backend_cpu_reg [241]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1079]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [242]
                0.00    0.00       1/1           void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&) [1217]
                0.00    0.00       1/1           void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&) [1216]
-----------------------------------------------
                0.00    0.00       2/6           llama_new_context_with_model [80]
                0.00    0.00       4/6           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[237]    0.0    0.00    0.00       6         ggml_type_name [237]
-----------------------------------------------
                0.00    0.00       1/6           llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00       5/6           gguf_kv_to_str(gguf_context const*, int) [52]
[238]    0.0    0.00    0.00       6         gguf_get_arr_data [238]
                0.00    0.00       6/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00       1/4           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       3/4           llama_new_context_with_model [80]
[239]    0.0    0.00    0.00       4         ggml_backend_buft_name [239]
-----------------------------------------------
                0.00    0.00       1/4           llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00       1/4           llama_new_context_with_model [80]
                0.00    0.00       2/4           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[240]    0.0    0.00    0.00       4         ggml_backend_cpu_buffer_type [240]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1079]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [242]
                0.00    0.00       1/4           ggml_backend_cpu_reg [241]
-----------------------------------------------
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [240]
                0.00    0.00       1/4           ggml_backend_cpu_init [278]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_from_ptr [277]
                0.00    0.00       1/4           ggml_backend_reg_count [236]
[241]    0.0    0.00    0.00       4         ggml_backend_cpu_reg [241]
-----------------------------------------------
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [240]
                0.00    0.00       1/4           ggml_backend_cpu_init [278]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_from_ptr [277]
                0.00    0.00       1/4           ggml_backend_reg_count [236]
[242]    0.0    0.00    0.00       4         ggml_backend_reg_dev_get [242]
-----------------------------------------------
                0.00    0.00       1/4           llama_new_context_with_model [80]
                0.00    0.00       1/4           common_init_from_params(common_params&) [11]
                0.00    0.00       2/4           main [8]
[243]    0.0    0.00    0.00       4         llama_model_has_encoder [243]
-----------------------------------------------
                0.00    0.00       1/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       2/3           llama_new_context_with_model [80]
[244]    0.0    0.00    0.00       3         ggml_backend_buffer_name [244]
                0.00    0.00       3/118535      ggml_backend_buffer_get_type [142]
-----------------------------------------------
                0.00    0.00       1/3           ggml_tallocr_new [313]
                0.00    0.00       1/3           ggml_gallocr_new_n [309]
                0.00    0.00       1/3           ggml_backend_alloc_ctx_tensors_from_buft [117]
[245]    0.0    0.00    0.00       3         ggml_backend_buft_get_alignment [245]
-----------------------------------------------
                0.00    0.00       1/3           llama_new_context_with_model [80]
                0.00    0.00       2/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[246]    0.0    0.00    0.00       3         ggml_backend_dev_buffer_type [246]
-----------------------------------------------
                0.00    0.00       1/3           llama_supports_gpu_offload [356]
                0.00    0.00       2/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[247]    0.0    0.00    0.00       3         ggml_backend_dev_by_type [247]
                0.00    0.00       4/19          ggml_backend_dev_count [222]
                0.00    0.00       3/7           ggml_backend_dev_get [233]
                0.00    0.00       3/7           ggml_backend_cpu_device_get_type(ggml_backend_device*) [1067]
                0.00    0.00       3/7           ggml_backend_dev_type [234]
-----------------------------------------------
                0.00    0.00       1/3           ggml_gallocr_free [307]
                0.00    0.00       1/3           ggml_gallocr_reserve_n [101]
                0.00    0.00       1/3           ggml_backend_sched_free [283]
[248]    0.0    0.00    0.00       3         ggml_hash_set_free [248]
-----------------------------------------------
                0.00    0.00       1/3           ggml_graph_compute [45]
                0.00    0.00       2/3           main [8]
[249]    0.0    0.00    0.00       3         ggml_threadpool_free [249]
                0.00    0.00       2/532         ggml_aligned_free [186]
-----------------------------------------------
                0.00    0.00       1/3           ggml_threadpool_params_default [315]
                0.00    0.00       2/3           ggml_threadpool_params_from_cpu_params(cpu_params const&) [1113]
[250]    0.0    0.00    0.00       3         ggml_threadpool_params_init [250]
-----------------------------------------------
                0.00    0.00       1/3           ggml_init [174]
                0.00    0.00       1/3           llama_backend_init [324]
                0.00    0.00       1/3           llama_load_model_from_file [12]
[251]    0.0    0.00    0.00       3         ggml_time_init [251]
-----------------------------------------------
                0.00    0.00       3/3           ggml_quantize_free [312]
[252]    0.0    0.00    0.00       3         iq2xs_free_impl [252]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_buffer_set_usage [254]
[253]    0.0    0.00    0.00       2         ggml_backend_buffer_is_multi_buffer [253]
-----------------------------------------------
                0.00    0.00       1/2           ggml_gallocr_reserve_n [101]
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[254]    0.0    0.00    0.00       2         ggml_backend_buffer_set_usage [254]
                0.00    0.00       2/2           ggml_backend_buffer_is_multi_buffer [253]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[255]    0.0    0.00    0.00       2         ggml_backend_dev_backend_reg [255]
-----------------------------------------------
                0.00    0.00       1/2           llama_free [326]
                0.00    0.00       1/2           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
[256]    0.0    0.00    0.00       2         ggml_backend_free [256]
-----------------------------------------------
                0.00    0.00       2/2           llama_supports_rpc [272]
[257]    0.0    0.00    0.00       2         ggml_backend_reg_by_name [257]
                0.00    0.00       4/6           ggml_backend_reg_count [236]
                0.00    0.00       2/2           ggml_backend_reg_get [259]
                0.00    0.00       2/2           ggml_backend_cpu_reg_get_name(ggml_backend_reg*) [1117]
                0.00    0.00       2/2           ggml_backend_reg_name [261]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_count [236]
[258]    0.0    0.00    0.00       2         ggml_backend_reg_dev_count [258]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_by_name [257]
[259]    0.0    0.00    0.00       2         ggml_backend_reg_get [259]
                0.00    0.00       2/6           ggml_backend_reg_count [236]
                0.00    0.00       2/9           get_reg() [1057]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[260]    0.0    0.00    0.00       2         ggml_backend_reg_get_proc_address [260]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_by_name [257]
[261]    0.0    0.00    0.00       2         ggml_backend_reg_name [261]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[262]    0.0    0.00    0.00       2         ggml_backend_sched_get_n_splits [262]
-----------------------------------------------
                0.00    0.00       1/2           gguf_init_from_file [38]
                0.00    0.00       1/2           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[263]    0.0    0.00    0.00       2         ggml_fopen [263]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[264]    0.0    0.00    0.00       2         ggml_graph_n_nodes [264]
-----------------------------------------------
                0.00    0.00       1/2           ggml_backend_sched_new [285]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[265]    0.0    0.00    0.00       2         ggml_graph_overhead_custom [265]
                0.00    0.00       2/690         ggml_hash_size [180]
-----------------------------------------------
                0.00    0.00       1/2           ggml_gallocr_reserve_n [101]
                0.00    0.00       1/2           ggml_backend_sched_new [285]
[266]    0.0    0.00    0.00       2         ggml_hash_set_new [266]
                0.00    0.00       2/690         ggml_hash_size [180]
-----------------------------------------------
                0.00    0.00       2/2           gguf_init_from_file [38]
[267]    0.0    0.00    0.00       2         ggml_set_no_alloc [267]
-----------------------------------------------
                0.00    0.00       1/2           main [8]
                0.00    0.00       1/2           ggml_graph_compute [45]
[268]    0.0    0.00    0.00       2         ggml_threadpool_new_impl [268]
                0.00    0.00       4/532         ggml_aligned_malloc [187]
-----------------------------------------------
                0.00    0.00       2/2           bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1076]
[269]    0.0    0.00    0.00       2         gguf_get_val_f32 [269]
                0.00    0.00       2/818795      gguf_get_n_kv [125]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[270]    0.0    0.00    0.00       2         llama_model_is_recurrent [270]
-----------------------------------------------
                0.00    0.00       1/2           main [8]
                0.00    0.00       1/2           llama_sampler_init_dry [346]
[271]    0.0    0.00    0.00       2         llama_n_ctx_train [271]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/2           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[272]    0.0    0.00    0.00       2         llama_supports_rpc [272]
                0.00    0.00       2/2           ggml_backend_reg_by_name [257]
-----------------------------------------------
                0.00    0.00       1/2           llama_new_context_with_model [80]
                0.00    0.00       1/2           common_init_from_params(common_params&) [11]
[273]    0.0    0.00    0.00       2         llama_token_bos [273]
-----------------------------------------------
                0.00    0.00       1/2           common_init_from_params(common_params&) [11]
                0.00    0.00       1/2           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[274]    0.0    0.00    0.00       2         llama_token_eos [274]
-----------------------------------------------
                0.00    0.00       1/1           ggml_tallocr_new [313]
[275]    0.0    0.00    0.00       1         ggml_backend_buffer_get_alignment [275]
                0.00    0.00       1/118535      ggml_backend_buffer_get_type [142]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [117]
[276]    0.0    0.00    0.00       1         ggml_backend_buft_get_max_size [276]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[277]    0.0    0.00    0.00       1         ggml_backend_cpu_buffer_from_ptr [277]
                0.00    0.00       1/183         ggml_backend_buffer_init [209]
                0.00    0.00       1/4           ggml_backend_cpu_reg [241]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1079]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [242]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[278]    0.0    0.00    0.00       1         ggml_backend_cpu_init [278]
                0.00    0.00       1/1554        ggml_critical_section_end [170]
                0.00    0.00       1/342         ggml_cpu_init [193]
                0.00    0.00       1/4           ggml_backend_cpu_reg [241]
                0.00    0.00       1/4           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1079]
                0.00    0.00       1/4           ggml_backend_reg_dev_get [242]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[279]    0.0    0.00    0.00       1         ggml_backend_dev_buffer_from_host_ptr [279]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[280]    0.0    0.00    0.00       1         ggml_backend_dev_get_props [280]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_sched_free [283]
[281]    0.0    0.00    0.00       1         ggml_backend_event_free [281]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[282]    0.0    0.00    0.00       1         ggml_backend_get_default_buffer_type [282]
-----------------------------------------------
                0.00    0.00       1/1           llama_free [326]
[283]    0.0    0.00    0.00       1         ggml_backend_sched_free [283]
                0.00    0.00       1/1           ggml_backend_event_free [281]
                0.00    0.00       1/1           ggml_gallocr_free [307]
                0.00    0.00       1/1212        ggml_free [173]
                0.00    0.00       1/3           ggml_hash_set_free [248]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[284]    0.0    0.00    0.00       1         ggml_backend_sched_get_buffer_size [284]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[285]    0.0    0.00    0.00       1         ggml_backend_sched_new [285]
                0.00    0.00       1/1022        ggml_guid_matches [176]
                0.00    0.00       1/1022        ggml_backend_is_cpu [175]
                0.00    0.00       1/2           ggml_hash_set_new [266]
                0.00    0.00       1/2           ggml_graph_overhead_custom [265]
                0.00    0.00       1/145427      ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [959]
                0.00    0.00       1/145427      ggml_backend_buft_is_host [138]
                0.00    0.00       1/144747      ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) [960]
                0.00    0.00       1/144747      ggml_backend_dev_supports_buft [139]
                0.00    0.00       1/144747      ggml_backend_supports_buft [140]
                0.00    0.00       1/684         ggml_backend_sched_reset [181]
                0.00    0.00       1/1           ggml_gallocr_new_n [309]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[286]    0.0    0.00    0.00       1         ggml_cpu_has_amx_int8 [286]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[287]    0.0    0.00    0.00       1         ggml_cpu_has_arm_fma [287]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[288]    0.0    0.00    0.00       1         ggml_cpu_has_avx [288]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[289]    0.0    0.00    0.00       1         ggml_cpu_has_avx2 [289]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[290]    0.0    0.00    0.00       1         ggml_cpu_has_avx512 [290]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[291]    0.0    0.00    0.00       1         ggml_cpu_has_avx512_bf16 [291]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[292]    0.0    0.00    0.00       1         ggml_cpu_has_avx512_vbmi [292]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[293]    0.0    0.00    0.00       1         ggml_cpu_has_avx512_vnni [293]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[294]    0.0    0.00    0.00       1         ggml_cpu_has_avx_vnni [294]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[295]    0.0    0.00    0.00       1         ggml_cpu_has_blas [295]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[296]    0.0    0.00    0.00       1         ggml_cpu_has_fma [296]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[297]    0.0    0.00    0.00       1         ggml_cpu_has_fp16_va [297]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[298]    0.0    0.00    0.00       1         ggml_cpu_has_llamafile [298]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[299]    0.0    0.00    0.00       1         ggml_cpu_has_matmul_int8 [299]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[300]    0.0    0.00    0.00       1         ggml_cpu_has_neon [300]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[301]    0.0    0.00    0.00       1         ggml_cpu_has_riscv_v [301]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[302]    0.0    0.00    0.00       1         ggml_cpu_has_sse3 [302]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[303]    0.0    0.00    0.00       1         ggml_cpu_has_ssse3 [303]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[304]    0.0    0.00    0.00       1         ggml_cpu_has_sve [304]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[305]    0.0    0.00    0.00       1         ggml_cpu_has_vsx [305]
-----------------------------------------------
                0.00    0.00       1/1           llama_print_system_info [340]
[306]    0.0    0.00    0.00       1         ggml_cpu_has_wasm_simd [306]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_sched_free [283]
[307]    0.0    0.00    0.00       1         ggml_gallocr_free [307]
                0.00    0.00       1/3           ggml_hash_set_free [248]
                0.00    0.00       1/184         ggml_backend_buffer_free [207]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[308]    0.0    0.00    0.00       1         ggml_gallocr_get_buffer_size [308]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_sched_new [285]
[309]    0.0    0.00    0.00       1         ggml_gallocr_new_n [309]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1089]
                0.00    0.00       1/3           ggml_backend_buft_get_alignment [245]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_alloc_ctx_tensors_from_buft [117]
[310]    0.0    0.00    0.00       1         ggml_get_no_alloc [310]
-----------------------------------------------
                0.00    0.00       1/1           llama_log_set [329]
[311]    0.0    0.00    0.00       1         ggml_log_set [311]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[312]    0.0    0.00    0.00       1         ggml_quantize_free [312]
                0.00    0.00       3/3           iq2xs_free_impl [252]
                0.00    0.00       1/1554        ggml_critical_section_start [171]
                0.00    0.00       1/1           iq3xs_free_impl [319]
-----------------------------------------------
                0.00    0.00       1/1           alloc_tensor_range [118]
[313]    0.0    0.00    0.00       1         ggml_tallocr_new [313]
                0.00    0.00       1/353652      ggml_backend_buffer_get_base [127]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1089]
                0.00    0.00       1/3           ggml_backend_buft_get_alignment [245]
                0.00    0.00       1/1           ggml_backend_buffer_get_alignment [275]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[314]    0.0    0.00    0.00       1         ggml_threadpool_new [314]
-----------------------------------------------
                0.00    0.00       1/1           ggml_graph_compute [45]
[315]    0.0    0.00    0.00       1         ggml_threadpool_params_default [315]
                0.00    0.00       1/3           ggml_threadpool_params_init [250]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[316]    0.0    0.00    0.00       1         ggml_threadpool_params_match [316]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[317]    0.0    0.00    0.00       1         gguf_free [317]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[318]    0.0    0.00    0.00       1         gguf_get_version [318]
-----------------------------------------------
                0.00    0.00       1/1           ggml_quantize_free [312]
[319]    0.0    0.00    0.00       1         iq3xs_free_impl [319]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[320]    0.0    0.00    0.00       1         llama_add_bos_token [320]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[321]    0.0    0.00    0.00       1         llama_add_eos_token [321]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[322]    0.0    0.00    0.00       1         llama_attach_threadpool [322]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[323]    0.0    0.00    0.00       1         llama_backend_free [323]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[324]    0.0    0.00    0.00       1         llama_backend_init [324]
                0.00    0.00       1/3           ggml_time_init [251]
                0.00    0.00       1/1211        ggml_init [174]
-----------------------------------------------
                0.00    0.00       1/1           common_context_params_to_llama(common_params const&) [1151]
[325]    0.0    0.00    0.00       1         llama_context_default_params [325]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[326]    0.0    0.00    0.00       1         llama_free [326]
                0.00    0.00     343/355         llama_format_tensor_shape(ggml_tensor const*) [985]
                0.00    0.00       2/184         ggml_backend_buffer_free [207]
                0.00    0.00       1/1           ggml_backend_sched_free [283]
                0.00    0.00       1/1           ggml_backend_cpu_free(ggml_backend*) [1155]
                0.00    0.00       1/2           ggml_backend_free [256]
                0.00    0.00       1/1212        ggml_free [173]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[327]    0.0    0.00    0.00       1         llama_free_model [327]
                0.00    0.00       1/1           llama_model::~llama_model() [1183]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [11]
[328]    0.0    0.00    0.00       1         llama_kv_cache_clear [328]
                0.00    0.00       2/355         llama_format_tensor_shape(ggml_tensor const*) [985]
                0.00    0.00       1/343         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [991]
                0.00    0.00       1/343         ggml_backend_buffer_clear [188]
-----------------------------------------------
                0.00    0.00       1/1           common_init() [1131]
[329]    0.0    0.00    0.00       1         llama_log_set [329]
                0.00    0.00       1/1           ggml_log_set [311]
-----------------------------------------------
                0.00    0.00       1/1           common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1147]
[330]    0.0    0.00    0.00       1         llama_lora_adapter_clear [330]
-----------------------------------------------
                0.00    0.00       1/1           common_model_params_to_llama(common_params const&) [1149]
[331]    0.0    0.00    0.00       1         llama_model_default_params [331]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [11]
[332]    0.0    0.00    0.00       1         llama_model_has_decoder [332]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[333]    0.0    0.00    0.00       1         llama_n_ctx [333]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[334]    0.0    0.00    0.00       1         llama_numa_init [334]
-----------------------------------------------
                0.00    0.00       1/1           llama_perf_context_print [336]
[335]    0.0    0.00    0.00       1         llama_perf_context [335]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[336]    0.0    0.00    0.00       1         llama_perf_context_print [336]
                0.00    0.00       3/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00       1/2053        ggml_time_us [168]
                0.00    0.00       1/1           llama_perf_context [335]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [11]
[337]    0.0    0.00    0.00       1         llama_perf_context_reset [337]
                0.00    0.00       1/2053        ggml_time_us [168]
-----------------------------------------------
                0.00    0.00       1/1           llama_perf_sampler_print [339]
[338]    0.0    0.00    0.00       1         llama_perf_sampler [338]
-----------------------------------------------
                0.00    0.00       1/1           common_perf_print(llama_context const*, common_sampler const*) [1135]
[339]    0.0    0.00    0.00       1         llama_perf_sampler_print [339]
                0.00    0.00       1/1           llama_perf_sampler [338]
-----------------------------------------------
                0.00    0.00       1/1           common_params_get_system_info[abi:cxx11](common_params const&) [1150]
[340]    0.0    0.00    0.00       1         llama_print_system_info [340]
                0.00    0.00      17/17          std::__cxx11::to_string(int) [1044]
                0.00    0.00       1/1554        ggml_critical_section_end [170]
                0.00    0.00       1/342         ggml_cpu_init [193]
                0.00    0.00       1/1           ggml_cpu_has_avx [288]
                0.00    0.00       1/1           ggml_cpu_has_avx_vnni [294]
                0.00    0.00       1/1           ggml_cpu_has_avx2 [289]
                0.00    0.00       1/1           ggml_cpu_has_avx512 [290]
                0.00    0.00       1/1           ggml_cpu_has_avx512_vbmi [292]
                0.00    0.00       1/1           ggml_cpu_has_avx512_vnni [293]
                0.00    0.00       1/1           ggml_cpu_has_avx512_bf16 [291]
                0.00    0.00       1/1           ggml_cpu_has_amx_int8 [286]
                0.00    0.00       1/1           ggml_cpu_has_fma [296]
                0.00    0.00       1/1           ggml_cpu_has_neon [300]
                0.00    0.00       1/1           ggml_cpu_has_sve [304]
                0.00    0.00       1/1           ggml_cpu_has_arm_fma [287]
                0.00    0.00       1/249657      ggml_cpu_has_f16c [129]
                0.00    0.00       1/1           ggml_cpu_has_fp16_va [297]
                0.00    0.00       1/1           ggml_cpu_has_riscv_v [301]
                0.00    0.00       1/1           ggml_cpu_has_wasm_simd [306]
                0.00    0.00       1/1           ggml_cpu_has_blas [295]
                0.00    0.00       1/1           ggml_cpu_has_sse3 [302]
                0.00    0.00       1/1           ggml_cpu_has_ssse3 [303]
                0.00    0.00       1/1           ggml_cpu_has_vsx [305]
                0.00    0.00       1/1           ggml_cpu_has_matmul_int8 [299]
                0.00    0.00       1/1           ggml_cpu_has_llamafile [298]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_hparams(llama_model_loader&, llama_model&) [58]
[341]    0.0    0.00    0.00       1         llama_rope_type [341]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[342]    0.0    0.00    0.00       1         llama_sampler_chain_default_params [342]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[343]    0.0    0.00    0.00       1         llama_sampler_chain_init [343]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[344]    0.0    0.00    0.00       1         llama_sampler_get_seed [344]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[345]    0.0    0.00    0.00       1         llama_sampler_init_dist [345]
                0.00    0.00       1/2           get_rng_seed(unsigned int) [1115]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[346]    0.0    0.00    0.00       1         llama_sampler_init_dry [346]
                0.00    0.00       1/2           llama_n_ctx_train [271]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[347]    0.0    0.00    0.00       1         llama_sampler_init_grammar [347]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[348]    0.0    0.00    0.00       1         llama_sampler_init_logit_bias [348]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[349]    0.0    0.00    0.00       1         llama_sampler_init_min_p [349]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[350]    0.0    0.00    0.00       1         llama_sampler_init_penalties [350]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[351]    0.0    0.00    0.00       1         llama_sampler_init_temp_ext [351]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[352]    0.0    0.00    0.00       1         llama_sampler_init_top_k [352]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[353]    0.0    0.00    0.00       1         llama_sampler_init_top_p [353]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[354]    0.0    0.00    0.00       1         llama_sampler_init_typical [354]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[355]    0.0    0.00    0.00       1         llama_sampler_init_xtc [355]
                0.00    0.00       1/2           get_rng_seed(unsigned int) [1115]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[356]    0.0    0.00    0.00       1         llama_supports_gpu_offload [356]
                0.00    0.00       1/3           ggml_backend_dev_by_type [247]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[357]    0.0    0.00    0.00       1         llama_token_nl [357]
-----------------------------------------------
                0.00    0.00       1/1           common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1132]
[358]    0.0    0.00    0.00       1         llama_tokenize [358]
-----------------------------------------------
                0.00    0.00 3182328/3182328     unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [953]
[949]    0.0    0.00    0.00 3182328         unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&) [949]
-----------------------------------------------
                0.00    0.00      18/872707      unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
                0.00    0.00     256/872707      unicode_byte_to_utf8[abi:cxx11](unsigned char) [1053]
                0.00    0.00     512/872707      unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [31]
                0.00    0.00  871921/872707      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [33]
[950]    0.0    0.00    0.00  872707         unicode_cpt_to_utf8[abi:cxx11](unsigned int) [950]
-----------------------------------------------
                                 781             replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
                0.00    0.00      21/817191      std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::~map() [1912]
                0.00    0.00      35/817191      llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00      50/817191      std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [1206]
                0.00    0.00      50/817191      std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [1031]
                0.00    0.00     201/817191      __static_initialization_and_destruction_0() [1054]
                0.00    0.00  816834/817191      gguf_kv_to_str(gguf_context const*, int) [52]
[951]    0.0    0.00    0.00  817191+781     replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
                                 781             replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
-----------------------------------------------
                0.00    0.00      16/560310      gguf_kv_to_str(gguf_context const*, int) [52]
                0.00    0.00  560294/560310      llm_load_vocab(llama_model_loader&, llama_model&) [13]
[952]    0.0    0.00    0.00  560310         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) [952]
-----------------------------------------------
                0.00    0.00       2/409746      unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1119]
                0.00    0.00       6/409746      unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
                0.00    0.00  129591/409746      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [33]
                0.00    0.00  280147/409746      llm_load_vocab(llama_model_loader&, llama_model&) [13]
[953]    0.0    0.00    0.00  409746         unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [953]
                0.00    0.00 3182328/3182328     unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&) [949]
-----------------------------------------------
                0.00    0.00       4/387162      common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
                0.00    0.00  387158/387162      llm_load_vocab(llama_model_loader&, llama_model&) [13]
[954]    0.0    0.00    0.00  387162         bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [954]
-----------------------------------------------
                0.00    0.00  353652/353652      ggml_backend_buffer_get_base [127]
[955]    0.0    0.00    0.00  353652         ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*) [955]
-----------------------------------------------
                0.00    0.00  229531/229531      ggml_backend_sched_get_tensor_backend [43]
[956]    0.0    0.00    0.00  229531         ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
                0.00    0.00  144746/145427      ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [959]
                0.00    0.00  144746/145427      ggml_backend_buft_is_host [138]
                0.00    0.00  144746/144747      ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) [960]
                0.00    0.00  144746/144747      ggml_backend_dev_supports_buft [139]
                0.00    0.00  144746/144747      ggml_backend_supports_buft [140]
                0.00    0.00  144746/211810      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [957]
                0.00    0.00  144746/211810      ggml_backend_dev_supports_op [132]
                0.00    0.00  144746/211631      ggml_backend_supports_op [133]
-----------------------------------------------
                0.00    0.00      16/211810      llama_new_context_with_model [80]
                0.00    0.00     163/211810      weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) [110]
                0.00    0.00   10912/211810      std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00   55973/211810      ggml_backend_sched_get_tensor_backend [43]
                0.00    0.00  144746/211810      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[957]    0.0    0.00    0.00  211810         ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [957]
-----------------------------------------------
                0.00    0.00     686/156408      std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() [104]
                0.00    0.00   10976/156408      llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) [75]
                0.00    0.00   27440/156408      llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [63]
                0.00    0.00   43904/156408      llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [66]
                0.00    0.00   73402/156408      llm_build_context::build_llama() [61]
[958]    0.0    0.00    0.00  156408         std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) [958]
                0.00    0.00  153664/247678      ggml_format_name [130]
                0.00    0.00   10912/10913       ggml_backend_get_device [157]
                0.00    0.00   10912/211810      ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) [957]
                0.00    0.00   10912/211810      ggml_backend_dev_supports_op [132]
                0.00    0.00   10912/211631      ggml_backend_supports_op [133]
                0.00    0.00   10912/10912       ggml_backend_sched_set_tensor_backend [158]
                0.00    0.00    2744/3038        ggml_set_name [167]
-----------------------------------------------
                0.00    0.00       1/145427      ggml_backend_sched_new [285]
                0.00    0.00     680/145427      llama_set_inputs(llama_context&, llama_ubatch const&) [39]
                0.00    0.00  144746/145427      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[959]    0.0    0.00    0.00  145427         ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) [959]
-----------------------------------------------
                0.00    0.00       1/144747      ggml_backend_sched_new [285]
                0.00    0.00  144746/144747      ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) [956]
[960]    0.0    0.00    0.00  144747         ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) [960]
-----------------------------------------------
                0.00    0.00  130443/130443      llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [33]
[961]    0.0    0.00    0.00  130443         llama_token_get_attr_impl(llama_vocab const&, int) [961]
-----------------------------------------------
                0.00    0.00  128292/128292      gguf_kv_to_str(gguf_context const*, int) [52]
[962]    0.0    0.00    0.00  128292         gguf_data_to_str(gguf_type, void const*, int) [962]
                0.00    0.00       4/4           std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...) [1081]
-----------------------------------------------
                0.00    0.00   13221/80977       llama_sampler_top_k_impl(llama_token_data_array*, int) [24]
                0.00    0.00   67756/80977       void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) [26]
[963]    0.0    0.00    0.00   80977         void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) [963]
-----------------------------------------------
                0.00    0.00     988/988         (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [966]
[964]    0.0    0.00    0.00     988         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long) [964]
-----------------------------------------------
                0.00    0.00     927/927         (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [966]
[965]    0.0    0.00    0.00     927         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long) [965]
-----------------------------------------------
                                2844             (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [966]
                0.00    0.00     913/913         llamafile_sgemm [6]
[966]    0.0    0.00    0.00     913+2844    (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [966]
                0.00    0.00     988/988         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long) [964]
                0.00    0.00     927/927         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long) [965]
                0.00    0.00     479/479         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long) [978]
                                2844             (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [966]
-----------------------------------------------
                0.00    0.00       1/790         common_init() [1131]
                0.00    0.00       1/790         common_init_from_params(common_params&) [11]
                0.00    0.00     357/790         main [8]
                0.00    0.00     431/790         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [980]
[967]    0.0    0.00    0.00     790         common_log_add(common_log*, ggml_log_level, char const*, ...) [967]
                0.00    0.00       2/258         std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [1012]
-----------------------------------------------
                0.00    0.00       1/790         common_init() [1131]
                0.00    0.00       1/790         common_init_from_params(common_params&) [11]
                0.00    0.00     357/790         main [8]
                0.00    0.00     431/790         common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) [981]
[968]    0.0    0.00    0.00     790         common_log_main() [968]
                0.00    0.00     256/258         std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [1012]
                0.00    0.00       1/1           std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long) [1211]
-----------------------------------------------
                0.00    0.00       2/733         std::map<int, int, std::less<int>, std::allocator<std::pair<int const, int> > >::~map() [1915]
                0.00    0.00       2/733         std::map<int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::less<int>, std::allocator<std::pair<int const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >::~map() [1914]
                0.00    0.00       2/733         std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> > >::~map() [1913]
                0.00    0.00       4/733         void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1082]
                0.00    0.00      10/733         unicode_byte_to_utf8[abi:cxx11](unsigned char) [1053]
                0.00    0.00      14/733         unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
                0.00    0.00     699/733         std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [1100]
[969]    0.0    0.00    0.00     733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [969]
-----------------------------------------------
                0.00    0.00       1/687         llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00     686/687         llama_decode_internal(llama_context&, llama_batch) [20]
[970]    0.0    0.00    0.00     687         std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [970]
-----------------------------------------------
                0.00    0.00     680/680         main [8]
[971]    0.0    0.00    0.00     680         llama_token_is_eog_impl(llama_vocab const&, int) [971]
-----------------------------------------------
                0.00    0.00     680/680         llama_set_inputs(llama_context&, llama_ubatch const&) [39]
[972]    0.0    0.00    0.00     680         ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long) [972]
-----------------------------------------------
                0.00    0.00     339/678         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
                0.00    0.00     339/678         llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1002]
[973]    0.0    0.00    0.00     678         llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [973]
                0.00    0.00       1/1           std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand() [1201]
-----------------------------------------------
                0.00    0.00     339/678         llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) [1005]
                0.00    0.00     339/678         llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1002]
[974]    0.0    0.00    0.00     678         llama_sampler_softmax_impl(llama_token_data_array*) [974]
-----------------------------------------------
                                  17             common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [975]
                0.00    0.00     127/565         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
                0.00    0.00     173/565         common_arg::common_arg(common_arg const&) [1017]
                0.00    0.00     265/565         common_arg::~common_arg() [983]
[975]    0.0    0.00    0.00     565+17      common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [975]
                                  17             common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [975]
-----------------------------------------------
                0.00    0.00       3/524         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1091]
                0.00    0.00       9/524         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [1058]
                0.00    0.00      42/524         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
                0.00    0.00      45/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1034]
                0.00    0.00      50/524         common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [1030]
                0.00    0.00      96/524         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1028]
                0.00    0.00     106/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
                0.00    0.00     173/524         common_arg::common_arg(common_arg const&) [1017]
[976]    0.0    0.00    0.00     524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
-----------------------------------------------
                0.00    0.00       1/522         LLM_KV::operator()[abi:cxx11](llm_kv) const [1193]
                0.00    0.00       2/522         llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00       3/522         llama_state_seq_get_size [232]
                0.00    0.00       5/522         bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1076]
                0.00    0.00       5/522         bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1075]
                0.00    0.00      14/522         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00      25/522         llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00      28/522         bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
                0.00    0.00     439/522         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
[977]    0.0    0.00    0.00     522         format(char const*, ...) [977]
-----------------------------------------------
                0.00    0.00     479/479         (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) [966]
[978]    0.0    0.00    0.00     479         void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long) [978]
-----------------------------------------------
                0.00    0.00       1/431         main [8]
                0.00    0.00       1/431         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/431         common_perf_print(llama_context const*, common_sampler const*) [1135]
                0.00    0.00       3/431         llama_perf_context_print [336]
                0.00    0.00      15/431         llama_new_context_with_model [80]
                0.00    0.00      41/431         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00      52/431         llama_load_model_from_file [12]
                0.00    0.00      61/431         llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) [1019]
                0.00    0.00     256/431         llm_load_vocab(llama_model_loader&, llama_model&) [13]
[979]    0.0    0.00    0.00     431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00     431/431         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [980]
-----------------------------------------------
                0.00    0.00     431/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
[980]    0.0    0.00    0.00     431         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [980]
                0.00    0.00     431/790         common_log_add(common_log*, ggml_log_level, char const*, ...) [967]
                0.00    0.00     431/431         common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) [981]
-----------------------------------------------
                0.00    0.00     431/431         llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) [980]
[981]    0.0    0.00    0.00     431         common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) [981]
                0.00    0.00     431/790         common_log_main() [968]
-----------------------------------------------
                0.00    0.00     385/385         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const [1016]
[982]    0.0    0.00    0.00     385         common_arg::in_example(llama_example) [982]
-----------------------------------------------
                0.00    0.00     376/376         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[983]    0.0    0.00    0.00     376         common_arg::~common_arg() [983]
                0.00    0.00     265/565         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [975]
-----------------------------------------------
                               46885             llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [984]
                0.00    0.00      18/358         llama_vocab::~llama_vocab() [1185]
                0.00    0.00     340/358         llama_decode_internal(llama_context&, llama_batch) [20]
[984]    0.0    0.00    0.00     358+46885   llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [984]
                0.00    0.00       2/2           std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long) [1128]
                               46885             llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [984]
-----------------------------------------------
                0.00    0.00       1/355         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
                0.00    0.00       1/355         llama_new_context_with_model [80]
                0.00    0.00       1/355         llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00       2/355         llama_kv_cache_clear [328]
                0.00    0.00       7/355         llama_load_model_from_file [12]
                0.00    0.00     343/355         llama_free [326]
[985]    0.0    0.00    0.00     355         llama_format_tensor_shape(ggml_tensor const*) [985]
-----------------------------------------------
                0.00    0.00       2/347         llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00     345/347         llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) [999]
[986]    0.0    0.00    0.00     347         std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [986]
-----------------------------------------------
                0.00    0.00     344/344         main [8]
[987]    0.0    0.00    0.00     344         common_sampler_accept(common_sampler*, int, bool) [987]
                0.00    0.00     683/4123        llama_sampler_accept [165]
                0.00    0.00     344/344         llama_sampler_chain_accept(llama_sampler*, int) [989]
                0.00    0.00     339/339         llama_sampler_grammar_accept_impl(llama_sampler*, int) [1011]
-----------------------------------------------
                0.00    0.00     344/344         llama_sampler_chain_accept(llama_sampler*, int) [989]
[988]    0.0    0.00    0.00     344         llama_sampler_dry_accept(llama_sampler*, int) [988]
-----------------------------------------------
                0.00    0.00     344/344         common_sampler_accept(common_sampler*, int, bool) [987]
[989]    0.0    0.00    0.00     344         llama_sampler_chain_accept(llama_sampler*, int) [989]
                0.00    0.00    3440/4123        llama_sampler_accept [165]
                0.00    0.00     688/2053        ggml_time_us [168]
                0.00    0.00     344/344         llama_sampler_dry_accept(llama_sampler*, int) [988]
                0.00    0.00     344/344         llama_sampler_penalties_accept(llama_sampler*, int) [990]
-----------------------------------------------
                0.00    0.00     344/344         llama_sampler_chain_accept(llama_sampler*, int) [989]
[990]    0.0    0.00    0.00     344         llama_sampler_penalties_accept(llama_sampler*, int) [990]
-----------------------------------------------
                0.00    0.00       1/343         llama_kv_cache_clear [328]
                0.00    0.00       1/343         llama_new_context_with_model [80]
                0.00    0.00     341/343         llama_output_reserve(llama_context&, unsigned long) [997]
[991]    0.0    0.00    0.00     343         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [991]
-----------------------------------------------
                0.00    0.00     343/343         llama_build_graph(llama_context&, llama_ubatch const&, bool) [60]
[992]    0.0    0.00    0.00     343         std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [992]
-----------------------------------------------
                0.00    0.00       1/342         llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/342         llama_new_context_with_model [80]
                0.00    0.00     340/342         llama_decode_internal(llama_context&, llama_batch) [20]
[993]    0.0    0.00    0.00     342         llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) [993]
-----------------------------------------------
                0.00    0.00       1/342         console::cleanup() [1611]
                0.00    0.00     341/342         main [8]
[994]    0.0    0.00    0.00     342         console::set_display(console::display_t) [994]
-----------------------------------------------
                0.00    0.00     342/342         llama_decode_internal(llama_context&, llama_batch) [20]
[995]    0.0    0.00    0.00     342         std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long) [995]
-----------------------------------------------
                0.00    0.00     342/342         llama_decode_internal(llama_context&, llama_batch) [20]
[996]    0.0    0.00    0.00     342         std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long) [996]
-----------------------------------------------
                0.00    0.00       1/341         llama_new_context_with_model [80]
                0.00    0.00     340/341         llama_decode_internal(llama_context&, llama_batch) [20]
[997]    0.0    0.00    0.00     341         llama_output_reserve(llama_context&, unsigned long) [997]
                0.00    0.00     341/353652      ggml_backend_buffer_get_base [127]
                0.00    0.00     341/343         ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) [991]
                0.00    0.00     341/343         ggml_backend_buffer_clear [188]
                0.00    0.00     340/118197      ggml_backend_buffer_get_size [143]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [240]
                0.00    0.00       1/164         ggml_backend_dev_host_buffer_type [212]
                0.00    0.00       1/3           ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1088]
                0.00    0.00       1/182         ggml_backend_buft_alloc_buffer [210]
                0.00    0.00       1/687         std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [970]
-----------------------------------------------
                0.00    0.00     340/340         main [8]
[998]    0.0    0.00    0.00     340         common_sampler_last(common_sampler const*) [998]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[999]    0.0    0.00    0.00     340         llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) [999]
                0.00    0.00     345/347         std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [986]
-----------------------------------------------
                0.00    0.00     340/340         llama_decode_internal(llama_context&, llama_batch) [20]
[1000]   0.0    0.00    0.00     340         ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long) [1000]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1001]   0.0    0.00    0.00     339         llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*) [1001]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1002]   0.0    0.00    0.00     339         llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) [1002]
                0.00    0.00     339/678         llama_sampler_softmax_impl(llama_token_data_array*) [974]
                0.00    0.00     339/678         llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [973]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1003]   0.0    0.00    0.00     339         llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*) [1003]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1004]   0.0    0.00    0.00     339         llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*) [1004]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1005]   0.0    0.00    0.00     339         llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) [1005]
                0.00    0.00     339/678         llama_sampler_softmax_impl(llama_token_data_array*) [974]
-----------------------------------------------
                0.00    0.00     339/339         common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
[1006]   0.0    0.00    0.00     339         llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*) [1006]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1007]   0.0    0.00    0.00     339         llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*) [1007]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1008]   0.0    0.00    0.00     339         llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*) [1008]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1009]   0.0    0.00    0.00     339         llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*) [1009]
-----------------------------------------------
                0.00    0.00     339/339         llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) [25]
[1010]   0.0    0.00    0.00     339         llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*) [1010]
-----------------------------------------------
                0.00    0.00     339/339         common_sampler_accept(common_sampler*, int, bool) [987]
[1011]   0.0    0.00    0.00     339         llama_sampler_grammar_accept_impl(llama_sampler*, int) [1011]
-----------------------------------------------
                0.00    0.00       2/258         common_log_add(common_log*, ggml_log_level, char const*, ...) [967]
                0.00    0.00     256/258         common_log_main() [968]
[1012]   0.0    0.00    0.00     258         std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [1012]
-----------------------------------------------
                0.00    0.00     256/256         std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [1015]
[1013]   0.0    0.00    0.00     256         std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long) [1013]
-----------------------------------------------
                0.00    0.00     256/256         unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [31]
[1014]   0.0    0.00    0.00     256         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&) [1014]
-----------------------------------------------
                0.00    0.00     256/256         unicode_byte_to_utf8[abi:cxx11](unsigned char) [1053]
[1015]   0.0    0.00    0.00     256         std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [1015]
                0.00    0.00     256/256         std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long) [1013]
-----------------------------------------------
                0.00    0.00     203/203         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1016]   0.0    0.00    0.00     203         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const [1016]
                0.00    0.00     385/385         common_arg::in_example(llama_example) [982]
-----------------------------------------------
                0.00    0.00     173/173         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1017]   0.0    0.00    0.00     173         common_arg::common_arg(common_arg const&) [1017]
                0.00    0.00     173/565         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [975]
                0.00    0.00     173/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
-----------------------------------------------
                0.00    0.00     172/172         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1018]   0.0    0.00    0.00     172         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long) [1018]
-----------------------------------------------
                0.00    0.00     148/148         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
[1019]   0.0    0.00    0.00     148         llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) [1019]
                0.00    0.00      61/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[1020]   0.0    0.00    0.00     147         std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&) [1020]
-----------------------------------------------
                0.00    0.00     147/147         llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[1021]   0.0    0.00    0.00     147         std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1021]
-----------------------------------------------
                0.00    0.00     120/120         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1022]   0.0    0.00    0.00     120         common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1022]
-----------------------------------------------
                0.00    0.00     120/120         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1023]   0.0    0.00    0.00     120         void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&) [1023]
-----------------------------------------------
                0.00    0.00       5/119         std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>) [1194]
                0.00    0.00      36/119         std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&) [1042]
                0.00    0.00      36/119         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>) [1124]
                0.00    0.00      42/119         __static_initialization_and_destruction_0() [1325]
[1024]   0.0    0.00    0.00     119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1024]
-----------------------------------------------
                0.00    0.00     107/107         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1025]   0.0    0.00    0.00     107         common_arg::set_examples(std::initializer_list<llama_example>) [1025]
                0.00    0.00     107/107         void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*) [1026]
-----------------------------------------------
                0.00    0.00     107/107         common_arg::set_examples(std::initializer_list<llama_example>) [1025]
[1026]   0.0    0.00    0.00     107         void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*) [1026]
-----------------------------------------------
                0.00    0.00     105/105         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1027]   0.0    0.00    0.00     105         string_format[abi:cxx11](char const*, ...) [1027]
-----------------------------------------------
                0.00    0.00      96/96          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1028]   0.0    0.00    0.00      96         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1028]
                0.00    0.00      96/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
-----------------------------------------------
                0.00    0.00      60/60          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1029]   0.0    0.00    0.00      60         common_arg::set_env(char const*) [1029]
-----------------------------------------------
                0.00    0.00      50/50          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1030]   0.0    0.00    0.00      50         common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [1030]
                0.00    0.00      50/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
-----------------------------------------------
                0.00    0.00      50/50          __static_initialization_and_destruction_0() [1054]
[1031]   0.0    0.00    0.00      50         std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [1031]
                0.00    0.00      50/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
-----------------------------------------------
                0.00    0.00      50/50          __static_initialization_and_destruction_0() [1054]
[1032]   0.0    0.00    0.00      50         std::__throw_regex_error(std::regex_constants::error_type, char const*) [1032]
-----------------------------------------------
                0.00    0.00       1/49          llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
                0.00    0.00       5/49          bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1076]
                0.00    0.00       5/49          bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1075]
                0.00    0.00      10/49          llama_state_seq_get_size [232]
                0.00    0.00      28/49          bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
[1033]   0.0    0.00    0.00      49         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1033]
-----------------------------------------------
                0.00    0.00      45/45          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1034]   0.0    0.00    0.00      45         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1034]
                0.00    0.00      45/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
-----------------------------------------------
                0.00    0.00       1/32          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1084]
                0.00    0.00       3/32          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1073]
                0.00    0.00       6/32          std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
                0.00    0.00       7/32          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
                0.00    0.00      15/32          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1040]
[1035]   0.0    0.00    0.00      32         std::__detail::_Scanner<char>::_M_advance() [1035]
-----------------------------------------------
                0.00    0.00      30/30          common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1036]   0.0    0.00    0.00      30         common_arg::set_sparam() [1036]
-----------------------------------------------
                0.00    0.00      30/30          llm_load_hparams(llama_model_loader&, llama_model&) [58]
[1037]   0.0    0.00    0.00      30         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long) [1037]
-----------------------------------------------
                0.00    0.00      10/28          llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00      18/28          llm_load_vocab(llama_model_loader&, llama_model&) [13]
[1038]   0.0    0.00    0.00      28         bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [1038]
                0.00    0.00      28/522         format(char const*, ...) [977]
                0.00    0.00      28/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1033]
                0.00    0.00      28/58          gguf_find_key [218]
                0.00    0.00       9/158         gguf_get_kv_type [213]
                0.00    0.00       9/13          gguf_get_val_u32 [224]
-----------------------------------------------
                0.00    0.00       1/26          llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1112]
                0.00    0.00       2/26          common_init_from_params(common_params&) [11]
                0.00    0.00       5/26          llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
                0.00    0.00      18/26          main [8]
[1039]   0.0    0.00    0.00      26         void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1039]
-----------------------------------------------
                0.00    0.00       3/25          void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
                0.00    0.00       6/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [1074]
                0.00    0.00      16/25          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
[1040]   0.0    0.00    0.00      25         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1040]
                0.00    0.00      15/22          std::__detail::_Scanner<char>::_M_scan_in_bracket() [1041]
                0.00    0.00      15/32          std::__detail::_Scanner<char>::_M_advance() [1035]
-----------------------------------------------
                0.00    0.00       3/22          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1073]
                0.00    0.00       4/22          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
                0.00    0.00      15/22          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1040]
[1041]   0.0    0.00    0.00      22         std::__detail::_Scanner<char>::_M_scan_in_bracket() [1041]
                0.00    0.00       3/3           std::__detail::_Scanner<char>::_M_eat_escape_ecma() [1104]
-----------------------------------------------
                0.00    0.00      18/18          __static_initialization_and_destruction_0() [1325]
[1042]   0.0    0.00    0.00      18         std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&) [1042]
                0.00    0.00      36/119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1024]
-----------------------------------------------
                0.00    0.00      18/18          __static_initialization_and_destruction_0() [1325]
[1043]   0.0    0.00    0.00      18         std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::~vector() [1043]
-----------------------------------------------
                0.00    0.00      17/17          llama_print_system_info [340]
[1044]   0.0    0.00    0.00      17         std::__cxx11::to_string(int) [1044]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [52]
[1045]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1045]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [52]
[1046]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1046]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [52]
[1047]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1047]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [52]
[1048]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1048]
-----------------------------------------------
                0.00    0.00      16/16          gguf_kv_to_str(gguf_context const*, int) [52]
[1049]   0.0    0.00    0.00      16         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&) [1049]
-----------------------------------------------
                0.00    0.00      15/15          void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
[1050]   0.0    0.00    0.00      15         bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
                0.00    0.00      16/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1040]
                0.00    0.00       7/32          std::__detail::_Scanner<char>::_M_advance() [1035]
                0.00    0.00       6/8           void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [1063]
                0.00    0.00       4/22          std::__detail::_Scanner<char>::_M_scan_in_bracket() [1041]
                0.00    0.00       3/3           void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&) [1097]
                0.00    0.00       1/4           std::__detail::_Scanner<char>::_M_scan_normal() [1083]
                0.00    0.00       1/1           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const [1233]
-----------------------------------------------
                0.00    0.00       1/13          unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
                0.00    0.00      12/13          unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1119]
[1051]   0.0    0.00    0.00      13         unicode_cpt_flags(unsigned int) [1051]
-----------------------------------------------
                0.00    0.00       1/12          std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [1224]
                0.00    0.00       2/12          std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [1102]
                0.00    0.00       2/12          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
                0.00    0.00       3/12          std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [1103]
                0.00    0.00       4/12          std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
[1052]   0.0    0.00    0.00      12         void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1052]
-----------------------------------------------
                0.00    0.00      10/10          unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
[1053]   0.0    0.00    0.00      10         unicode_byte_to_utf8[abi:cxx11](unsigned char) [1053]
                0.00    0.00     256/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [950]
                0.00    0.00     256/256         std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [1015]
                0.00    0.00      10/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [969]
-----------------------------------------------
                0.00    0.00      10/10          __static_initialization_and_destruction_0() [1325]
[1054]   0.0    0.00    0.00      10         __static_initialization_and_destruction_0() [1054]
                0.00    0.00     201/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
                0.00    0.00      50/50          std::__throw_regex_error(std::regex_constants::error_type, char const*) [1032]
                0.00    0.00      50/50          std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [1031]
                0.00    0.00       1/1           std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&) [1205]
                0.00    0.00       1/1           std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&) [1204]
                0.00    0.00       1/1           std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [1206]
                0.00    0.00       1/1           std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&) [1203]
                0.00    0.00       1/1           std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&) [1202]
-----------------------------------------------
                0.00    0.00      10/10          llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
[1055]   0.0    0.00    0.00      10         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1055]
-----------------------------------------------
                0.00    0.00       2/9           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1112]
                0.00    0.00       3/9           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
                0.00    0.00       4/9           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1061]
[1056]   0.0    0.00    0.00       9         tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1056]
-----------------------------------------------
                0.00    0.00       2/9           ggml_backend_reg_get [259]
                0.00    0.00       7/9           ggml_backend_dev_get [233]
[1057]   0.0    0.00    0.00       9         get_reg() [1057]
-----------------------------------------------
                0.00    0.00       9/9           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1058]   0.0    0.00    0.00       9         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [1058]
                0.00    0.00       9/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
-----------------------------------------------
                0.00    0.00       9/9           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
[1059]   0.0    0.00    0.00       9         void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&) [1059]
-----------------------------------------------
                0.00    0.00       9/9           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1060]   0.0    0.00    0.00       9         void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&) [1060]
-----------------------------------------------
                0.00    0.00       8/8           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
[1061]   0.0    0.00    0.00       8         llm_tokenizer_bpe_session::add_new_bigram(int, int) [1061]
                0.00    0.00       6/6           llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1069]
                0.00    0.00       4/9           tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1056]
                0.00    0.00       3/3           void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&) [1095]
-----------------------------------------------
                0.00    0.00       8/8           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1062]   0.0    0.00    0.00       8         void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&) [1062]
-----------------------------------------------
                0.00    0.00       2/8           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
                0.00    0.00       6/8           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
[1063]   0.0    0.00    0.00       8         void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [1063]
-----------------------------------------------
                0.00    0.00       7/7           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1064]   0.0    0.00    0.00       7         string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1064]
-----------------------------------------------
                0.00    0.00       7/7           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1065]   0.0    0.00    0.00       7         common_sampler_type_to_chr(common_sampler_type) [1065]
-----------------------------------------------
                0.00    0.00       7/7           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1066]   0.0    0.00    0.00       7         common_sampler_type_to_str[abi:cxx11](common_sampler_type) [1066]
-----------------------------------------------
                0.00    0.00       1/7           llama_new_context_with_model [80]
                0.00    0.00       1/7           llama_load_model_from_file [12]
                0.00    0.00       2/7           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       3/7           ggml_backend_dev_by_type [247]
[1067]   0.0    0.00    0.00       7         ggml_backend_cpu_device_get_type(ggml_backend_device*) [1067]
-----------------------------------------------
                0.00    0.00       6/6           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
[1068]   0.0    0.00    0.00       6         unicode_len_utf8(char) [1068]
-----------------------------------------------
                0.00    0.00       6/6           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1061]
[1069]   0.0    0.00    0.00       6         llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1069]
-----------------------------------------------
                0.00    0.00       3/6           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
                0.00    0.00       3/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
[1070]   0.0    0.00    0.00       6         void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [1070]
-----------------------------------------------
                0.00    0.00       6/6           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1071]   0.0    0.00    0.00       6         std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1071]
-----------------------------------------------
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
[1072]   0.0    0.00    0.00       6         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion() [1072]
-----------------------------------------------
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
[1073]   0.0    0.00    0.00       6         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1073]
                0.00    0.00       3/22          std::__detail::_Scanner<char>::_M_scan_in_bracket() [1041]
                0.00    0.00       3/32          std::__detail::_Scanner<char>::_M_advance() [1035]
                0.00    0.00       3/3           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
-----------------------------------------------
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
[1074]   0.0    0.00    0.00       6         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [1074]
                0.00    0.00       6/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1040]
-----------------------------------------------
                0.00    0.00       1/5           llm_load_hparams(llama_model_loader&, llama_model&) [58]
                0.00    0.00       4/5           llm_load_vocab(llama_model_loader&, llama_model&) [13]
[1075]   0.0    0.00    0.00       5         bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [1075]
                0.00    0.00       5/522         format(char const*, ...) [977]
                0.00    0.00       5/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1033]
                0.00    0.00       5/58          gguf_find_key [218]
-----------------------------------------------
                0.00    0.00       5/5           llm_load_hparams(llama_model_loader&, llama_model&) [58]
[1076]   0.0    0.00    0.00       5         bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [1076]
                0.00    0.00       5/522         format(char const*, ...) [977]
                0.00    0.00       5/49          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1033]
                0.00    0.00       5/58          gguf_find_key [218]
                0.00    0.00       2/158         gguf_get_kv_type [213]
                0.00    0.00       2/2           gguf_get_val_f32 [269]
-----------------------------------------------
                0.00    0.00       2/5           unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1119]
                0.00    0.00       3/5           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
[1077]   0.0    0.00    0.00       5         void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [1077]
-----------------------------------------------
                0.00    0.00       4/4           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1078]   0.0    0.00    0.00       4         postprocess_cpu_params(cpu_params&, cpu_params const*) [1078]
                0.00    0.00       1/1           cpu_get_num_math() [1134]
-----------------------------------------------
                0.00    0.00       1/4           ggml_backend_cpu_buffer_type [240]
                0.00    0.00       1/4           ggml_backend_cpu_init [278]
                0.00    0.00       1/4           ggml_backend_cpu_buffer_from_ptr [277]
                0.00    0.00       1/4           ggml_backend_reg_count [236]
[1079]   0.0    0.00    0.00       4         ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1079]
                0.00    0.00       1/1           ggml_backend_cpu_device_context::ggml_backend_cpu_device_context() [1190]
-----------------------------------------------
                0.00    0.00       4/4           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[1080]   0.0    0.00    0.00       4         llama_data_write_file::write(void const*, unsigned long) [1080]
-----------------------------------------------
                0.00    0.00       4/4           gguf_data_to_str(gguf_type, void const*, int) [962]
[1081]   0.0    0.00    0.00       4         std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...) [1081]
-----------------------------------------------
                0.00    0.00       4/4           unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
[1082]   0.0    0.00    0.00       4         void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1082]
                0.00    0.00       4/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [969]
-----------------------------------------------
                0.00    0.00       1/4           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
                0.00    0.00       3/4           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
[1083]   0.0    0.00    0.00       4         std::__detail::_Scanner<char>::_M_scan_normal() [1083]
-----------------------------------------------
                0.00    0.00       4/4           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
[1084]   0.0    0.00    0.00       4         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1084]
                0.00    0.00       1/32          std::__detail::_Scanner<char>::_M_advance() [1035]
                0.00    0.00       1/1           std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back() [1207]
                0.00    0.00       1/1           std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [1224]
-----------------------------------------------
                0.00    0.00       3/3           ggml_backend_buffer_free [207]
[1085]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*) [1085]
-----------------------------------------------
                0.00    0.00       3/3           llama_new_context_with_model [80]
[1086]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*) [1086]
-----------------------------------------------
                0.00    0.00       1/3           llama_new_context_with_model [80]
                0.00    0.00       2/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1087]   0.0    0.00    0.00       3         ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) [1087]
-----------------------------------------------
                0.00    0.00       1/3           alloc_tensor_range [118]
                0.00    0.00       1/3           ggml_gallocr_reserve_n [101]
                0.00    0.00       1/3           llama_output_reserve(llama_context&, unsigned long) [997]
[1088]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) [1088]
                0.00    0.00       3/532         ggml_aligned_malloc [187]
                0.00    0.00       3/183         ggml_backend_buffer_init [209]
-----------------------------------------------
                0.00    0.00       1/3           ggml_tallocr_new [313]
                0.00    0.00       1/3           ggml_gallocr_new_n [309]
                0.00    0.00       1/3           ggml_backend_alloc_ctx_tensors_from_buft [117]
[1089]   0.0    0.00    0.00       3         ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) [1089]
-----------------------------------------------
                0.00    0.00       3/3           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1090]   0.0    0.00    0.00       3         common_arg::has_value_from_env() [1090]
-----------------------------------------------
                0.00    0.00       3/3           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
[1091]   0.0    0.00    0.00       3         common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1091]
                0.00    0.00       3/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
-----------------------------------------------
                0.00    0.00       3/3           std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() [1094]
[1092]   0.0    0.00    0.00       3         std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1092]
                0.00    0.00       3/3           std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher() [1101]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::~basic_regex() [2038]
[1093]   0.0    0.00    0.00       3         std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_destroy() [1093]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::~basic_regex() [2038]
[1094]   0.0    0.00    0.00       3         std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() [1094]
                0.00    0.00       3/3           std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1092]
-----------------------------------------------
                0.00    0.00       3/3           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1061]
[1095]   0.0    0.00    0.00       3         void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&) [1095]
-----------------------------------------------
                0.00    0.00       1/3           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const [105]
                0.00    0.00       1/3           llama_new_context_with_model [80]
                0.00    0.00       1/3           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[1096]   0.0    0.00    0.00       3         void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [1096]
-----------------------------------------------
                0.00    0.00       3/3           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
[1097]   0.0    0.00    0.00       3         void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&) [1097]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type) [1099]
[1098]   0.0    0.00    0.00       3         std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
                0.00    0.00       6/32          std::__detail::_Scanner<char>::_M_advance() [1035]
                0.00    0.00       4/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1052]
                0.00    0.00       3/4           std::__detail::_Scanner<char>::_M_scan_normal() [1083]
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [1106]
                0.00    0.00       3/5           void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [1077]
                0.00    0.00       3/3           std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [1102]
-----------------------------------------------
                0.00    0.00       3/3           __static_initialization_and_destruction_0() [1325]
[1099]   0.0    0.00    0.00       3         std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type) [1099]
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
-----------------------------------------------
                0.00    0.00       3/3           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
[1100]   0.0    0.00    0.00       3         std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [1100]
                0.00    0.00     699/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [969]
-----------------------------------------------
                0.00    0.00       3/3           std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1092]
[1101]   0.0    0.00    0.00       3         std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher() [1101]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
[1102]   0.0    0.00    0.00       3         std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [1102]
                0.00    0.00       2/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1052]
-----------------------------------------------
                0.00    0.00       3/3           void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
[1103]   0.0    0.00    0.00       3         std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [1103]
                0.00    0.00       3/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1052]
-----------------------------------------------
                0.00    0.00       3/3           std::__detail::_Scanner<char>::_M_scan_in_bracket() [1041]
[1104]   0.0    0.00    0.00       3         std::__detail::_Scanner<char>::_M_eat_escape_ecma() [1104]
-----------------------------------------------
                                   3             std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [1106]
[1105]   0.0    0.00    0.00       3+3       std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion() [1072]
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1073]
                0.00    0.00       6/6           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [1074]
                0.00    0.00       4/4           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1084]
                0.00    0.00       3/6           void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [1070]
                0.00    0.00       2/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1052]
                                   3             std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
-----------------------------------------------
                0.00    0.00       3/3           std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [1098]
[1106]   0.0    0.00    0.00       3         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [1106]
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [1105]
-----------------------------------------------
                0.00    0.00       3/3           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [1073]
[1107]   0.0    0.00    0.00       3         void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [1107]
                0.00    0.00      15/15          bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
                0.00    0.00       3/25          std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [1040]
                0.00    0.00       3/3           std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [1100]
                0.00    0.00       3/3           std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [1103]
                0.00    0.00       3/6           void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [1070]
                0.00    0.00       2/8           void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [1063]
-----------------------------------------------
                0.00    0.00       3/3           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1108]   0.0    0.00    0.00       3         std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1108]
-----------------------------------------------
                0.00    0.00       2/2           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
[1109]   0.0    0.00    0.00       2         unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
                0.00    0.00      18/872707      unicode_cpt_to_utf8[abi:cxx11](unsigned int) [950]
                0.00    0.00      14/733         void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [969]
                0.00    0.00      10/10          unicode_byte_to_utf8[abi:cxx11](unsigned char) [1053]
                0.00    0.00       6/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [953]
                0.00    0.00       4/4           void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1082]
                0.00    0.00       2/2           unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1119]
                0.00    0.00       1/13          unicode_cpt_flags(unsigned int) [1051]
-----------------------------------------------
                0.00    0.00       1/2           llama_new_context_with_model [80]
                0.00    0.00       1/2           common_init_from_params(common_params&) [11]
[1110]   0.0    0.00    0.00       2         llama_token_bos_impl(llama_vocab const&) [1110]
-----------------------------------------------
                0.00    0.00       1/2           common_init_from_params(common_params&) [11]
                0.00    0.00       1/2           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[1111]   0.0    0.00    0.00       2         llama_token_eos_impl(llama_vocab const&) [1111]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_vocab(llama_model_loader&, llama_model&) [13]
                0.00    0.00       1/2           llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [1140]
[1112]   0.0    0.00    0.00       2         llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1112]
                0.00    0.00       2/9           tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1056]
                0.00    0.00       2/2           llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
                0.00    0.00       1/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1039]
-----------------------------------------------
                0.00    0.00       2/2           main [8]
[1113]   0.0    0.00    0.00       2         ggml_threadpool_params_from_cpu_params(cpu_params const&) [1113]
                0.00    0.00       2/3           ggml_threadpool_params_init [250]
-----------------------------------------------
                0.00    0.00       2/2           main [8]
[1114]   0.0    0.00    0.00       2         print_usage(int, char**) [1114]
-----------------------------------------------
                0.00    0.00       1/2           llama_sampler_init_dist [345]
                0.00    0.00       1/2           llama_sampler_init_xtc [355]
[1115]   0.0    0.00    0.00       2         get_rng_seed(unsigned int) [1115]
-----------------------------------------------
                0.00    0.00       2/2           common_context_params_to_llama(common_params const&) [1151]
[1116]   0.0    0.00    0.00       2         kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1116]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_by_name [257]
[1117]   0.0    0.00    0.00       2         ggml_backend_cpu_reg_get_name(ggml_backend_reg*) [1117]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/2           llama_new_context_with_model [80]
[1118]   0.0    0.00    0.00       2         ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) [1118]
-----------------------------------------------
                0.00    0.00       2/2           unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
[1119]   0.0    0.00    0.00       2         unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1119]
                0.00    0.00      12/13          unicode_cpt_flags(unsigned int) [1051]
                0.00    0.00       2/2           std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long) [1129]
                0.00    0.00       2/409746      unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [953]
                0.00    0.00       2/5           void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [1077]
-----------------------------------------------
                0.00    0.00       2/2           ggml_backend_reg_count [236]
[1120]   0.0    0.00    0.00       2         ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*) [1120]
-----------------------------------------------
                0.00    0.00       2/2           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
[1121]   0.0    0.00    0.00       2         llama_mmap::unmap_fragment(unsigned long, unsigned long) [1121]
-----------------------------------------------
                0.00    0.00       1/2           main [8]
                0.00    0.00       1/2           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1122]   0.0    0.00    0.00       2         common_params::~common_params() [1122]
-----------------------------------------------
                0.00    0.00       2/2           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1112]
[1123]   0.0    0.00    0.00       2         llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [1123]
                0.00    0.00      10/10          std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1055]
                0.00    0.00       9/9           void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&) [1059]
                0.00    0.00       8/8           llm_tokenizer_bpe_session::add_new_bigram(int, int) [1061]
                0.00    0.00       6/6           unicode_len_utf8(char) [1068]
                0.00    0.00       5/26          void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [1039]
                0.00    0.00       3/9           tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) [1056]
                0.00    0.00       2/2           unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1109]
-----------------------------------------------
                0.00    0.00       2/2           __static_initialization_and_destruction_0() [1325]
[1124]   0.0    0.00    0.00       2         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>) [1124]
                0.00    0.00      36/119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1024]
-----------------------------------------------
                0.00    0.00       2/2           __static_initialization_and_destruction_0() [1325]
[1125]   0.0    0.00    0.00       2         std::_Hashtable<char, char, std::allocator<char>, std::__detail::_Identity, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, true, true> >::_Hashtable<char const*>(char const*, char const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<char> const&, std::integral_constant<bool, true>) [1125]
-----------------------------------------------
                0.00    0.00       2/2           llama_new_context_with_model [80]
[1126]   0.0    0.00    0.00       2         std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long) [1126]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/2           llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [116]
[1127]   0.0    0.00    0.00       2         std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [1127]
-----------------------------------------------
                0.00    0.00       2/2           llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [984]
[1128]   0.0    0.00    0.00       2         std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long) [1128]
-----------------------------------------------
                0.00    0.00       2/2           unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) [1119]
[1129]   0.0    0.00    0.00       2         std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long) [1129]
-----------------------------------------------
                0.00    0.00       1/2           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
                0.00    0.00       1/2           llm_load_vocab(llama_model_loader&, llama_model&) [13]
[1130]   0.0    0.00    0.00       2         void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1130]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1131]   0.0    0.00    0.00       1         common_init() [1131]
                0.00    0.00       1/1           llama_log_set [329]
                0.00    0.00       1/790         common_log_main() [968]
                0.00    0.00       1/790         common_log_add(common_log*, ggml_log_level, char const*, ...) [967]
-----------------------------------------------
                0.00    0.00       1/1           common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1133]
[1132]   0.0    0.00    0.00       1         common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1132]
                0.00    0.00       1/1           llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [1140]
                0.00    0.00       1/1           llama_tokenize [358]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1133]   0.0    0.00    0.00       1         common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1133]
                0.00    0.00       1/684         llama_get_model [182]
                0.00    0.00       1/1           common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1132]
-----------------------------------------------
                0.00    0.00       1/1           postprocess_cpu_params(cpu_params&, cpu_params const*) [1078]
[1134]   0.0    0.00    0.00       1         cpu_get_num_math() [1134]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1135]   0.0    0.00    0.00       1         common_perf_print(llama_context const*, common_sampler const*) [1135]
                0.00    0.00       1/431         llama_log_internal(ggml_log_level, char const*, ...) [979]
                0.00    0.00       1/1           llama_perf_sampler_print [339]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1136]   0.0    0.00    0.00       1         common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
                0.00    0.00     172/172         std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long) [1018]
                0.00    0.00     127/565         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [975]
                0.00    0.00     120/120         common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1022]
                0.00    0.00      42/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
                0.00    0.00       7/7           string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1064]
                0.00    0.00       6/6           std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1071]
                0.00    0.00       4/4           postprocess_cpu_params(cpu_params&, cpu_params const*) [1078]
                0.00    0.00       3/3           std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1108]
                0.00    0.00       3/3           common_arg::has_value_from_env() [1090]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
                0.00    0.00       1/1           common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*) [1225]
                0.00    0.00       1/1           common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*) [1226]
                0.00    0.00       1/2           common_params::~common_params() [1122]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1229]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1230]
                0.00    0.00       1/1           common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int) [1231]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1137]   0.0    0.00    0.00       1         common_sampler_free(common_sampler*) [1137]
                0.00    0.00       2/2           llama_sampler_free <cycle 1> [226]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1138]   0.0    0.00    0.00       1         common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
                0.00    0.00      10/10          llama_sampler_chain_add [229]
                0.00    0.00       2/341         llama_n_vocab [194]
                0.00    0.00       1/1           llama_sampler_chain_default_params [342]
                0.00    0.00       1/1           common_sampler_params::common_sampler_params(common_sampler_params const&) [1189]
                0.00    0.00       1/1           llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*) [1152]
                0.00    0.00       1/1           llama_sampler_init_grammar [347]
                0.00    0.00       1/1           llama_sampler_chain_init [343]
                0.00    0.00       1/1           llama_sampler_init_logit_bias [348]
                0.00    0.00       1/2           llama_token_eos_impl(llama_vocab const&) [1111]
                0.00    0.00       1/2           llama_token_eos [274]
                0.00    0.00       1/1           llama_token_nl_impl(llama_vocab const&) [1139]
                0.00    0.00       1/1           llama_token_nl [357]
                0.00    0.00       1/1           llama_sampler_init_penalties [350]
                0.00    0.00       1/1           llama_sampler_init_dist [345]
                0.00    0.00       1/1           llama_sampler_init_xtc [355]
                0.00    0.00       1/1           llama_sampler_init_temp_ext [351]
                0.00    0.00       1/1           llama_sampler_init_typical [354]
                0.00    0.00       1/1           llama_sampler_init_min_p [349]
                0.00    0.00       1/1           llama_sampler_init_top_p [353]
                0.00    0.00       1/1           llama_sampler_init_top_k [352]
                0.00    0.00       1/1           llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long) [1148]
                0.00    0.00       1/1           llama_sampler_init_dry [346]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[1139]   0.0    0.00    0.00       1         llama_token_nl_impl(llama_vocab const&) [1139]
-----------------------------------------------
                0.00    0.00       1/1           common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1132]
[1140]   0.0    0.00    0.00       1         llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [1140]
                0.00    0.00       1/2           llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1112]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1141]   0.0    0.00    0.00       1         common_sampler_print[abi:cxx11](common_sampler const*) [1141]
                0.00    0.00      11/11          llama_sampler_chain_n [227]
                0.00    0.00      10/10          llama_sampler_chain_get [230]
                0.00    0.00      10/10          llama_sampler_name [231]
                0.00    0.00       1/1           llama_sampler_dist_name(llama_sampler const*) [1163]
                0.00    0.00       1/1           llama_sampler_temp_ext_name(llama_sampler const*) [1175]
                0.00    0.00       1/1           llama_sampler_xtc_name(llama_sampler const*) [1161]
                0.00    0.00       1/1           llama_sampler_min_p_name(llama_sampler const*) [1166]
                0.00    0.00       1/1           llama_sampler_top_p_name(llama_sampler const*) [1170]
                0.00    0.00       1/1           llama_sampler_typical_name(llama_sampler const*) [1173]
                0.00    0.00       1/1           llama_sampler_top_k_name(llama_sampler const*) [1168]
                0.00    0.00       1/1           llama_sampler_dry_name(llama_sampler const*) [1159]
                0.00    0.00       1/1           llama_sampler_penalties_name(llama_sampler const*) [1177]
                0.00    0.00       1/1           llama_sampler_logit_bias_name(llama_sampler const*) [1179]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1142]   0.0    0.00    0.00       1         set_process_priority(ggml_sched_priority) [1142]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1143]   0.0    0.00    0.00       1         common_sampler_get_seed(common_sampler const*) [1143]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1144]   0.0    0.00    0.00       1         llama_add_bos_token_impl(llama_vocab const&) [1144]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1145]   0.0    0.00    0.00       1         llama_add_eos_token_impl(llama_vocab const&) [1145]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1146]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1146]
                0.00    0.00     376/376         common_arg::~common_arg() [983]
                0.00    0.00     203/203         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const [1016]
                0.00    0.00     173/173         common_arg::common_arg(common_arg const&) [1017]
                0.00    0.00     120/120         void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&) [1023]
                0.00    0.00     107/107         common_arg::set_examples(std::initializer_list<llama_example>) [1025]
                0.00    0.00     106/524         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) [976]
                0.00    0.00     105/105         string_format[abi:cxx11](char const*, ...) [1027]
                0.00    0.00      96/96          common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1028]
                0.00    0.00      60/60          common_arg::set_env(char const*) [1029]
                0.00    0.00      50/50          common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [1030]
                0.00    0.00      45/45          common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1034]
                0.00    0.00      30/30          common_arg::set_sparam() [1036]
                0.00    0.00       9/9           common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [1058]
                0.00    0.00       8/8           void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&) [1062]
                0.00    0.00       7/7           common_sampler_type_to_chr(common_sampler_type) [1065]
                0.00    0.00       7/7           common_sampler_type_to_str[abi:cxx11](common_sampler_type) [1066]
                0.00    0.00       4/387162      bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [954]
                0.00    0.00       3/3           common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [1091]
                0.00    0.00       1/2           llama_supports_rpc [272]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [11]
[1147]   0.0    0.00    0.00       1         common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1147]
                0.00    0.00       1/1           llama_lora_adapter_clear [330]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[1148]   0.0    0.00    0.00       1         llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long) [1148]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [11]
[1149]   0.0    0.00    0.00       1         common_model_params_to_llama(common_params const&) [1149]
                0.00    0.00       1/1           llama_model_default_params [331]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1150]   0.0    0.00    0.00       1         common_params_get_system_info[abi:cxx11](common_params const&) [1150]
                0.00    0.00       1/1           llama_print_system_info [340]
-----------------------------------------------
                0.00    0.00       1/1           common_init_from_params(common_params&) [11]
[1151]   0.0    0.00    0.00       1         common_context_params_to_llama(common_params const&) [1151]
                0.00    0.00       2/2           kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1116]
                0.00    0.00       1/1           llama_context_default_params [325]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[1152]   0.0    0.00    0.00       1         llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*) [1152]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1153]   0.0    0.00    0.00       1         llm_load_arch(llama_model_loader&, llama_model&) [1153]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1154]   0.0    0.00    0.00       1         write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&) [1154]
-----------------------------------------------
                0.00    0.00       1/1           llama_free [326]
[1155]   0.0    0.00    0.00       1         ggml_backend_cpu_free(ggml_backend*) [1155]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1156]   0.0    0.00    0.00       1         llama_model_type_name(e_model) [1156]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1157]   0.0    0.00    0.00       1         llama_model_ftype_name(llama_ftype) [1157]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1158]   0.0    0.00    0.00       1         llama_sampler_dry_free(llama_sampler*) [1158]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1159]   0.0    0.00    0.00       1         llama_sampler_dry_name(llama_sampler const*) [1159]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1160]   0.0    0.00    0.00       1         llama_sampler_xtc_free(llama_sampler*) [1160]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1161]   0.0    0.00    0.00       1         llama_sampler_xtc_name(llama_sampler const*) [1161]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1162]   0.0    0.00    0.00       1         llama_sampler_dist_free(llama_sampler*) [1162]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1163]   0.0    0.00    0.00       1         llama_sampler_dist_name(llama_sampler const*) [1163]
-----------------------------------------------
                                   1             llama_sampler_free <cycle 1> [226]
[1164]   0.0    0.00    0.00       1         llama_sampler_chain_free(llama_sampler*) <cycle 1> [1164]
                                  10             llama_sampler_free <cycle 1> [226]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1165]   0.0    0.00    0.00       1         llama_sampler_min_p_free(llama_sampler*) [1165]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1166]   0.0    0.00    0.00       1         llama_sampler_min_p_name(llama_sampler const*) [1166]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1167]   0.0    0.00    0.00       1         llama_sampler_top_k_free(llama_sampler*) [1167]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1168]   0.0    0.00    0.00       1         llama_sampler_top_k_name(llama_sampler const*) [1168]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1169]   0.0    0.00    0.00       1         llama_sampler_top_p_free(llama_sampler*) [1169]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1170]   0.0    0.00    0.00       1         llama_sampler_top_p_name(llama_sampler const*) [1170]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1171]   0.0    0.00    0.00       1         llama_sampler_grammar_free(llama_sampler*) [1171]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1172]   0.0    0.00    0.00       1         llama_sampler_typical_free(llama_sampler*) [1172]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1173]   0.0    0.00    0.00       1         llama_sampler_typical_name(llama_sampler const*) [1173]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1174]   0.0    0.00    0.00       1         llama_sampler_temp_ext_free(llama_sampler*) [1174]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1175]   0.0    0.00    0.00       1         llama_sampler_temp_ext_name(llama_sampler const*) [1175]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1176]   0.0    0.00    0.00       1         llama_sampler_penalties_free(llama_sampler*) [1176]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1177]   0.0    0.00    0.00       1         llama_sampler_penalties_name(llama_sampler const*) [1177]
-----------------------------------------------
                0.00    0.00       1/1           llama_sampler_free <cycle 1> [226]
[1178]   0.0    0.00    0.00       1         llama_sampler_logit_bias_free(llama_sampler*) [1178]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_print[abi:cxx11](common_sampler const*) [1141]
[1179]   0.0    0.00    0.00       1         llama_sampler_logit_bias_name(llama_sampler const*) [1179]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1180]   0.0    0.00    0.00       1         ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*) [1180]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1181]   0.0    0.00    0.00       1         ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long) [1181]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1182]   0.0    0.00    0.00       1         ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*) [1182]
-----------------------------------------------
                0.00    0.00       1/1           llama_free_model [327]
[1183]   0.0    0.00    0.00       1         llama_model::~llama_model() [1183]
                0.00    0.00       1/184         ggml_backend_buffer_free [207]
                0.00    0.00       1/1212        ggml_free [173]
                0.00    0.00       1/1           llama_vocab::~llama_vocab() [1185]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [13]
[1184]   0.0    0.00    0.00       1         llama_vocab::init_tokenizer() [1184]
                0.00    0.00       1/1           llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [1187]
-----------------------------------------------
                0.00    0.00       1/1           llama_model::~llama_model() [1183]
[1185]   0.0    0.00    0.00       1         llama_vocab::~llama_vocab() [1185]
                0.00    0.00      18/358         llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [984]
                0.00    0.00       1/1           llm_tokenizer_bpe::~llm_tokenizer_bpe() [1188]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1186]   0.0    0.00    0.00       1         common_params::common_params() [1186]
-----------------------------------------------
                0.00    0.00       1/1           llama_vocab::init_tokenizer() [1184]
[1187]   0.0    0.00    0.00       1         llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [1187]
                0.00    0.00       1/1           std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) [1227]
-----------------------------------------------
                0.00    0.00       1/1           llama_vocab::~llama_vocab() [1185]
[1188]   0.0    0.00    0.00       1         llm_tokenizer_bpe::~llm_tokenizer_bpe() [1188]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_init(llama_model const*, common_sampler_params const&) [1138]
[1189]   0.0    0.00    0.00       1         common_sampler_params::common_sampler_params(common_sampler_params const&) [1189]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) [1079]
[1190]   0.0    0.00    0.00       1         ggml_backend_cpu_device_context::ggml_backend_cpu_device_context() [1190]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1191]   0.0    0.00    0.00       1         console::init(bool, bool) [1191]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1192]   0.0    0.00    0.00       1         common_sampler_params::print[abi:cxx11]() const [1192]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [13]
[1193]   0.0    0.00    0.00       1         LLM_KV::operator()[abi:cxx11](llm_kv) const [1193]
                0.00    0.00       1/522         format(char const*, ...) [977]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1325]
[1194]   0.0    0.00    0.00       1         std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>) [1194]
                0.00    0.00       5/119         std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1024]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1195]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1195]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1196]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1196]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1197]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1197]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1198]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1198]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1199]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1199]
-----------------------------------------------
                0.00    0.00       1/1           llama_load_model_from_file [12]
[1200]   0.0    0.00    0.00       1         std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [1200]
-----------------------------------------------
                0.00    0.00       1/1           llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) [973]
[1201]   0.0    0.00    0.00       1         std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand() [1201]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1054]
[1202]   0.0    0.00    0.00       1         std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&) [1202]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1054]
[1203]   0.0    0.00    0.00       1         std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&) [1203]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1054]
[1204]   0.0    0.00    0.00       1         std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&) [1204]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1054]
[1205]   0.0    0.00    0.00       1         std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&) [1205]
-----------------------------------------------
                0.00    0.00       1/1           __static_initialization_and_destruction_0() [1054]
[1206]   0.0    0.00    0.00       1         std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [1206]
                0.00    0.00      50/817191      replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [951]
-----------------------------------------------
                0.00    0.00       1/1           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1084]
[1207]   0.0    0.00    0.00       1         std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back() [1207]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1208]   0.0    0.00    0.00       1         std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long) [1208]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1209]   0.0    0.00    0.00       1         std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long) [1209]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1210]   0.0    0.00    0.00       1         std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector() [1210]
-----------------------------------------------
                0.00    0.00       1/1           common_log_main() [968]
[1211]   0.0    0.00    0.00       1         std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long) [1211]
-----------------------------------------------
                0.00    0.00       1/1           common_sampler_sample(common_sampler*, llama_context*, int, bool) [17]
[1212]   0.0    0.00    0.00       1         std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long) [1212]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1213]   0.0    0.00    0.00       1         std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector() [1213]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1214]   0.0    0.00    0.00       1         std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long) [1214]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [13]
[1215]   0.0    0.00    0.00       1         std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long) [1215]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_reg_count [236]
[1216]   0.0    0.00    0.00       1         void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&) [1216]
-----------------------------------------------
                0.00    0.00       1/1           ggml_backend_reg_count [236]
[1217]   0.0    0.00    0.00       1         void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&) [1217]
-----------------------------------------------
                0.00    0.00       1/1           main [8]
[1218]   0.0    0.00    0.00       1         std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector() [1218]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [35]
[1219]   0.0    0.00    0.00       1         void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&) [1219]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1220]   0.0    0.00    0.00       1         void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&) [1220]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1221]   0.0    0.00    0.00       1         void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&) [1221]
-----------------------------------------------
                0.00    0.00       1/1           llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) [81]
[1222]   0.0    0.00    0.00       1         void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&) [1222]
-----------------------------------------------
                0.00    0.00       1/1           llama_new_context_with_model [80]
[1223]   0.0    0.00    0.00       1         std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long) [1223]
-----------------------------------------------
                0.00    0.00       1/1           std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [1084]
[1224]   0.0    0.00    0.00       1         std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [1224]
                0.00    0.00       1/12          void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [1052]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1225]   0.0    0.00    0.00       1         common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*) [1225]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1226]   0.0    0.00    0.00       1         common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*) [1226]
-----------------------------------------------
                0.00    0.00       1/1           llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [1187]
[1227]   0.0    0.00    0.00       1         std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) [1227]
-----------------------------------------------
                                  19             void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1228]
                0.00    0.00       1/1           llm_load_vocab(llama_model_loader&, llama_model&) [13]
[1228]   0.0    0.00    0.00       1+19      void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1228]
                                  19             void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) [1228]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1229]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1229]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1230]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1230]
-----------------------------------------------
                0.00    0.00       1/1           common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1136]
[1231]   0.0    0.00    0.00       1         common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int) [1231]
-----------------------------------------------
                0.00    0.00       1/1           llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [113]
[1232]   0.0    0.00    0.00       1         llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const [1232]
-----------------------------------------------
                0.00    0.00       1/1           bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [1050]
[1233]   0.0    0.00    0.00       1         std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const [1233]
-----------------------------------------------

 This table describes the call tree of the program, and was sorted by
 the total amount of time spent in each function and its children.

 Each entry in this table consists of several lines.  The line with the
 index number at the left hand margin lists the current function.
 The lines above it list the functions that called this function,
 and the lines below it list the functions this one called.
 This line lists:
     index	A unique number given to each element of the table.
		Index numbers are sorted numerically.
		The index number is printed next to every function name so
		it is easier to look up where the function is in the table.

     % time	This is the percentage of the `total' time that was spent
		in this function and its children.  Note that due to
		different viewpoints, functions excluded by options, etc,
		these numbers will NOT add up to 100%.

     self	This is the total amount of time spent in this function.

     children	This is the total amount of time propagated into this
		function by its children.

     called	This is the number of times the function was called.
		If the function called itself recursively, the number
		only includes non-recursive calls, and is followed by
		a `+' and the number of recursive calls.

     name	The name of the current function.  The index number is
		printed after it.  If the function is a member of a
		cycle, the cycle number is printed between the
		function's name and the index number.


 For the function's parents, the fields have the following meanings:

     self	This is the amount of time that was propagated directly
		from the function into this parent.

     children	This is the amount of time that was propagated from
		the function's children into this parent.

     called	This is the number of times this parent called the
		function `/' the total number of times the function
		was called.  Recursive calls to the function are not
		included in the number after the `/'.

     name	This is the name of the parent.  The parent's index
		number is printed after it.  If the parent is a
		member of a cycle, the cycle number is printed between
		the name and the index number.

 If the parents of the function cannot be determined, the word
 `<spontaneous>' is printed in the `name' field, and all the other
 fields are blank.

 For the function's children, the fields have the following meanings:

     self	This is the amount of time that was propagated directly
		from the child into the function.

     children	This is the amount of time that was propagated from the
		child's children to the function.

     called	This is the number of times the function called
		this child `/' the total number of times the child
		was called.  Recursive calls by the child are not
		listed in the number after the `/'.

     name	This is the name of the child.  The child's index
		number is printed after it.  If the child is a
		member of a cycle, the cycle number is printed
		between the name and the index number.

 If there are any cycles (circles) in the call graph, there is an
 entry for the cycle-as-a-whole.  This entry shows who called the
 cycle (as parents) and the members of the cycle (as children.)
 The `+' recursive calls entry shows the number of function calls that
 were internal to the cycle, and the calls entry for each member shows,
 for that member, how many times it was called from other members of
 the cycle.

Copyright (C) 2012-2024 Free Software Foundation, Inc.

Copying and distribution of this file, with or without modification,
are permitted in any medium without royalty provided the copyright
notice and this notice are preserved.

Index by function name

 [1131] common_init()       [1200] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [129] ggml_cpu_has_f16c
 [1027] string_format[abi:cxx11](char const*, ...) [1049] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#1}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [296] ggml_cpu_has_fma
 [967] common_log_add(common_log*, ggml_log_level, char const*, ...) [992] std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [297] ggml_cpu_has_fp16_va
 [968] common_log_main()     [958] std::_Function_handler<void (ggml_tensor*, char const*, int), llama_build_graph(llama_context&, llama_ubatch const&, bool)::{lambda(ggml_tensor*, char const*, int)#1}>::_M_invoke(std::_Any_data const&, ggml_tensor*&&, char const*&&, int&&) (std_function.h) [298] ggml_cpu_has_llamafile
 [1132] common_tokenize(llama_model const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1093] std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_destroy() [299] ggml_cpu_has_matmul_int8
 [1133] common_tokenize(llama_context const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool) [1094] std::_Sp_counted_ptr_inplace<std::__detail::_NFA<std::__cxx11::regex_traits<char> >, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose() [300] ggml_cpu_has_neon
 [1134] cpu_get_num_math()  [1201] std::mersenne_twister_engine<unsigned long, 32ul, 624ul, 397ul, 31ul, 2567483615ul, 11ul, 4294967295ul, 7ul, 2636928640ul, 15ul, 4022730752ul, 18ul, 1812433253ul>::_M_gen_rand() [301] ggml_cpu_has_riscv_v
 [1068] unicode_len_utf8(char) [1202] std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::map(std::initializer_list<std::pair<llm_tensor const, llm_tensor_info> >, std::less<llm_tensor> const&, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > const&) [302] ggml_cpu_has_sse3
 [1135] common_perf_print(llama_context const*, common_sampler const*) [73] std::map<llm_tensor, llm_tensor_info, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, llm_tensor_info> > >::~map() [303] ggml_cpu_has_ssse3
 [1051] unicode_cpt_flags(unsigned int) [1203] std::map<llama_rope_scaling_type, char const*, std::less<llama_rope_scaling_type>, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > >::map(std::initializer_list<std::pair<llama_rope_scaling_type const, char const*> >, std::less<llama_rope_scaling_type> const&, std::allocator<std::pair<llama_rope_scaling_type const, char const*> > const&) [304] ggml_cpu_has_sve
 [979] llama_log_internal(ggml_log_level, char const*, ...) [1204] std::map<llm_kv, char const*, std::less<llm_kv>, std::allocator<std::pair<llm_kv const, char const*> > >::map(std::initializer_list<std::pair<llm_kv const, char const*> >, std::less<llm_kv> const&, std::allocator<std::pair<llm_kv const, char const*> > const&) [305] ggml_cpu_has_vsx
 [1136] common_params_parse(int, char**, common_params&, llama_example, void (*)(int, char**)) [1205] std::map<llm_arch, char const*, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, char const*> > >::map(std::initializer_list<std::pair<llm_arch const, char const*> >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, char const*> > const&) [306] ggml_cpu_has_wasm_simd
 [1137] common_sampler_free(common_sampler*) [1206] std::map<llm_arch, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >, std::less<llm_arch>, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > >::map(std::initializer_list<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > >, std::less<llm_arch> const&, std::allocator<std::pair<llm_arch const, std::map<llm_tensor, char const*, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > > > const&) [193] ggml_cpu_init
 [1138] common_sampler_init(llama_model const*, common_sampler_params const&) [1042] std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule, true>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, BuiltinRule const&) [85] ggml_cpy
 [998] common_sampler_last(common_sampler const*) [1070] void std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::emplace_back<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > >(std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >&&) [170] ggml_critical_section_end
 [1139] llama_token_nl_impl(llama_vocab const&) [1207] std::deque<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> >, std::allocator<std::__detail::_StateSeq<std::__cxx11::regex_traits<char> > > >::pop_back() [171] ggml_critical_section_start
 [1140] llama_tokenize_impl(llama_vocab const&, char const*, int, int*, int, bool, bool) [104] std::thread::_State_impl<std::thread::_Invoker<std::tuple<llama_tensor_dequantize_internal(ggml_tensor*, std::vector<no_init<float>, std::allocator<no_init<float> > >&, std::vector<std::thread, std::allocator<std::thread> >&, unsigned long, int)::{lambda(ggml_type, unsigned char*, float*, int)#1}, ggml_type, unsigned char*, float*, unsigned long> > >::_M_run() (std_thread.h) [147] ggml_dup_tensor
 [950] unicode_cpt_to_utf8[abi:cxx11](unsigned int) [1023] void std::vector<common_arg, std::allocator<common_arg> >::emplace_back<common_arg>(common_arg&&) [154] ggml_element_size
 [1109] unicode_regex_split(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [1062] void std::vector<common_arg, std::allocator<common_arg> >::_M_realloc_append<common_arg>(common_arg&&) [263] ggml_fopen
 [1141] common_sampler_print[abi:cxx11](common_sampler const*) [1059] void std::vector<llm_symbol, std::allocator<llm_symbol> >::_M_realloc_append<llm_symbol&>(llm_symbol&) [130] ggml_format_name
 [1110] llama_token_bos_impl(llama_vocab const&) [1208] std::vector<llama_layer, std::allocator<llama_layer> >::_M_default_append(unsigned long) [42] ggml_fp32_to_fp16_row
 [1111] llama_token_eos_impl(llama_vocab const&) [1209] std::vector<llama_kv_cell, std::allocator<llama_kv_cell> >::_M_default_append(unsigned long) [173] ggml_free
 [1142] set_process_priority(ggml_sched_priority) [1095] void std::vector<llm_bigram_bpe, std::allocator<llm_bigram_bpe> >::_M_realloc_append<llm_bigram_bpe const&>(llm_bigram_bpe const&) [64] ggml_gallocr_alloc_graph
 [1053] unicode_byte_to_utf8[abi:cxx11](unsigned char) [1210] std::vector<common_chat_msg, std::allocator<common_chat_msg> >::~vector() [107] ggml_gallocr_allocate_node (ggml-alloc.c)
  [31] unicode_utf8_to_byte(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1211] std::vector<common_log_entry, std::allocator<common_log_entry> >::_M_default_append(unsigned long) [307] ggml_gallocr_free
 [987] common_sampler_accept(common_sampler*, int, bool) [1212] std::vector<llama_token_data, std::allocator<llama_token_data> >::_M_default_append(unsigned long) [308] ggml_gallocr_get_buffer_size
  [17] common_sampler_sample(common_sampler*, llama_context*, int, bool) [1213] std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >::~vector() [309] ggml_gallocr_new_n
  [83] common_token_to_piece[abi:cxx11](llama_context const*, int, bool) [1214] std::vector<llama_model::layer_dev, std::allocator<llama_model::layer_dev> >::_M_default_append(unsigned long) [101] ggml_gallocr_reserve_n
 [949] unicode_cpt_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, unsigned long&) [1215] std::vector<llama_vocab::token_data, std::allocator<llama_vocab::token_data> >::_M_default_append(unsigned long) [235] ggml_get_first_tensor
 [1078] postprocess_cpu_params(cpu_params&, cpu_params const*) [1082] void std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::_M_realloc_append<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [115] ggml_get_max_tensor_size
 [1064] string_process_escapes(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [1071] std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::vector(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) [178] ggml_get_name
 [953] unicode_cpts_from_utf8(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [1043] std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >::~vector() [177] ggml_get_next_tensor
  [11] common_init_from_params(common_params&) [1052] void std::vector<std::__detail::_State<char>, std::allocator<std::__detail::_State<char> > >::_M_realloc_append<std::__detail::_State<char> >(std::__detail::_State<char>&&) [310] ggml_get_no_alloc
 [1143] common_sampler_get_seed(common_sampler const*) [1126] std::vector<ggml_tensor*, std::allocator<ggml_tensor*> >::reserve(unsigned long) [103] ggml_get_rows
 [971] llama_token_is_eog_impl(llama_vocab const&, int) [1216] void std::vector<ggml_backend_reg*, std::allocator<ggml_backend_reg*> >::_M_realloc_append<ggml_backend_reg* const&>(ggml_backend_reg* const&) [223] ggml_get_tensor
 [1112] llama_tokenize_internal(llama_vocab const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, bool) [1217] void std::vector<ggml_backend_device*, std::allocator<ggml_backend_device*> >::_M_realloc_append<ggml_backend_device* const&>(ggml_backend_device* const&) [128] ggml_get_type_traits
 [1144] llama_add_bos_token_impl(llama_vocab const&) [995] std::vector<int*, std::allocator<int*> >::_M_default_append(unsigned long) [153] ggml_get_unary_op
 [1145] llama_add_eos_token_impl(llama_vocab const&) [1218] std::vector<std::vector<int, std::allocator<int> >, std::allocator<std::vector<int, std::allocator<int> > > >::~vector() [45] ggml_graph_compute
 [1146] common_params_parser_init(common_params&, llama_example, void (*)(int, char**)) [1219] void std::vector<std::unique_ptr<llama_file, std::default_delete<llama_file> >, std::allocator<std::unique_ptr<llama_file, std::default_delete<llama_file> > > >::_M_realloc_append<llama_file*>(llama_file*&&) [108] ggml_graph_compute_with_ctx
 [961] llama_token_get_attr_impl(llama_vocab const&, int) [1127] std::vector<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> >, std::allocator<std::unique_ptr<llama_mmap, std::default_delete<llama_mmap> > > >::reserve(unsigned long) [264] ggml_graph_n_nodes
  [33] llama_token_to_piece_impl(llama_vocab const&, int, char*, int, int, bool) [1220] void std::vector<std::unique_ptr<ggml_backend, ggml_backend_deleter>, std::allocator<std::unique_ptr<ggml_backend, ggml_backend_deleter> > >::_M_realloc_append<ggml_backend*&>(ggml_backend*&) [184] ggml_graph_node
 [1147] common_lora_adapters_apply(llama_context*, std::vector<common_lora_adapter_container, std::allocator<common_lora_adapter_container> >&) [1096] void std::vector<std::unique_ptr<ggml_context, ggml_context_deleter>, std::allocator<std::unique_ptr<ggml_context, ggml_context_deleter> > >::_M_realloc_append<ggml_context*&>(ggml_context*&) [265] ggml_graph_overhead_custom
 [1065] common_sampler_type_to_chr(common_sampler_type) [1221] void std::vector<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter>, std::allocator<std::unique_ptr<ggml_backend_buffer, ggml_backend_buffer_deleter> > >::_M_realloc_append<ggml_backend_buffer*&>(ggml_backend_buffer*&) [65] ggml_graph_plan
 [1066] common_sampler_type_to_str[abi:cxx11](common_sampler_type) [1060] void std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, ggml_tensor*> > >::_M_realloc_append<char const*, ggml_tensor*&>(char const*&&, ggml_tensor*&) [191] ggml_graph_view
 [1148] llama_sampler_init_dry_impl(llama_vocab const&, int, float, float, int, int, char const**, unsigned long) [1222] void std::vector<std::pair<ggml_backend_device*, ggml_backend_buffer_type*>, std::allocator<std::pair<ggml_backend_device*, ggml_backend_buffer_type*> > >::_M_realloc_append<ggml_backend_device*&, ggml_backend_buffer_type*>(ggml_backend_device*&, ggml_backend_buffer_type*&&) [176] ggml_guid_matches
 [1149] common_model_params_to_llama(common_params const&) [1097] void std::vector<std::pair<char, char>, std::allocator<std::pair<char, char> > >::_M_realloc_append<std::pair<char, char> >(std::pair<char, char>&&) [248] ggml_hash_set_free
 [1150] common_params_get_system_info[abi:cxx11](common_params const&) [996] std::vector<signed char, std::allocator<signed char> >::_M_default_append(unsigned long) [266] ggml_hash_set_new
 [1151] common_context_params_to_llama(common_params const&) [1012] std::vector<char, std::allocator<char> >::_M_default_append(unsigned long) [179] ggml_hash_set_reset
 [1152] llama_sampler_init_grammar_impl(llama_vocab const&, char const*, char const*) [1063] void std::vector<char, std::allocator<char> >::_M_realloc_append<char>(char&&) [180] ggml_hash_size
 [1113] ggml_threadpool_params_from_cpu_params(cpu_params const&) [969] void std::vector<double, std::allocator<double> >::_M_realloc_append<double const&>(double const&) [174] ggml_init
 [1054] __static_initialization_and_destruction_0() (llama.cpp) [1223] std::vector<unsigned char, std::allocator<unsigned char> >::_M_default_append(unsigned long) [55] ggml_is_3d
 [1114] print_usage(int, char**) (main.cpp) [970] std::vector<int, std::allocator<int> >::_M_default_append(unsigned long) [56] ggml_is_contiguous
 [951] replace_all(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (llama-impl.h) [1039] void std::vector<int, std::allocator<int> >::_M_realloc_append<int const&>(int const&) [50] ggml_is_contiguous_0
 [1115] get_rng_seed(unsigned int) (llama-sampling.cpp) [1128] std::vector<unsigned long, std::allocator<unsigned long> >::_M_default_append(unsigned long) [99] ggml_is_contiguous_1
  [63] llm_build_kv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) (llama.cpp) [1077] void std::vector<unsigned long, std::allocator<unsigned long> >::_M_realloc_append<unsigned long const&>(unsigned long const&) [124] ggml_is_empty
  [66] llm_build_kqv(ggml_context*, llama_context&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, int, int, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) (llama.cpp) [1129] std::vector<unsigned long, std::allocator<unsigned long> >::reserve(unsigned long) [161] ggml_is_matrix
 [1153] llm_load_arch(llama_model_loader&, llama_model&) (llama.cpp) [1098] std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::_M_compile(char const*, char const*, std::regex_constants::syntax_option_type) [146] ggml_is_numa
 [1154] write_logfile(llama_context const*, common_params const&, llama_model const*, std::vector<int, std::allocator<int> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> > const&) (main.cpp) [1099] std::__cxx11::basic_regex<char, std::__cxx11::regex_traits<char> >::basic_regex(char const*, std::regex_constants::syntax_option_type) [155] ggml_is_quantized
  [52] gguf_kv_to_str(gguf_context const*, int) (llama.cpp) [1044] std::__cxx11::to_string(int) [149] ggml_is_transposed
  [13] llm_load_vocab(llama_model_loader&, llama_model&) (llama.cpp) [1031] std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > >::_Rb_tree(std::_Rb_tree<llm_tensor, std::pair<llm_tensor const, char const*>, std::_Select1st<std::pair<llm_tensor const, char const*> >, std::less<llm_tensor>, std::allocator<std::pair<llm_tensor const, char const*> > > const&) [156] ggml_is_vector
 [962] gguf_data_to_str(gguf_type, void const*, int) (llama.cpp) [1026] void std::_Rb_tree<llama_example, llama_example, std::_Identity<llama_example>, std::less<llama_example>, std::allocator<llama_example> >::_M_assign_unique<llama_example const*>(llama_example const*, llama_example const*) [311] ggml_log_set
  [39] llama_set_inputs(llama_context&, llama_ubatch const&) (llama.cpp) [1020] std::pair<std::_Rb_tree_iterator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, bool> std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::_M_emplace_unique<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, llama_model_loader::llama_tensor_weight&&) [84] ggml_mul
  [58] llm_load_hparams(llama_model_loader&, llama_model&) (llama.cpp) [1021] std::_Rb_tree<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight>, std::_Select1st<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> >, llama_model_loader::weight_name_comparer, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_loader::llama_tensor_weight> > >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [72] ggml_mul_mat
  [81] llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*) (llama.cpp) [15] std::pair<std::_Rb_tree_iterator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, bool> std::_Rb_tree<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int>, std::_Select1st<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> >, std::less<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::allocator<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const, int> > >::_M_emplace_unique<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, int&>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >&&, int&) [162] ggml_mul_mat_set_prec
  [60] llama_build_graph(llama_context&, llama_ubatch const&, bool) (llama.cpp) [986] std::pair<std::_Rb_tree_iterator<int>, bool> std::_Rb_tree<int, int, std::_Identity<int>, std::less<int>, std::allocator<int> >::_M_insert_unique<int const&>(int const&) [54] ggml_n_dims
  [78] llm_build_lora_mm(llama_context&, ggml_context*, ggml_tensor*, ggml_tensor*) (llama.cpp) [1100] std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::_M_ready() [62] ggml_nbytes
 [993] llm_build_moe_ffn(ggml_context*, llama_context&, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, ggml_tensor*, long, long, llm_ffn_op_type, bool, bool, float, std::function<void (ggml_tensor*, char const*, int)> const&, int) (llama.cpp) [1101] std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>::~_BracketMatcher() [131] ggml_nelements
  [75] llm_build_kv_store(ggml_context*, llama_hparams const&, llama_cparams const&, llama_kv_cache const&, ggml_cgraph*, ggml_tensor*, ggml_tensor*, int, int, std::function<void (ggml_tensor*, char const*, int)> const&, long) (llama.cpp) [1102] std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_state(std::__detail::_State<char>) [192] ggml_new_graph_custom
 [980] llama_log_internal_v(ggml_log_level, char const*, __va_list_tag*) (llama.cpp) [1224] std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_repeat(long, long, bool) [134] ggml_new_object (ggml.c)
 [997] llama_output_reserve(llama_context&, unsigned long) (llama.cpp) [1103] std::__detail::_NFA<std::__cxx11::regex_traits<char> >::_M_insert_matcher(std::function<bool (char)>) [67] ggml_new_tensor
 [1155] ggml_backend_cpu_free(ggml_backend*) (ggml-backend.cpp) [1035] std::__detail::_Scanner<char>::_M_advance() [102] ggml_new_tensor_1d
  [20] llama_decode_internal(llama_context&, llama_batch) (llama.cpp) [1083] std::__detail::_Scanner<char>::_M_scan_normal() [106] ggml_new_tensor_2d
 [1156] llama_model_type_name(e_model) (llama.cpp) [1104] std::__detail::_Scanner<char>::_M_eat_escape_ecma() [120] ggml_new_tensor_3d
 [110] weight_buft_supported(llama_hparams const&, ggml_tensor*, ggml_op, ggml_backend_buffer_type*, ggml_backend_device*) (llama.cpp) [1041] std::__detail::_Scanner<char>::_M_scan_in_bracket() [98] ggml_new_tensor_4d
 [1116] kv_cache_type_from_str(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (common.cpp) [1040] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_try_char() [76] ggml_new_tensor_impl.constprop.0 (ggml.c)
 [1157] llama_model_ftype_name(llama_ftype) (llama.cpp) [1072] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_assertion() [79] ggml_new_tensor_impl.constprop.1 (ggml.c)
 [973] llama_sample_xtc_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1084] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_quantifier() [94] ggml_new_tensor_impl.constprop.2 (ggml.c)
 [1158] llama_sampler_dry_free(llama_sampler*) (llama-sampling.cpp) [1105] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_alternative() [95] ggml_new_tensor_impl.constprop.3 (ggml.c)
 [1159] llama_sampler_dry_name(llama_sampler const*) (llama-sampling.cpp) [1106] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_disjunction() [34] ggml_nrows
 [1160] llama_sampler_xtc_free(llama_sampler*) (llama-sampling.cpp) [1050] bool std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&) [86] ggml_permute
 [1161] llama_sampler_xtc_name(llama_sampler const*) (llama-sampling.cpp) [1073] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_bracket_expression() [312] ggml_quantize_free
 [1056] tokenizer_st_partition(llama_vocab const&, std::forward_list<fragment_buffer_variant, std::allocator<fragment_buffer_variant> >&, bool) (llama-vocab.cpp) [1107] void std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_insert_bracket_matcher<false, false>(bool) [68] ggml_reshape_3d
 [1162] llama_sampler_dist_free(llama_sampler*) (llama-sampling.cpp) [1074] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_atom() [89] ggml_rms_norm
 [1163] llama_sampler_dist_name(llama_sampler const*) (llama-sampling.cpp) [1108] std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [121] ggml_rope
 [1001] llama_sampler_dry_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1014] std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&&) [150] ggml_rope_cache_init (ggml-cpu.c)
 [999] llama_kv_cache_find_slot(llama_kv_cache&, llama_ubatch const&) (llama.cpp) [49] std::__detail::_Map_base<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [91] ggml_rope_ext
 [1164] llama_sampler_chain_free(llama_sampler*) (llama-sampling.cpp) [1015] std::__detail::_Map_base<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true>, true>::operator[](unsigned char&&) [151] ggml_rope_yarn_corr_dims
 [1002] llama_sampler_dist_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [26] void std::__heap_select<llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}> >(llama_token_data*, llama_token_data*, llama_token_data*, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_top_k_impl(llama_token_data_array*, int)::{lambda(llama_token_data const&, llama_token_data const&)#1}>) (stl_algo.h) [59] ggml_row_size
 [988] llama_sampler_dry_accept(llama_sampler*, int) (llama-sampling.cpp) [1225] common_lora_adapter_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*>(__gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, __gnu_cxx::__normal_iterator<common_lora_adapter_info const*, std::vector<common_lora_adapter_info, std::allocator<common_lora_adapter_info> > >, common_lora_adapter_info*) [172] ggml_set_input
 [1165] llama_sampler_min_p_free(llama_sampler*) (llama-sampling.cpp) [1226] common_control_vector_load_info* std::__do_uninit_copy<__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*>(__gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, __gnu_cxx::__normal_iterator<common_control_vector_load_info const*, std::vector<common_control_vector_load_info, std::allocator<common_control_vector_load_info> > >, common_control_vector_load_info*) [167] ggml_set_name
 [1166] llama_sampler_min_p_name(llama_sampler const*) (llama-sampling.cpp) [1227] std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >* std::__do_uninit_copy<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*>(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >*) [267] ggml_set_no_alloc
 [1167] llama_sampler_top_k_free(llama_sampler*) (llama-sampling.cpp) [1130] void std::__insertion_sort<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) (stl_algo.h) [163] ggml_silu
  [24] llama_sampler_top_k_impl(llama_token_data_array*, int) (llama-sampling.cpp) [963] void std::__insertion_sort<__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}> >(__gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__normal_iterator<unsigned long*, std::vector<unsigned long, std::allocator<unsigned long> > >, __gnu_cxx::__ops::_Iter_comp_iter<llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*)::{lambda(unsigned long, unsigned long)#1}>) (stl_algo.h) [69] ggml_soft_max_ext
 [1168] llama_sampler_top_k_name(llama_sampler const*) (llama-sampling.cpp) [1228] void std::__introsort_loop<__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}> >(__gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, __gnu_cxx::__normal_iterator<int*, std::vector<int, std::allocator<int> > >, long, __gnu_cxx::__ops::_Iter_comp_iter<llm_load_vocab(llama_model_loader&, llama_model&)::{lambda(int, int)#1}>) (stl_algo.h) [119] ggml_tallocr_alloc
 [1169] llama_sampler_top_p_free(llama_sampler*) (llama-sampling.cpp) [1032] std::__throw_regex_error(std::regex_constants::error_type, char const*) [313] ggml_tallocr_new
 [1170] llama_sampler_top_p_name(llama_sampler const*) (llama-sampling.cpp) [954] bool std::operator==<char, std::char_traits<char>, std::allocator<char> >(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, char const*) [208] ggml_tensor_overhead
 [985] llama_format_tensor_shape(ggml_tensor const*) (llama.cpp) [981] common_init()::{lambda(ggml_log_level, char const*, void*)#1}::_FUN(ggml_log_level, char const*, void*) (common.cpp) [249] ggml_threadpool_free
  [25] llama_sampler_chain_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1016] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_arg)#1}::operator()(common_arg) const (arg.cpp) [314] ggml_threadpool_new
 [1003] llama_sampler_min_p_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [976] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&)#2}::_FUN(common_params&) (arg.cpp) [268] ggml_threadpool_new_impl (ggml-cpu.c)
 [1004] llama_sampler_top_k_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1229] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#14}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [315] ggml_threadpool_params_default
 [1005] llama_sampler_top_p_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1034] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#46}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [250] ggml_threadpool_params_init
 [989] llama_sampler_chain_accept(llama_sampler*, int) (llama-sampling.cpp) [1230] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#69}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [316] ggml_threadpool_params_match
 [1171] llama_sampler_grammar_free(llama_sampler*) (llama-sampling.cpp) [975] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#92}::_FUN(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) (arg.cpp) [251] ggml_time_init
 [974] llama_sampler_softmax_impl(llama_token_data_array*) (llama-sampling.cpp) [1231] common_params_parser_init(common_params&, llama_example, void (*)(int, char**))::{lambda(common_params&, int)#17}::_FUN(common_params&, int) (arg.cpp) [168] ggml_time_us
 [1172] llama_sampler_typical_free(llama_sampler*) (llama-sampling.cpp) [1019] llama_load_model_from_file::{lambda(float, void*)#1}::_FUN(float, void*) (llama.cpp) [93] ggml_transpose
 [1173] llama_sampler_typical_name(llama_sampler const*) (llama-sampling.cpp) [105] llm_load_tensors(llama_model_loader&, llama_model&, int, llama_split_mode, int, float const*, bool, bool (*)(float, void*), void*)::{lambda(LLM_TN_IMPL const&, std::initializer_list<long> const&, int)#1}::operator()(LLM_TN_IMPL const&, std::initializer_list<long> const&, int) const (llama.cpp) [237] ggml_type_name
 [1006] llama_sampler_grammar_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [1232] llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*)::{lambda(char const*)#1}::operator()(char const*) const [123] ggml_type_size
 [1174] llama_sampler_temp_ext_free(llama_sampler*) (llama-sampling.cpp) [1233] std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_M_expression_term<false, false>(std::__detail::_Compiler<std::__cxx11::regex_traits<char> >::_BracketState&, std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false>&)::{lambda(char)#1}::operator()(char) const [90] ggml_unary
 [1175] llama_sampler_temp_ext_name(llama_sampler const*) (llama-sampling.cpp) [27] _init [10] ggml_vec_dot_f16 (ggml-cpu.c)
 [1007] llama_sampler_typical_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [118] alloc_tensor_range (ggml-alloc.c) [3] ggml_vec_dot_q4_0_q8_0
 [1176] llama_sampler_penalties_free(llama_sampler*) (llama-sampling.cpp) [206] dequantize_row_q6_K [5] ggml_vec_dot_q4_1_q8_1
 [1177] llama_sampler_penalties_name(llama_sampler const*) (llama-sampling.cpp) [92] ggml_add [47] ggml_vec_dot_q5_K_q8_K
 [1008] llama_sampler_temp_ext_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [186] ggml_aligned_free [4] ggml_vec_dot_q6_K_q8_K
 [991] ggml_backend_cpu_buffer_clear(ggml_backend_buffer*, unsigned char) (ggml-backend.cpp) [187] ggml_aligned_malloc [22] ggml_vec_soft_max_f32 (ggml-cpu.c)
 [1117] ggml_backend_cpu_reg_get_name(ggml_backend_reg*) (ggml-backend.cpp) [136] ggml_are_same_shape [96] ggml_view_1d
 [1178] llama_sampler_logit_bias_free(llama_sampler*) (llama-sampling.cpp) [117] ggml_backend_alloc_ctx_tensors_from_buft [97] ggml_view_2d
 [1179] llama_sampler_logit_bias_name(llama_sampler const*) (llama-sampling.cpp) [188] ggml_backend_buffer_clear [87] ggml_view_3d
 [1009] llama_sampler_penalties_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [207] ggml_backend_buffer_free [77] ggml_view_tensor
  [37] ggml_backend_cpu_graph_compute(ggml_backend*, ggml_cgraph*) (ggml-backend.cpp) [275] ggml_backend_buffer_get_alignment [145] ggml_visit_parents (ggml.c)
 [1010] llama_sampler_logit_bias_apply(llama_sampler*, llama_token_data_array*) (llama-sampling.cpp) [144] ggml_backend_buffer_get_alloc_size [218] gguf_find_key
 [990] llama_sampler_penalties_accept(llama_sampler*, int) (llama-sampling.cpp) [127] ggml_backend_buffer_get_base [214] gguf_find_tensor
 [1079] ggml_backend_cpu_reg_get_device(ggml_backend_reg*, unsigned long) (ggml-backend.cpp) [143] ggml_backend_buffer_get_size [41] gguf_fread_str (ggml.c)
 [955] ggml_backend_cpu_buffer_get_base(ggml_backend_buffer*) (ggml-backend.cpp) [142] ggml_backend_buffer_get_type [317] gguf_free
 [1067] ggml_backend_cpu_device_get_type(ggml_backend_device*) (ggml-backend.cpp) [209] ggml_backend_buffer_init [238] gguf_get_arr_data
 [1180] ggml_backend_cpu_device_get_props(ggml_backend_device*, ggml_backend_dev_props*) (ggml-backend.cpp) [135] ggml_backend_buffer_init_tensor [225] gguf_get_arr_n
 [1118] ggml_backend_cpu_get_proc_address(ggml_backend_reg*, char const*) (ggml-backend.cpp) [183] ggml_backend_buffer_is_host [40] gguf_get_arr_str
 [1011] llama_sampler_grammar_accept_impl(llama_sampler*, int) (llama-sampling.cpp) [253] ggml_backend_buffer_is_multi_buffer [228] gguf_get_arr_type
 [1119] unicode_regex_split_custom_llama3(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<unsigned long, std::allocator<unsigned long> > const&) (unicode.cpp) [244] ggml_backend_buffer_name [215] gguf_get_data_offset
 [1000] ggml_backend_cpu_buffer_get_tensor(ggml_backend_buffer*, ggml_tensor const*, void*, unsigned long, unsigned long) (ggml-backend.cpp) [195] ggml_backend_buffer_reset [169] gguf_get_key
 [972] ggml_backend_cpu_buffer_set_tensor(ggml_backend_buffer*, ggml_tensor*, void const*, unsigned long, unsigned long) (ggml-backend.cpp) [254] ggml_backend_buffer_set_usage [213] gguf_get_kv_type
 [1085] ggml_backend_cpu_buffer_free_buffer(ggml_backend_buffer*) (ggml-backend.cpp) [210] ggml_backend_buft_alloc_buffer [125] gguf_get_n_kv
 [957] ggml_backend_cpu_device_supports_op(ggml_backend_device*, ggml_tensor const*) (ggml-backend.cpp) [245] ggml_backend_buft_get_alignment [216] gguf_get_n_tensors
 [959] ggml_backend_cpu_buffer_type_is_host(ggml_backend_buffer_type*) (ggml-backend.cpp) [126] ggml_backend_buft_get_alloc_size [159] gguf_get_tensor_name
 [1086] ggml_backend_cpu_buffer_type_get_name(ggml_backend_buffer_type*) (ggml-backend.cpp) [211] ggml_backend_buft_get_device [217] gguf_get_tensor_offset
 [960] ggml_backend_cpu_device_supports_buft(ggml_backend_device*, ggml_backend_buffer_type*) (ggml-backend.cpp) [276] ggml_backend_buft_get_max_size [220] gguf_get_val_data
 [1120] ggml_backend_cpu_reg_get_device_count(ggml_backend_reg*) (ggml-backend.cpp) [138] ggml_backend_buft_is_host [269] gguf_get_val_f32
 [956] ggml_backend_sched_backend_id_from_cur(ggml_backend_sched*, ggml_tensor*) (ggml-backend.cpp) [239] ggml_backend_buft_name [221] gguf_get_val_str
 [1087] ggml_backend_cpu_device_get_buffer_type(ggml_backend_device*) (ggml-backend.cpp) [277] ggml_backend_cpu_buffer_from_ptr [224] gguf_get_val_u32
 [1088] ggml_backend_cpu_buffer_type_alloc_buffer(ggml_backend_buffer_type*, unsigned long) (ggml-backend.cpp) [240] ggml_backend_cpu_buffer_type [318] gguf_get_version
 [1089] ggml_backend_cpu_buffer_type_get_alignment(ggml_backend_buffer_type*) (ggml-backend.cpp) [278] ggml_backend_cpu_init [38] gguf_init_from_file
 [1181] ggml_backend_cpu_device_buffer_from_host_ptr(ggml_backend_device*, void*, unsigned long, unsigned long) (ggml-backend.cpp) [241] ggml_backend_cpu_reg [219] gguf_type_name
 [1182] ggml_backend_cpu_buffer_from_ptr_type_get_name(ggml_backend_buffer_type*) (ggml-backend.cpp) [196] ggml_backend_cpu_set_abort_callback [252] iq2xs_free_impl
 [977] format(char const*, ...) (llama.cpp) [197] ggml_backend_cpu_set_n_threads [319] iq3xs_free_impl
 [1057] get_reg() (ggml-backend.cpp) [198] ggml_backend_cpu_set_threadpool [320] llama_add_bos_token
 [982] common_arg::in_example(llama_example) [255] ggml_backend_dev_backend_reg [321] llama_add_eos_token
 [1036] common_arg::set_sparam() [279] ggml_backend_dev_buffer_from_host_ptr [322] llama_attach_threadpool
 [1025] common_arg::set_examples(std::initializer_list<llama_example>) [246] ggml_backend_dev_buffer_type [323] llama_backend_free
 [1022] common_arg::get_value_from_env(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&) [247] ggml_backend_dev_by_type [324] llama_backend_init
 [1090] common_arg::has_value_from_env() [222] ggml_backend_dev_count [201] llama_batch_get_one
 [1029] common_arg::set_env(char const*) [233] ggml_backend_dev_get [325] llama_context_default_params
 [1091] common_arg::common_arg(std::initializer_list<char const*> const&, char const*, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [280] ggml_backend_dev_get_props [19] llama_decode
 [1017] common_arg::common_arg(common_arg const&) [212] ggml_backend_dev_host_buffer_type [326] llama_free
 [1030] common_arg::common_arg(std::initializer_list<char const*> const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&)) [139] ggml_backend_dev_supports_buft [327] llama_free_model
 [1028] common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)) [132] ggml_backend_dev_supports_op [204] llama_get_logits_ith
 [1058] common_arg::common_arg(std::initializer_list<char const*> const&, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, void (*)(common_params&, int)) [234] ggml_backend_dev_type [182] llama_get_model
 [983] common_arg::~common_arg() [281] ggml_backend_event_free [328] llama_kv_cache_clear
 [1121] llama_mmap::unmap_fragment(unsigned long, unsigned long) [256] ggml_backend_free [202] llama_kv_cache_update
 [1183] llama_model::~llama_model() [282] ggml_backend_get_default_buffer_type [12] llama_load_model_from_file
 [1184] llama_vocab::init_tokenizer() [157] ggml_backend_get_device [329] llama_log_set
 [1185] llama_vocab::~llama_vocab() [199] ggml_backend_graph_compute_async [330] llama_lora_adapter_clear
   [7] (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::mnpack(long, long, long, long) (sgemm.cpp) [175] ggml_backend_is_cpu [331] llama_model_default_params
  [14] void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<1>(long, long, long, long) (sgemm.cpp) [257] ggml_backend_reg_by_name [332] llama_model_has_decoder
   [9] void (anonymous namespace)::tinyBLAS_Q0_AVX<block_q4_0, block_q8_0, float>::gemm4xN<2>(long, long, long, long) (sgemm.cpp) [236] ggml_backend_reg_count [243] llama_model_has_encoder
 [965] void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 2>(long, long, long, long) (sgemm.cpp) [258] ggml_backend_reg_dev_count [270] llama_model_is_recurrent
 [978] void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<4, 3>(long, long, long, long) (sgemm.cpp) [242] ggml_backend_reg_dev_get [333] llama_n_ctx
 [964] void (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::gemm<5, 2>(long, long, long, long) (sgemm.cpp) [259] ggml_backend_reg_get [271] llama_n_ctx_train
 [966] (anonymous namespace)::tinyBLAS<8, float __vector(8), float __vector(8), unsigned short, float, float>::mnpack(long, long, long, long) (sgemm.cpp) [260] ggml_backend_reg_get_proc_address [194] llama_n_vocab
 [984] llama_sbatch::from_batch(llama_batch const&, unsigned long, bool, bool) [261] ggml_backend_reg_name [80] llama_new_context_with_model
 [1186] common_params::common_params() [51] ggml_backend_sched_alloc_graph [334] llama_numa_init
 [1122] common_params::~common_params() [283] ggml_backend_sched_free [335] llama_perf_context
  [61] llm_build_context::build_llama() [284] ggml_backend_sched_get_buffer_size [336] llama_perf_context_print
 [1187] llm_tokenizer_bpe::llm_tokenizer_bpe(llama_vocab const&) [262] ggml_backend_sched_get_n_splits [337] llama_perf_context_reset
 [1188] llm_tokenizer_bpe::~llm_tokenizer_bpe() [43] ggml_backend_sched_get_tensor_backend [338] llama_perf_sampler
 [114] llama_model_loader::create_tensor(ggml_context*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::initializer_list<long> const&, int) [36] ggml_backend_sched_graph_compute_async [339] llama_perf_sampler_print
 [116] llama_model_loader::init_mappings(bool, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*) [285] ggml_backend_sched_new [340] llama_print_system_info
 [113] llama_model_loader::load_all_data(ggml_context*, std::unordered_map<unsigned int, ggml_backend_buffer*, std::hash<unsigned int>, std::equal_to<unsigned int>, std::allocator<std::pair<unsigned int const, ggml_backend_buffer*> > >&, std::vector<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> >, std::allocator<std::unique_ptr<llama_mlock, std::default_delete<llama_mlock> > > >*, bool (*)(float, void*), void*) [88] ggml_backend_sched_reserve [341] llama_rope_type
 [1075] bool llama_model_loader::get_key<bool>(llm_kv, bool&, bool) [181] ggml_backend_sched_reset [165] llama_sampler_accept
 [1076] bool llama_model_loader::get_key<float>(llm_kv, float&, bool) [200] ggml_backend_sched_set_eval_callback [166] llama_sampler_apply
 [1038] bool llama_model_loader::get_key<unsigned int>(llm_kv, unsigned int&, bool) [158] ggml_backend_sched_set_tensor_backend [229] llama_sampler_chain_add
  [35] llama_model_loader::llama_model_loader(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool, bool, llama_model_kv_override const*) [189] ggml_backend_sched_synchronize [342] llama_sampler_chain_default_params
 [1189] common_sampler_params::common_sampler_params(common_sampler_params const&) [140] ggml_backend_supports_buft [230] llama_sampler_chain_get
 [1080] llama_data_write_file::write(void const*, unsigned long) [133] ggml_backend_supports_op [343] llama_sampler_chain_init
 [1061] llm_tokenizer_bpe_session::add_new_bigram(int, int) [190] ggml_backend_synchronize [227] llama_sampler_chain_n
 [1123] llm_tokenizer_bpe_session::tokenize(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<int, std::allocator<int> >&) [70] ggml_backend_tensor_alloc [226] llama_sampler_free
 [1190] ggml_backend_cpu_device_context::ggml_backend_cpu_device_context() [111] ggml_backend_tensor_get [344] llama_sampler_get_seed
 [994] console::set_display(console::display_t) [112] ggml_backend_tensor_get_async [345] llama_sampler_init_dist
 [1191] console::init(bool, bool) [109] ggml_backend_tensor_set [346] llama_sampler_init_dry
 [1081] std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > __gnu_cxx::__to_xstring<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, char>(int (*)(char*, unsigned long, char const*, __va_list_tag*), unsigned long, char const*, ...) [148] ggml_backend_view_init [347] llama_sampler_init_grammar
 [1069] llama_vocab::find_bpe_rank(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [53] ggml_blck_size [348] llama_sampler_init_logit_bias
 [1192] common_sampler_params::print[abi:cxx11]() const [152] ggml_build_forward_expand [349] llama_sampler_init_min_p
 [1193] LLM_KV::operator()[abi:cxx11](llm_kv) const [137] ggml_can_repeat [350] llama_sampler_init_penalties
 [1055] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const [1] ggml_compute_forward (ggml-cpu.c) [351] llama_sampler_init_temp_ext
 [1124] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, BuiltinRule> > const&, std::integral_constant<bool, true>) [57] ggml_compute_forward_add (ggml-cpu.c) [352] llama_sampler_init_top_k
 [1033] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, llama_model_kv_override> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [21] ggml_compute_forward_dup (ggml-cpu.c) [353] llama_sampler_init_top_p
 [1018] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, common_arg*>, true>*, unsigned long) [164] ggml_compute_forward_get_rows (ggml-cpu.c) [354] llama_sampler_init_typical
 [1037] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, true>*, unsigned long) [18] ggml_compute_forward_mul (ggml-cpu.c) [355] llama_sampler_init_xtc
  [32] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, unsigned char> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::find(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) [2] ggml_compute_forward_mul_mat (ggml-cpu.c) [231] llama_sampler_name
  [48] std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int>, true>*, unsigned long) [30] ggml_compute_forward_rms_norm (ggml-cpu.c) [232] llama_state_seq_get_size
 [1194] std::_Hashtable<char, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_Hashtable<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*>(std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<std::pair<char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::integral_constant<bool, true>) [28] ggml_compute_forward_rope_f32 (ggml-cpu.c) [356] llama_supports_gpu_offload
 [1125] std::_Hashtable<char, char, std::allocator<char>, std::__detail::_Identity, std::equal_to<char>, std::hash<char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, true, true> >::_Hashtable<char const*>(char const*, char const*, unsigned long, std::hash<char> const&, std::equal_to<char> const&, std::allocator<char> const&, std::integral_constant<bool, true>) [16] ggml_compute_forward_soft_max (ggml-cpu.c) [272] llama_supports_rpc
 [1013] std::_Hashtable<unsigned char, std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::__detail::_Select1st, std::equal_to<unsigned char>, std::hash<unsigned char>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<false, false, true> >::_M_insert_unique_node(unsigned long, unsigned long, std::__detail::_Hash_node<std::pair<unsigned char const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, false>*, unsigned long) [29] ggml_compute_forward_unary (ggml-cpu.c) [203] llama_synchronize
 [1024] std::_Function_handler<nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), json_schema_to_grammar(nlohmann::json_abi_v3_11_3::basic_json<nlohmann::json_abi_v3_11_3::ordered_map, std::vector, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool, long, unsigned long, double, std::allocator, nlohmann::json_abi_v3_11_3::adl_serializer, std::vector<unsigned char, std::allocator<unsigned char> >, void> const&)::{lambda(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)#1}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [160] ggml_cont_2d [273] llama_token_bos
 [1092] std::_Function_handler<bool (char), std::__detail::_BracketMatcher<std::__cxx11::regex_traits<char>, false, false> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) [100] ggml_cont_4d [274] llama_token_eos
 [1195] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [286] ggml_cpu_has_amx_int8 [185] llama_token_is_eog
 [1045] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#2}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [287] ggml_cpu_has_arm_fma [357] llama_token_nl
 [1196] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [288] ggml_cpu_has_avx [141] llama_token_to_piece
 [1046] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#3}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [289] ggml_cpu_has_avx2 [358] llama_tokenize
 [1197] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [290] ggml_cpu_has_avx512 [6] llamafile_sgemm
 [952] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#4}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [291] ggml_cpu_has_avx512_bf16 [23] quantize_row_q8_0
 [1198] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [292] ggml_cpu_has_avx512_vbmi [44] quantize_row_q8_1
 [1047] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#5}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [293] ggml_cpu_has_avx512_vnni [46] quantize_row_q8_K
 [1199] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) (std_function.h) [294] ggml_cpu_has_avx_vnni [205] quantize_row_q8_K_ref
 [1048] std::_Function_handler<unsigned int (unsigned int), llm_load_print_meta(llama_model_loader&, llama_model&)::{lambda(unsigned int)#6}>::_M_invoke(std::_Any_data const&, unsigned int&&) (std_function.h) [295] ggml_cpu_has_blas [122] <cycle 1>
